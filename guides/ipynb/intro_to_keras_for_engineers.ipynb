{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Introduction to Keras for engineers\n",
    "\n",
    "**Author:** [fchollet](https://twitter.com/fchollet)<br>\n",
    "**Date created:** 2023/07/10<br>\n",
    "**Last modified:** 2023/07/10<br>\n",
    "**Description:** First contact with Keras 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Keras 3 is a deep learning framework\n",
    "works with TensorFlow, JAX, and PyTorch interchangeably.\n",
    "This notebook will walk you through key Keras 3 workflows.\n",
    "\n",
    "Let's start by installing Keras 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "!pip install keras --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Setup\n",
    "\n",
    "We're going to be using the JAX backend here -- but you can\n",
    "edit the string below to `\"tensorflow\"` or `\"torch\"` and hit\n",
    "\"Restart runtime\", and the whole notebook will run just the same!\n",
    "This entire guide is backend-agnostic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "\n",
    "# Note that Keras should only be imported after the backend\n",
    "# has been configured. The backend cannot be changed once the\n",
    "# package is imported.\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## A first example: A MNIST convnet\n",
    "\n",
    "Let's start with the Hello World of ML: training a convnet\n",
    "to classify MNIST digits.\n",
    "\n",
    "Here's the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Load the data and split it between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Here's our model.\n",
    "\n",
    "Different model-building options that Keras offers include:\n",
    "\n",
    "- [The Sequential API](https://keras.io/guides/sequential_model/) (what we use below)\n",
    "- [The Functional API](https://keras.io/guides/functional_api/) (most typical)\n",
    "- [Writing your own models yourself via subclassing](https://keras.io/guides/making_new_layers_and_models_via_subclassing/) (for advanced use cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Input(shape=input_shape),\n",
    "        keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        keras.layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Here's our model summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "We use the `compile()` method to specify the optimizer, loss function,\n",
    "and the metrics to monitor. Note that with the JAX and TensorFlow backends,\n",
    "XLA compilation is turned on by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    metrics=[\n",
    "        keras.metrics.SparseCategoricalAccuracy(name=\"acc\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Let's train and evaluate the model. We'll set aside a validation split of 15%\n",
    "of the data during training to monitor generalization on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 20\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(filepath=\"model_at_epoch_{epoch}.keras\"),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2),\n",
    "]\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.15,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "score = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "During training, we were saving a model at the end of each epoch. You\n",
    "can also save the model in its latest state like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.save(\"final_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "And reload it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.saving.load_model(\"final_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Next, you can query predictions of class probabilities with `predict()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "That's it for the basics!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Writing cross-framework custom components\n",
    "\n",
    "Keras enables you to write custom Layers, Models, Metrics, Losses, and Optimizers\n",
    "that work across TensorFlow, JAX, and PyTorch with the same codebase. Let's take a look\n",
    "at custom layers first.\n",
    "\n",
    "The `keras.ops` namespace contains:\n",
    "\n",
    "- An implementation of the NumPy API, e.g. `keras.ops.stack` or `keras.ops.matmul`.\n",
    "- A set of neural network specific ops that are absent from NumPy, such as `keras.ops.conv`\n",
    "or `keras.ops.binary_crossentropy`.\n",
    "\n",
    "Let's make a custom `Dense` layer that works with all backends:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim = input_shape[-1]\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_dim, self.units),\n",
    "            initializer=keras.initializers.GlorotNormal(),\n",
    "            name=\"kernel\",\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.units,),\n",
    "            initializer=keras.initializers.Zeros(),\n",
    "            name=\"bias\",\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Use Keras ops to create backend-agnostic layers/metrics/etc.\n",
    "        x = keras.ops.matmul(inputs, self.w) + self.b\n",
    "        return self.activation(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Next, let's make a custom `Dropout` layer that relies on the `keras.random`\n",
    "namespace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "class MyDropout(keras.layers.Layer):\n",
    "    def __init__(self, rate, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.rate = rate\n",
    "        # Use seed_generator for managing RNG state.\n",
    "        # It is a state element and its seed variable is\n",
    "        # tracked as part of `layer.variables`.\n",
    "        self.seed_generator = keras.random.SeedGenerator(1337)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Use `keras.random` for random ops.\n",
    "        return keras.random.dropout(inputs, self.rate, seed=self.seed_generator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Next, let's write a custom subclassed model that uses our two custom layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "class MyModel(keras.Model):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv_base = keras.Sequential(\n",
    "            [\n",
    "                keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                keras.layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                keras.layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\"),\n",
    "                keras.layers.GlobalAveragePooling2D(),\n",
    "            ]\n",
    "        )\n",
    "        self.dp = MyDropout(0.5)\n",
    "        self.dense = MyDense(num_classes, activation=\"softmax\")\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv_base(x)\n",
    "        x = self.dp(x)\n",
    "        return self.dense(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Let's compile it and fit it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = MyModel(num_classes=10)\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    metrics=[\n",
    "        keras.metrics.SparseCategoricalAccuracy(name=\"acc\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=1,  # For speed\n",
    "    validation_split=0.15,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Training models on arbitrary data sources\n",
    "\n",
    "All Keras models can be trained and evaluated on a wide variety of data sources,\n",
    "independently of the backend you're using. This includes:\n",
    "\n",
    "- NumPy arrays\n",
    "- Pandas dataframes\n",
    "- TensorFlow `tf.data.Dataset` objects\n",
    "- PyTorch `DataLoader` objects\n",
    "- Keras `PyDataset` objects\n",
    "\n",
    "They all work whether you're using TensorFlow, JAX, or PyTorch as your Keras backend.\n",
    "\n",
    "Let's try it out with PyTorch `DataLoaders`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Create a TensorDataset\n",
    "train_torch_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.from_numpy(x_train), torch.from_numpy(y_train)\n",
    ")\n",
    "val_torch_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.from_numpy(x_test), torch.from_numpy(y_test)\n",
    ")\n",
    "\n",
    "# Create a DataLoader\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_torch_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_torch_dataset, batch_size=batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "model = MyModel(num_classes=10)\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    metrics=[\n",
    "        keras.metrics.SparseCategoricalAccuracy(name=\"acc\"),\n",
    "    ],\n",
    ")\n",
    "model.fit(train_dataloader, epochs=1, validation_data=val_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Now let's try this out with `tf.data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    .batch(batch_size)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "test_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    .batch(batch_size)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "model = MyModel(num_classes=10)\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    metrics=[\n",
    "        keras.metrics.SparseCategoricalAccuracy(name=\"acc\"),\n",
    "    ],\n",
    ")\n",
    "model.fit(train_dataset, epochs=1, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Further reading\n",
    "\n",
    "This concludes our short overview of the new multi-backend capabilities\n",
    "of Keras 3. Next, you can learn about:\n",
    "\n",
    "### How to customize what happens in `fit()`\n",
    "\n",
    "Want to implement a non-standard training algorithm yourself but still want to benefit from\n",
    "the power and usability of `fit()`? It's easy to customize\n",
    "`fit()` to support arbitrary use cases:\n",
    "\n",
    "- [Customizing what happens in `fit()` with TensorFlow](http://keras.io/guides/custom_train_step_in_tensorflow/)\n",
    "- [Customizing what happens in `fit()` with JAX](http://keras.io/guides/custom_train_step_in_jax/)\n",
    "- [Customizing what happens in `fit()` with PyTorch](http://keras.io/guides/custom_train_step_in_torch/)\n",
    "\n",
    "## How to write custom training loops\n",
    "\n",
    "- [Writing a training loop from scratch in TensorFlow](http://keras.io/guides/writing_a_custom_training_loop_in_tensorflow/)\n",
    "- [Writing a training loop from scratch in JAX](http://keras.io/guides/writing_a_custom_training_loop_in_jax/)\n",
    "- [Writing a training loop from scratch in PyTorch](http://keras.io/guides/writing_a_custom_training_loop_in_torch/)\n",
    "\n",
    "## How to distribute training\n",
    "\n",
    "- [Guide to distributed training with TensorFlow](http://keras.io/guides/distributed_training_with_tensorflow/)\n",
    "- [JAX distributed training example](https://github.com/keras-team/keras/blob/master/examples/demo_jax_distributed.py)\n",
    "- [PyTorch distributed training example](https://github.com/keras-team/keras/blob/master/examples/demo_torch_multi_gpu.py)\n",
    "\n",
    "Enjoy the library! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "intro_to_keras_for_engineers",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
