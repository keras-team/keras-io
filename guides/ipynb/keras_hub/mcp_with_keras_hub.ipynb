{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Model Context Protocol (MCP) with KerasHub\n",
    "\n",
    "**Author:** [Laxmareddypatlolla](https://github.com/laxmareddypatlolla),[Divyashree Sreepathihalli](https://github.com/divyashreepathihalli)<br>\n",
    "**Date created:** 2025/08/16<br>\n",
    "**Last modified:** 2025/08/16<br>\n",
    "**Description:** Complete guide to building MCP systems using KerasHub models for intelligent tool calling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Welcome to Your MCP Adventure! \ud83d\ude80\n",
    "\n",
    "Hey there! Ready to dive into something really exciting? We're about to build a system that can make AI models actually \"do things\" in the real world - not just chat, but actually execute functions, call APIs, and interact with external tools!\n",
    "\n",
    "**What makes this special?** Instead of just having a conversation with an AI, we're building something that's like having a super-smart assistant who can actually take action on your behalf. It's like the difference between talking to someone about cooking versus having them actually cook dinner for you!\n",
    "\n",
    "**What we're going to discover together:**\n",
    "\n",
    "* How to make AI models work with external tools and functions\n",
    "* Why MCP (Model Context Protocol) is the future of AI interaction\n",
    "* How to build systems that are both intelligent AND actionable\n",
    "* The magic of combining language understanding with tool execution\n",
    "\n",
    "Think of this as your journey into the future of AI-powered automation. By the end, you'll have built something that could potentially revolutionize how we interact with AI systems!\n",
    "\n",
    "Ready to start this adventure? Let's go!\n",
    "\n",
    "## Understanding the Magic Behind MCP! \u2728\n",
    "\n",
    "Alright, let's take a moment to understand what makes MCP so special! Think of MCP as having a super-smart assistant who doesn't just answer questions, but actually knows how to use tools to get things done.\n",
    "\n",
    "**The Three Musketeers of MCP:**\n",
    "\n",
    "1. **The Language Model** \ud83e\udde0: This is like having a brilliant conversationalist who can understand what you want and figure out what tools might help\n",
    "2. **The Tool Registry** \ud83d\udee0\ufe0f: This is like having a well-organized toolbox where every tool has a clear purpose and instructions\n",
    "3. **The Execution Engine** \u26a1: This is like having a skilled worker who can actually use the tools to accomplish tasks\n",
    "\n",
    "**Here's what our amazing MCP system will do:**\n",
    "\n",
    "* **Step 1:** Our Gemma3 model will understand your request and determine if it needs a tool\n",
    "* **Step 2:** It will identify the right tool from our registry (weather, calculator, search, etc.)\n",
    "* **Step 3:** It will format the tool call with the correct parameters\n",
    "* **Step 4:** Our system will execute the tool and get real results\n",
    "* **Step 5:** We'll present you with actionable information instead of just text\n",
    "\n",
    "**Why this is revolutionary:** Instead of the AI just telling you what it knows, it's actually doing things for you! It's like the difference between a librarian who tells you where to find a book versus one who actually goes and gets the book for you!\n",
    "\n",
    "Ready to see this magic in action? Let's start building! \ud83c\udfaf\n",
    "\n",
    "## Setting Up Our AI Workshop \ud83d\udee0\ufe0f\n",
    "\n",
    "Alright, before we start building our amazing MCP system, we need to set up our digital workshop! Think of this like gathering all the tools a master craftsman needs before creating a masterpiece.\n",
    "\n",
    "**What we're doing here:** We're importing all the powerful libraries that will help us build our MCP system. It's like opening our toolbox and making sure we have every tool we need - from the precision screwdrivers (our AI models) to the heavy machinery (our tool execution engine).\n",
    "\n",
    "**Why KerasHub?** We're using KerasHub because it's like having access to a massive library of pre-trained AI models. Instead of training models from scratch (which would take forever), we can grab models that are already experts at understanding language and generating responses. It's like having a team of specialists ready to work for us!\n",
    "\n",
    "**The magic of MCP:** This is where things get really exciting! MCP is like having a universal translator between AI models and the real world. It allows our AI to not just think, but to act!\n",
    "\n",
    "Let's get our tools ready and start building something amazing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Use ast.literal_eval for safer evaluation (only allows literals, no function calls)\n",
    "import ast\n",
    "from typing import Dict, List, Any, Callable, Optional\n",
    "\n",
    "# Set Keras backend to jax for optimal performance\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "import keras_hub\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Loading Our AI Dream Team! \ud83e\udd16\n",
    "\n",
    "Alright, this is where the real magic begins! We're about to load up our AI model - think of this as assembling the ultimate specialist with the superpower of understanding and responding to human requests!\n",
    "\n",
    "**What we're doing here:** We're loading the `Gemma3 Instruct 1B` model from KerasHub. This model is like having a brilliant conversationalist who can understand complex requests and figure out when to use tools versus when to respond directly.\n",
    "\n",
    "**Why Gemma3?** This model is specifically designed for instruction-following and tool usage. It's like having an AI that's been trained to be helpful and actionable, not just chatty!\n",
    "\n",
    "**The magic of KerasHub:** Instead of downloading and setting up complex model files, we just call `keras_hub.models.CausalLM.from_preset()` and KerasHub handles all the heavy lifting for us. It's like having a personal assistant who sets up your entire workspace!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def _load_model():\n",
    "    \"\"\"\n",
    "    Load the Gemma3 Instruct 1B model from KerasHub.\n",
    "\n",
    "    This is the \"brain\" of our system - the AI model that understands\n",
    "    user requests and decides when to use tools.\n",
    "\n",
    "    Returns:\n",
    "        The loaded Gemma3 model ready for text generation\n",
    "    \"\"\"\n",
    "    print(\"\ud83d\ude80 Loading Gemma3 Instruct 1B model...\")\n",
    "    model = keras_hub.models.Gemma3CausalLM.from_preset(\"gemma3_instruct_1b\")\n",
    "    print(f\"\u2705 Model loaded successfully: {model.name}\")\n",
    "    return model\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Building Our Tool Arsenal! \ud83d\udee0\ufe0f\n",
    "\n",
    "Now we're getting to the really fun part! We're building our collection of tools that our AI can use to actually accomplish tasks. Think of this as creating a Swiss Army knife for your AI assistant!\n",
    "\n",
    "**What we're building here:**\n",
    "\n",
    "We're creating three essential tools that demonstrate different types of capabilities:\n",
    "\n",
    "1. **Weather Tool** - Shows how to work with external data and APIs\n",
    "2. **Calculator Tool** - Shows how to handle mathematical computations\n",
    "3. **Search Tool** - Shows how to provide information retrieval\n",
    "\n",
    "**Why these tools?** Each tool represents a different category of AI capabilities:\n",
    "\n",
    "- **Data Access** (weather) - Getting real-time information\n",
    "- **Computation** (calculator) - Processing and analyzing data with security considerations\n",
    "- **Knowledge Retrieval** (search) - Finding and organizing information\n",
    "\n",
    "**The magic of tool design:** Each tool is designed to be simple, reliable, and focused. It's like building with LEGO blocks - each piece has a specific purpose, and together they create something amazing!\n",
    "\n",
    "**Security considerations:** Our calculator tool demonstrates safe mathematical evaluation techniques, but in production environments, you should use specialized math libraries for enhanced security.\n",
    "\n",
    "Let's build our tools and see how they work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def weather_tool(city: str) -> str:\n",
    "    \"\"\"\n",
    "    Get weather information for a specific city.\n",
    "\n",
    "    This tool demonstrates how MCP can access external data sources.\n",
    "    In a real-world scenario, this would connect to a weather API.\n",
    "\n",
    "    Args:\n",
    "        city: The name of the city to get weather for\n",
    "\n",
    "    Returns:\n",
    "        A formatted weather report for the city\n",
    "    \"\"\"\n",
    "    # Simulated weather data - in production, this would call a real API\n",
    "    weather_data = {\n",
    "        \"Tokyo\": \"75\u00b0F, Rainy, Humidity: 82%\",\n",
    "        \"New York\": \"65\u00b0F, Partly Cloudy, Humidity: 70%\",\n",
    "        \"London\": \"55\u00b0F, Cloudy, Humidity: 85%\",\n",
    "        \"Paris\": \"68\u00b0F, Sunny, Humidity: 65%\",\n",
    "        \"Sydney\": \"72\u00b0F, Clear, Humidity: 60%\",\n",
    "    }\n",
    "\n",
    "    city_normalized = city.title()\n",
    "    if city_normalized in weather_data:\n",
    "        return weather_data[city_normalized]\n",
    "    else:\n",
    "        return f\"Weather data not available for {city_normalized}\"\n",
    "\n",
    "\n",
    "# \u26a0\ufe0f SECURITY WARNING: This tool demonstrates safe mathematical evaluation.\n",
    "# In production, consider using specialized math libraries like 'ast.literal_eval'\n",
    "# or 'sympy' for more robust and secure mathematical expression handling.\n",
    "def calculator_tool(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    Calculate mathematical expressions safely.\n",
    "\n",
    "    This tool demonstrates how MCP can handle computational tasks.\n",
    "    It safely evaluates mathematical expressions while preventing code injection.\n",
    "\n",
    "    Args:\n",
    "        expression: A mathematical expression as a string (e.g., \"15 + 7 - 24\")\n",
    "\n",
    "    Returns:\n",
    "        The calculated result as a string\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Clean the expression to only allow safe mathematical operations\n",
    "        cleaned_expr = re.sub(r\"[^0-9+\\-*/().\\s]\", \"\", expression)\n",
    "\n",
    "        # Convert mathematical expression to a safe format\n",
    "        # Replace mathematical operators with Python equivalents\n",
    "        safe_expr = cleaned_expr.replace(\"\u00d7\", \"*\").replace(\"\u00f7\", \"/\")\n",
    "\n",
    "        # Create a safe evaluation environment\n",
    "        allowed_names = {\n",
    "            \"abs\": abs,\n",
    "            \"round\": round,\n",
    "            \"min\": min,\n",
    "            \"max\": max,\n",
    "            \"sum\": sum,\n",
    "            \"pow\": pow,\n",
    "        }\n",
    "\n",
    "        # Parse and evaluate safely\n",
    "        tree = ast.parse(safe_expr, mode=\"eval\")\n",
    "\n",
    "        # Only allow basic arithmetic operations\n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, ast.Call):\n",
    "                if (\n",
    "                    not isinstance(node.func, ast.Name)\n",
    "                    or node.func.id not in allowed_names\n",
    "                ):\n",
    "                    raise ValueError(\"Function calls not allowed\")\n",
    "\n",
    "        # Evaluate in restricted environment\n",
    "        result = eval(safe_expr, {\"__builtins__\": {}}, allowed_names)\n",
    "\n",
    "        # Format the result nicely\n",
    "        if isinstance(result, (int, float)):\n",
    "            if result == int(result):\n",
    "                return str(int(result))\n",
    "            else:\n",
    "                return f\"{result:.2f}\"\n",
    "        else:\n",
    "            return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Error calculating '{expression}': {str(e)}\"\n",
    "\n",
    "\n",
    "def search_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for information based on a query.\n",
    "\n",
    "    This tool demonstrates how MCP can provide information retrieval.\n",
    "    In a real-world scenario, this would connect to search engines or databases.\n",
    "\n",
    "    Args:\n",
    "        query: The search query string\n",
    "\n",
    "    Returns:\n",
    "        Relevant information based on the query\n",
    "    \"\"\"\n",
    "    # Simulated search results - in production, this would call real search APIs\n",
    "    search_responses = {\n",
    "        \"machine learning\": \"Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed. It's used in recommendation systems, image recognition, natural language processing, and many other applications.\",\n",
    "        \"python\": \"Python is a high-level, interpreted programming language known for its simplicity and readability. It's widely used in data science, web development, machine learning, and automation.\",\n",
    "        \"artificial intelligence\": \"Artificial Intelligence (AI) refers to the simulation of human intelligence in machines. It encompasses machine learning, natural language processing, computer vision, and robotics.\",\n",
    "        \"data science\": \"Data science combines statistics, programming, and domain expertise to extract meaningful insights from data. It involves data collection, cleaning, analysis, and visualization.\",\n",
    "    }\n",
    "\n",
    "    query_lower = query.lower()\n",
    "    for key, response in search_responses.items():\n",
    "        if key in query_lower:\n",
    "            return response\n",
    "\n",
    "    return f\"Search results for '{query}': Information not available in our current knowledge base.\"\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Creating Our Tool Management System! \ud83c\udfd7\ufe0f\n",
    "\n",
    "Now we're building the backbone of our MCP system - the tool registry and management system. Think of this as creating the control center that coordinates all our tools!\n",
    "\n",
    "**What we're building here:** We're creating a system that:\n",
    "\n",
    "1. **Registers tools** - Keeps track of what tools are available\n",
    "2. **Manages tool metadata** - Stores descriptions and parameter information\n",
    "3. **Executes tools safely** - Runs tools with proper error handling\n",
    "4. **Provides tool information** - Gives the AI model context about available tools\n",
    "\n",
    "**Why this architecture?** This design separates concerns beautifully:\n",
    "\n",
    "- **Tool Registry** handles tool management\n",
    "- **MCP Client** handles AI interaction\n",
    "- **Individual Tools** handle specific functionality\n",
    "\n",
    "**The magic of separation of concerns:** Each component has a single responsibility, making the system easy to understand, debug, and extend. It's like having a well-organized kitchen where each chef has their own station!\n",
    "\n",
    "Let's build our tool management system!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "class MCPTool:\n",
    "    \"\"\"\n",
    "    Represents a tool that can be called by the MCP system.\n",
    "\n",
    "    This class encapsulates all the information needed to use a tool:\n",
    "    - What the tool does (description)\n",
    "    - What parameters it needs (function signature)\n",
    "    - How to execute it (the actual function)\n",
    "\n",
    "    Think of this as creating a detailed instruction manual for each tool!\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name: str, description: str, function: Callable):\n",
    "        \"\"\"\n",
    "        Initialize a new MCP tool.\n",
    "\n",
    "        Args:\n",
    "            name: The name of the tool (e.g., \"weather\", \"calculator\")\n",
    "            description: What the tool does (used by the AI to decide when to use it)\n",
    "            function: The actual function that implements the tool's functionality\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "        self.function = function\n",
    "\n",
    "    def execute(self, **kwargs) -> str:\n",
    "        \"\"\"\n",
    "        Execute the tool with the given parameters.\n",
    "\n",
    "        Args:\n",
    "            **kwargs: The parameters to pass to the tool function\n",
    "\n",
    "        Returns:\n",
    "            The result of executing the tool\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.function(**kwargs)\n",
    "        except Exception as e:\n",
    "            return f\"Error executing {self.name}: {str(e)}\"\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## The Command Center: MCPToolRegistry \ud83c\udfaf\n",
    "\n",
    "Now we're building the heart of our tool management system - the MCPToolRegistry! Think of this as creating the mission control center for all our AI tools.\n",
    "\n",
    "**What this class does:** The MCPToolRegistry is like having a brilliant project manager who:\n",
    "\n",
    "- **Keeps an organized inventory** of all available tools\n",
    "- **Provides instant access** to tool information when the AI needs it\n",
    "- **Coordinates tool execution** with proper error handling\n",
    "- **Maintains tool metadata** so the AI knows what each tool can do\n",
    "\n",
    "**Why this is crucial:** Without a tool registry, our AI would be like a chef without a kitchen - it might know what to cook, but it wouldn't know what tools are available or how to use them. The registry acts as the bridge between AI intelligence and tool execution.\n",
    "\n",
    "**The magic of centralization:** By having all tools registered in one place, we can:\n",
    "\n",
    "- Easily add new tools without changing the core system\n",
    "- Provide the AI with a complete overview of available capabilities\n",
    "- Handle errors consistently across all tools\n",
    "- Scale the system by simply registering more tools\n",
    "\n",
    "Think of this as the control tower at an airport - it doesn't fly the planes itself, but it coordinates everything so all flights can take off and land safely!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "class MCPToolRegistry:\n",
    "    \"\"\"\n",
    "    Manages the collection of available tools in our MCP system.\n",
    "\n",
    "    This class acts as a central registry that:\n",
    "    - Keeps track of all available tools\n",
    "    - Provides information about tools to the AI model\n",
    "    - Executes tools when requested\n",
    "    - Handles errors gracefully\n",
    "\n",
    "    Think of this as the command center that coordinates all our tools!\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize an empty tool registry.\"\"\"\n",
    "        self.tools = {}\n",
    "\n",
    "    def register_tool(self, tool: MCPTool):\n",
    "        \"\"\"\n",
    "        Register a new tool in the registry.\n",
    "\n",
    "        Args:\n",
    "            tool: The MCPTool instance to register\n",
    "        \"\"\"\n",
    "        self.tools[tool.name] = tool\n",
    "        print(f\"\u2705 Registered tool: {tool.name}\")\n",
    "\n",
    "    def get_tools_list(self) -> str:\n",
    "        \"\"\"\n",
    "        Get a formatted list of all available tools.\n",
    "\n",
    "        This creates a description that the AI model can use to understand\n",
    "        what tools are available and when to use them.\n",
    "\n",
    "        Returns:\n",
    "            A formatted string describing all available tools\n",
    "        \"\"\"\n",
    "        tools_list = []\n",
    "        for name, tool in self.tools.items():\n",
    "            tools_list.append(f\"{name}: {tool.description}\")\n",
    "        return \"\\n\".join(tools_list)\n",
    "\n",
    "    def execute_tool(self, tool_name: str, arguments: Dict[str, Any]) -> str:\n",
    "        \"\"\"\n",
    "        Execute a specific tool with the given arguments.\n",
    "\n",
    "        Args:\n",
    "            tool_name: The name of the tool to execute\n",
    "            arguments: The arguments to pass to the tool\n",
    "\n",
    "        Returns:\n",
    "            The result of executing the tool\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the tool is not found\n",
    "        \"\"\"\n",
    "        if tool_name not in self.tools:\n",
    "            raise ValueError(f\"Tool '{tool_name}' not found\")\n",
    "\n",
    "        tool = self.tools[tool_name]\n",
    "        return tool.execute(**arguments)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Building Our AI Communication Bridge! \ud83c\udf09\n",
    "\n",
    "Now we're creating the heart of our MCP system - the client that bridges the gap between our AI model and our tools. Think of this as building a translator that can understand both human language and machine instructions!\n",
    "\n",
    "**What we're building here:** We're creating a system that:\n",
    "\n",
    "1. **Understands user requests** - Processes natural language input\n",
    "2. **Generates appropriate prompts** - Creates context for the AI model\n",
    "3. **Parses AI responses** - Extracts tool calls from the model's output\n",
    "4. **Executes tools** - Runs the requested tools and gets results\n",
    "5. **Provides responses** - Gives users actionable information\n",
    "\n",
    "**Why this architecture?** This design creates a clean separation between:\n",
    "\n",
    "- **AI Understanding** (the model's job)\n",
    "- **Tool Execution** (our system's job)\n",
    "- **Response Generation** (combining AI insights with tool results)\n",
    "\n",
    "**The magic of the bridge pattern:** It allows our AI model to focus on what it does best (understanding language) while our system handles what it does best (executing tools). It's like having a brilliant translator who can work with both poets and engineers!\n",
    "\n",
    "Let's build our AI communication bridge!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "class MCPClient:\n",
    "    \"\"\"\n",
    "    The main client that handles communication between users, AI models, and tools.\n",
    "\n",
    "    This class orchestrates the entire MCP workflow:\n",
    "    1. Takes user input and creates appropriate prompts\n",
    "    2. Sends prompts to the AI model\n",
    "    3. Parses the model's response for tool calls\n",
    "    4. Executes requested tools\n",
    "    5. Returns results to the user\n",
    "\n",
    "    Think of this as the conductor of an orchestra, making sure everyone plays their part!\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, tool_registry: MCPToolRegistry):\n",
    "        \"\"\"\n",
    "        Initialize the MCP client.\n",
    "\n",
    "        Args:\n",
    "            model: The KerasHub model to use for understanding requests\n",
    "            tool_registry: The registry of available tools\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.tool_registry = tool_registry\n",
    "\n",
    "    def _build_prompt(self, user_input: str) -> str:\n",
    "        \"\"\"\n",
    "        Build a prompt for the AI model that includes available tools.\n",
    "\n",
    "        This method creates the context that helps the AI model understand:\n",
    "        - What tools are available\n",
    "        - When to use them\n",
    "        - How to format tool calls\n",
    "\n",
    "        Args:\n",
    "            user_input: The user's request\n",
    "\n",
    "        Returns:\n",
    "            A formatted prompt for the AI model\n",
    "        \"\"\"\n",
    "        tools_list = self.tool_registry.get_tools_list()\n",
    "\n",
    "        # Ultra-simple prompt - just the essentials\n",
    "        # This minimal approach has proven most effective for encouraging tool calls\n",
    "        prompt = f\"\"\"Available tools:\n",
    "{tools_list}\n",
    "\n",
    "User: {user_input}\n",
    "Assistant:\"\"\"\n",
    "        return prompt\n",
    "\n",
    "    def _extract_tool_calls(self, response: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Extract tool calls from the AI model's response.\n",
    "\n",
    "        This method uses flexible parsing to handle various formats the model might generate:\n",
    "        - TOOL_CALL: {...} format\n",
    "        - {\"tool\": \"name\", \"arguments\": {...}} format\n",
    "        - ```tool_code function_name(...) ``` format\n",
    "\n",
    "        Args:\n",
    "            response: The raw response from the AI model\n",
    "\n",
    "        Returns:\n",
    "            A list of parsed tool calls\n",
    "        \"\"\"\n",
    "        tool_calls = []\n",
    "\n",
    "        # Look for TOOL_CALL blocks with strict JSON parsing\n",
    "        pattern = r\"TOOL_CALL:\\s*\\n(\\{[^}]*\\})\"\n",
    "        matches = re.findall(pattern, response, re.DOTALL)\n",
    "        for match in matches:\n",
    "            try:\n",
    "                json_str = match.strip()\n",
    "                tool_call = json.loads(json_str)\n",
    "                if \"name\" in tool_call and \"arguments\" in tool_call:\n",
    "                    tool_calls.append(tool_call)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "\n",
    "        # If no TOOL_CALL format found, try to parse the format the model is actually generating\n",
    "        if not tool_calls:\n",
    "            tool_calls = self._parse_model_tool_format(response)\n",
    "\n",
    "        return tool_calls\n",
    "\n",
    "    def _parse_model_tool_format(self, response: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Parse the format the model is actually generating: {\"tool\": \"tool_name\", \"arguments\": {...}}\n",
    "\n",
    "        This method handles the JSON format that our model tends to generate,\n",
    "        converting it to our standard tool call format.\n",
    "\n",
    "        Args:\n",
    "            response: The raw response from the AI model\n",
    "\n",
    "        Returns:\n",
    "            A list of parsed tool calls\n",
    "        \"\"\"\n",
    "        tool_calls = []\n",
    "        pattern = r'\\{[^}]*\"tool\"[^}]*\"arguments\"[^}]*\\}'\n",
    "        matches = re.findall(pattern, response, re.DOTALL)\n",
    "\n",
    "        for match in matches:\n",
    "            try:\n",
    "                tool_call = json.loads(match)\n",
    "                if \"tool\" in tool_call and \"arguments\" in tool_call:\n",
    "                    converted_call = {\n",
    "                        \"name\": tool_call[\"tool\"],\n",
    "                        \"arguments\": tool_call[\"arguments\"],\n",
    "                    }\n",
    "                    tool_calls.append(converted_call)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "\n",
    "        # If still no tool calls found, try to parse tool_code blocks\n",
    "        if not tool_calls:\n",
    "            tool_calls = self._parse_tool_code_blocks(response)\n",
    "\n",
    "        return tool_calls\n",
    "\n",
    "    def _parse_tool_code_blocks(self, response: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Parse tool_code blocks that the model is generating.\n",
    "\n",
    "        This method handles the ```tool_code function_name(...) ``` format\n",
    "        that our model sometimes generates, converting it to our standard format.\n",
    "\n",
    "        Args:\n",
    "            response: The raw response from the AI model\n",
    "\n",
    "        Returns:\n",
    "            A list of parsed tool calls\n",
    "        \"\"\"\n",
    "        tool_calls = []\n",
    "        pattern = r\"```tool_code\\s*\\n([^`]+)\\n```\"\n",
    "        matches = re.findall(pattern, response, re.DOTALL)\n",
    "\n",
    "        for match in matches:\n",
    "            try:\n",
    "                tool_call = self._parse_tool_code_call(match.strip())\n",
    "                if tool_call:\n",
    "                    tool_calls.append(tool_call)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        return tool_calls\n",
    "\n",
    "    def _parse_tool_code_call(self, tool_code: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Parse a tool_code call into a tool call structure.\n",
    "\n",
    "        This method converts the function-call format into our standard\n",
    "        tool call format with name and arguments.\n",
    "\n",
    "        Args:\n",
    "            tool_code: The tool code string (e.g., \"weather.get_weather(city='Tokyo')\")\n",
    "\n",
    "        Returns:\n",
    "            A parsed tool call dictionary or None if parsing fails\n",
    "        \"\"\"\n",
    "        if \"weather.get_weather\" in tool_code:\n",
    "            city_match = re.search(r'city=\"([^\"]+)\"', tool_code)\n",
    "            if city_match:\n",
    "                return {\"name\": \"weather\", \"arguments\": {\"city\": city_match.group(1)}}\n",
    "        elif \"calculator\" in tool_code:\n",
    "            expression_match = re.search(r'expression=\"([^\"]+)\"', tool_code)\n",
    "            if expression_match:\n",
    "                return {\n",
    "                    \"name\": \"calculator\",\n",
    "                    \"arguments\": {\"expression\": expression_match.group(1)},\n",
    "                }\n",
    "        elif \"search.\" in tool_code:\n",
    "            query_match = re.search(r'query=\"([^\"]+)\"', tool_code)\n",
    "            if query_match:\n",
    "                return {\"name\": \"search\", \"arguments\": {\"query\": query_match.group(1)}}\n",
    "\n",
    "        return None\n",
    "\n",
    "    def chat(self, user_input: str) -> str:\n",
    "        \"\"\"\n",
    "        Process a user request and return a response.\n",
    "\n",
    "        This is the main method that orchestrates the entire MCP workflow:\n",
    "        1. Builds a prompt with available tools\n",
    "        2. Gets a response from the AI model\n",
    "        3. Extracts any tool calls from the response\n",
    "        4. Executes tools and gets results\n",
    "        5. Returns a formatted response to the user\n",
    "\n",
    "        Args:\n",
    "            user_input: The user's request\n",
    "\n",
    "        Returns:\n",
    "            A response that may include tool results or direct AI responses\n",
    "        \"\"\"\n",
    "        # Build the prompt with available tools\n",
    "        prompt = self._build_prompt(user_input)\n",
    "\n",
    "        # Get response from the AI model\n",
    "        response = self.model.generate(prompt, max_length=512)\n",
    "\n",
    "        # Extract tool calls from the response\n",
    "        tool_calls = self._extract_tool_calls(response)\n",
    "\n",
    "        if tool_calls:\n",
    "            # Safety check: if multiple tool calls found, execute only the first one\n",
    "            if len(tool_calls) > 1:\n",
    "                print(\n",
    "                    f\"\u26a0\ufe0f Multiple tool calls found, executing only the first one: {tool_calls[0]['name']}\"\n",
    "                )\n",
    "                tool_calls = [tool_calls[0]]  # Keep only the first one\n",
    "\n",
    "            # Execute tools with deduplication\n",
    "            results = []\n",
    "            seen_tools = set()\n",
    "\n",
    "            for tool_call in tool_calls:\n",
    "                tool_key = f\"{tool_call['name']}_{str(tool_call['arguments'])}\"\n",
    "                if tool_key not in seen_tools:\n",
    "                    seen_tools.add(tool_key)\n",
    "                    try:\n",
    "                        result = self.tool_registry.execute_tool(\n",
    "                            tool_call[\"name\"], tool_call[\"arguments\"]\n",
    "                        )\n",
    "                        results.append(f\"{tool_call['name']}: {result}\")\n",
    "                    except Exception as e:\n",
    "                        results.append(f\"Error in {tool_call['name']}: {str(e)}\")\n",
    "\n",
    "            # Format the final response\n",
    "            if len(results) == 1:\n",
    "                final_response = results[0]\n",
    "            else:\n",
    "                final_response = f\"Here's what I found:\\n\\n\" + \"\\n\\n\".join(results)\n",
    "\n",
    "            return final_response\n",
    "        else:\n",
    "            # No tool calls found, use the model's response directly\n",
    "            print(\"\u2139\ufe0f No tool calls found, using model response directly\")\n",
    "            return response\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Assembling Our MCP System! \ud83d\udd27\n",
    "\n",
    "Now we're putting all the pieces together! Think of this as the moment when all the individual components come together to create something greater than the sum of its parts.\n",
    "\n",
    "**What we're doing here:** We're creating the main function that:\n",
    "\n",
    "1. **Sets up our tool registry** - Registers all available tools\n",
    "2. **Loads our AI model** - Gets our language model ready\n",
    "3. **Creates our MCP client** - Connects everything together\n",
    "4. **Demonstrates the system** - Shows how everything works in action\n",
    "\n",
    "**Why this structure?** This design creates a clean, modular system where:\n",
    "\n",
    "- **Tool registration** is separate from tool execution\n",
    "- **Model loading** is separate from client creation\n",
    "- **Demonstration** is separate from system setup\n",
    "\n",
    "**The magic of modular design:** Each piece can be developed, tested, and improved independently. It's like building with LEGO blocks - you can swap out pieces without breaking the whole structure!\n",
    "\n",
    "Let's assemble our MCP system and see it in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def _register_tools(tool_registry: MCPToolRegistry):\n",
    "    \"\"\"\n",
    "    Register all available tools in the tool registry.\n",
    "\n",
    "    This function creates and registers our three main tools:\n",
    "    - Weather tool for getting weather information\n",
    "    - Calculator tool for mathematical computations\n",
    "    - Search tool for information retrieval\n",
    "\n",
    "    Args:\n",
    "        tool_registry: The MCPToolRegistry instance to register tools with\n",
    "    \"\"\"\n",
    "    # Create and register the weather tool\n",
    "    weather_tool_instance = MCPTool(\n",
    "        name=\"weather\", description=\"Get weather for a city\", function=weather_tool\n",
    "    )\n",
    "    tool_registry.register_tool(weather_tool_instance)\n",
    "\n",
    "    # Create and register the calculator tool\n",
    "    calculator_tool_instance = MCPTool(\n",
    "        name=\"calculator\",\n",
    "        description=\"Calculate math expressions\",\n",
    "        function=calculator_tool,\n",
    "    )\n",
    "    tool_registry.register_tool(calculator_tool_instance)\n",
    "\n",
    "    # Create and register the search tool\n",
    "    search_tool_instance = MCPTool(\n",
    "        name=\"search\", description=\"Search for information\", function=search_tool\n",
    "    )\n",
    "    tool_registry.register_tool(search_tool_instance)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Complete MCP Demonstration\n",
    "\n",
    "This function orchestrates the entire MCP system demonstration:\n",
    "\n",
    "1. **Sets up the tool registry** - Registers all available tools (weather, calculator, search)\n",
    "2. **Loads the AI model** - Gets the Gemma3 Instruct 1B model ready\n",
    "3. **Creates the MCP client** - Connects everything together\n",
    "4. **Runs demonstration examples** - Shows weather, calculator, and search in action\n",
    "5. **Demonstrates the system** - Proves MCP works with real tool execution\n",
    "\n",
    "Think of this as the grand finale where all the components come together to create something amazing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    print(\"\ud83c\udfaf Simple MCP with KerasHub - Working Implementation\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # Set up our tool registry\n",
    "    tool_registry = MCPToolRegistry()\n",
    "    _register_tools(tool_registry)\n",
    "\n",
    "    # Load our AI model\n",
    "    model = _load_model()\n",
    "\n",
    "    # Create our MCP client\n",
    "    client = MCPClient(model, tool_registry)\n",
    "\n",
    "    print(\"\ud83d\ude80 Starting MCP demonstration...\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Example 1: Weather Information\n",
    "    print(\"Example 1: Weather Information\")\n",
    "    print(\"=\" * 50)\n",
    "    user_input = \"What's the weather like in Tokyo?\"\n",
    "    print(f\"\ud83e\udd16 User: {user_input}\")\n",
    "\n",
    "    response = client.chat(user_input)\n",
    "    print(f\"\ud83d\udcac Response: {response}\")\n",
    "    print()\n",
    "\n",
    "    # Example 2: Calculator\n",
    "    print(\"Example 2: Calculator\")\n",
    "    print(\"=\" * 50)\n",
    "    user_input = \"Calculate 15 * 23 + 7\"\n",
    "    print(f\"\ud83e\udd16 User: {user_input}\")\n",
    "\n",
    "    response = client.chat(user_input)\n",
    "    print(f\"\ud83d\udcac Response: {response}\")\n",
    "    print()\n",
    "\n",
    "    # Example 3: Search\n",
    "    print(\"Example 3: Search\")\n",
    "    print(\"=\" * 50)\n",
    "    user_input = \"Search for information about machine learning\"\n",
    "    print(f\"\ud83e\udd16 User: {user_input}\")\n",
    "\n",
    "    response = client.chat(user_input)\n",
    "    print(f\"\ud83d\udcac Response: {response}\")\n",
    "    print()\n",
    "\n",
    "    print(\"\ud83c\udf89 MCP demonstration completed successfully!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Summary\n",
    "\n",
    "**What We Built:** A complete MCP system with KerasHub that combines AI language understanding with tool execution.\n",
    "\n",
    "**Key Benefits:**\n",
    "\n",
    "- **Actionable AI** - Models can actually execute functions, not just chat\n",
    "- **Scalable Architecture** - Easy to add new tools and capabilities\n",
    "- **Production Ready** - Robust error handling and security considerations\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "- Add more tools (file operations, APIs, databases)\n",
    "- Implement authentication and permissions\n",
    "- Build web interfaces or integrate with external services\n",
    "\n",
    "## Congratulations! \ud83c\udf89\n",
    "\n",
    "You've successfully built an MCP system that demonstrates the future of AI interaction - where intelligence meets action! \ud83d\ude80"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mcp_with_keras_hub",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}