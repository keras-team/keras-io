{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Classification with KerasHub\n",
    "\n",
    "**Author:** [Gowtham Paimagam](https://github.com/gowthamkpr), [lukewood](https://lukewood.xyz)<br>\n",
    "**Date created:** 09/24/2024<br>\n",
    "**Last modified:** 10/04/2024<br>\n",
    "**Description:** Use KerasHub to train powerful image classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Classification is the process of predicting a categorical label for a given\n",
    "input image.\n",
    "While classification is a relatively straightforward computer vision task,\n",
    "modern approaches still are built of several complex components.\n",
    "Luckily, Keras provides APIs to construct commonly used components.\n",
    "\n",
    "This guide demonstrates KerasHub's modular approach to solving image\n",
    "classification problems at three levels of complexity:\n",
    "\n",
    "- Inference with a pretrained classifier\n",
    "- Fine-tuning a pretrained backbone\n",
    "- Training a image classifier from scratch\n",
    "\n",
    "KerasHub uses Keras 3 to work with any of TensorFlow, PyTorch or Jax. In the\n",
    "guide below, we will use the `jax` backend. This guide runs in\n",
    "TensorFlow or PyTorch backends with zero changes, simply update the\n",
    "`KERAS_BACKEND` below.\n",
    "\n",
    "We use Professor Keras, the official Keras mascot, as a\n",
    "visual reference for the complexity of the material:\n",
    "\n",
    "![](https://storage.googleapis.com/keras-nlp/getting_started_guide/prof_keras_evolution.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "!!pip install -q git+https://github.com/keras-team/keras-hub.git\n",
    "!!pip install -q --upgrade keras  # Upgrade to Keras 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # @param [\"tensorflow\", \"jax\", \"torch\"]\n",
    "\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras import losses\n",
    "from keras import ops\n",
    "from keras import optimizers\n",
    "from keras.optimizers import schedules\n",
    "from keras import metrics\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "import keras_hub\n",
    "\n",
    "# Import tensorflow for `tf.data` and its preprocessing functions\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Inference with a pretrained classifier\n",
    "\n",
    "![](https://storage.googleapis.com/keras-nlp/getting_started_guide/prof_keras_beginner.png)\n",
    "\n",
    "Let's get started with the simplest KerasHub API: a pretrained classifier.\n",
    "In this example, we will construct a classifier that was\n",
    "pretrained on the ImageNet dataset.\n",
    "We'll use this model to solve the age old \"Cat or Dog\" problem.\n",
    "\n",
    "The highest level module in KerasHub is a *task*. A *task* is a `keras.Model`\n",
    "consisting of a (generally pretrained) backbone model and task-specific layers.\n",
    "Here's an example using `keras_hub.models.ImageClassifier` with an\n",
    "ResNet Backbone.\n",
    "\n",
    "ResNet is a great starting model when constructing an image\n",
    "classification pipeline.\n",
    "This architecture manages to achieve high accuracy, while using a\n",
    "compact parameter count.\n",
    "If a ResNet is not powerful enough for the task you are hoping to\n",
    "solve, be sure to check out\n",
    "[KerasHub's other available Backbones](https://github.com/keras-team/keras-hub/tree/master/keras_hub/src/models)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "classifier = keras_hub.models.ImageClassifier.from_preset(\"resnet_v2_50_imagenet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "You may notice a small deviation from the old `keras.applications` API; where\n",
    "you would construct the class with `Resnet50V2(weights=\"imagenet\")`.\n",
    "While the old API was great for classification, it did not scale effectively to\n",
    "other use cases that required complex architectures, like object detection and\n",
    "semantic segmentation.\n",
    "\n",
    "We first create a utility function for plotting images throughout this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_image_gallery(images, titles=None, num_cols=3, figsize=(6, 12)):\n",
    "    num_images = len(images)\n",
    "    images = np.asarray(images) / 255.0\n",
    "    images = np.minimum(np.maximum(images, 0.0), 1.0)\n",
    "    num_rows = (num_images + num_cols - 1) // num_cols\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=figsize, squeeze=False)\n",
    "    axes = axes.flatten()  # Flatten in case the axes is a 2D array\n",
    "\n",
    "    for i, ax in enumerate(axes):\n",
    "        if i < num_images:\n",
    "            # Plot the image\n",
    "            ax.imshow(images[i])\n",
    "            ax.axis(\"off\")  # Remove axis\n",
    "            if titles and len(titles) > i:\n",
    "                ax.set_title(titles[i], fontsize=12)\n",
    "        else:\n",
    "            # Turn off the axis for any empty subplot\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Now that our classifier is built, let's apply it to this cute cat picture!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "filepath = keras.utils.get_file(\n",
    "    origin=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/49/5hR96puA_VA.jpg/1024px-5hR96puA_VA.jpg\"\n",
    ")\n",
    "image = keras.utils.load_img(filepath)\n",
    "image = np.array([image])\n",
    "plot_image_gallery(image, num_cols=1, figsize=(3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Next, let's get some predictions from our classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "predictions = classifier.predict(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Predictions come in the form of softmax-ed category rankings.\n",
    "We can use Keras' `imagenet_utils.decode_predictions` function to map\n",
    "them to class names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "print(f\"Top two classes are:\\n{decode_predictions(predictions, top=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Great!  Both of these appear to be correct!\n",
    "However, one of the classes is \"Bath towel\".\n",
    "We're trying to classify Cats VS Dogs.\n",
    "We don't care about the towel!\n",
    "\n",
    "Ideally, we'd have a classifier that only performs computation to determine if\n",
    "an image is a cat or a dog, and has all of its resources dedicated to this task.\n",
    "This can be solved by fine tuning our own classifier.\n",
    "\n",
    "## Fine tuning a pretrained classifier\n",
    "\n",
    "![](https://storage.googleapis.com/keras-nlp/getting_started_guide/prof_keras_intermediate.png)\n",
    "\n",
    "When labeled images specific to our task are available, fine-tuning a custom\n",
    "classifier can improve performance.\n",
    "If we want to train a Cats vs Dogs Classifier, using explicitly labeled Cat vs\n",
    "Dog data should perform better than the generic classifier!\n",
    "For many tasks, no relevant pretrained model\n",
    "will be available (e.g., categorizing images specific to your application).\n",
    "\n",
    "First, let's get started by loading some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = (224, 224)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "data, dataset_info = tfds.load(\"cats_vs_dogs\", with_info=True, as_supervised=True)\n",
    "train_steps_per_epoch = dataset_info.splits[\"train\"].num_examples // BATCH_SIZE\n",
    "train_dataset = data[\"train\"]\n",
    "\n",
    "num_classes = dataset_info.features[\"label\"].num_classes\n",
    "\n",
    "resizing = keras.layers.Resizing(\n",
    "    IMAGE_SIZE[0], IMAGE_SIZE[1], crop_to_aspect_ratio=True\n",
    ")\n",
    "\n",
    "\n",
    "def preprocess_inputs(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    # Staticly resize images as we only iterate the dataset once.\n",
    "    return resizing(image), tf.one_hot(label, num_classes)\n",
    "\n",
    "\n",
    "# Shuffle the dataset to increase diversity of batches.\n",
    "# 10*BATCH_SIZE follows the assumption that bigger machines can handle bigger\n",
    "# shuffle buffers.\n",
    "train_dataset = train_dataset.shuffle(\n",
    "    10 * BATCH_SIZE, reshuffle_each_iteration=True\n",
    ").map(preprocess_inputs, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "images = next(iter(train_dataset.take(1)))[0]\n",
    "plot_image_gallery(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Meow!\n",
    "\n",
    "Next let's construct our model.\n",
    "The use of imagenet in the preset name indicates that the backbone was\n",
    "pretrained on the ImageNet dataset.\n",
    "Pretrained backbones extract more information from our labeled examples by\n",
    "leveraging patterns extracted from potentially much larger datasets.\n",
    "\n",
    "Next lets put together our classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras_hub.models.ImageClassifier.from_preset(\n",
    "    \"resnet_v2_50_imagenet\", num_classes=2\n",
    ")\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.01),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Here our classifier is just a simple `keras.Sequential`.\n",
    "All that is left to do is call `model.fit()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.fit(train_dataset)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Let's look at how our model performs after the fine tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(image)\n",
    "\n",
    "classes = {0: \"cat\", 1: \"dog\"}\n",
    "print(\"Top class is:\", classes[predictions[0].argmax()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Awesome - looks like the model correctly classified the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Train a Classifier from Scratch\n",
    "\n",
    "![](https://storage.googleapis.com/keras-nlp/getting_started_guide/prof_keras_advanced.png)\n",
    "\n",
    "Now that we've gotten our hands dirty with classification, let's take on one\n",
    "last task: training a classification model from scratch!\n",
    "A standard benchmark for image classification is the ImageNet dataset, however\n",
    "due to licensing constraints we will use the CalTech 101 image classification\n",
    "dataset in this tutorial.\n",
    "While we use the simpler CalTech 101 dataset in this guide, the same training\n",
    "template may be used on ImageNet to achieve near state-of-the-art scores.\n",
    "\n",
    "Let's start out by tackling data loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 101\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "# Change epochs to 100~ to fully train.\n",
    "EPOCHS = 1\n",
    "\n",
    "\n",
    "def package_inputs(image, label):\n",
    "    return {\"images\": image, \"labels\": tf.one_hot(label, NUM_CLASSES)}\n",
    "\n",
    "\n",
    "train_ds, eval_ds = tfds.load(\n",
    "    \"caltech101\", split=[\"train\", \"test\"], as_supervised=\"true\"\n",
    ")\n",
    "train_ds = train_ds.map(package_inputs, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "eval_ds = eval_ds.map(package_inputs, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = train_ds.shuffle(BATCH_SIZE * 16)\n",
    "augmenters = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "The CalTech101 dataset has different sizes for every image, so we resize images before\n",
    "batching them using the\n",
    "`batch()` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "resize = keras.layers.Resizing(*IMAGE_SIZE, crop_to_aspect_ratio=True)\n",
    "train_ds = train_ds.map(resize)\n",
    "eval_ds = eval_ds.map(resize)\n",
    "\n",
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "eval_ds = eval_ds.batch(BATCH_SIZE)\n",
    "\n",
    "batch = next(iter(train_ds.take(1)))\n",
    "image_batch = batch[\"images\"]\n",
    "label_batch = batch[\"labels\"]\n",
    "\n",
    "plot_image_gallery(\n",
    "    image_batch,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Data Augmentation\n",
    "\n",
    "In our previous finetuning example, we performed a static resizing operation and\n",
    "did not utilize any image augmentation.\n",
    "This is because a single pass over the training set was sufficient to achieve\n",
    "decent results.\n",
    "When training to solve a more difficult task, you'll want to include data\n",
    "augmentation in your data pipeline.\n",
    "\n",
    "Data augmentation is a technique to make your model robust to changes in input\n",
    "data such as lighting, cropping, and orientation.\n",
    "Keras includes some of the most useful augmentations in the `keras.layers`\n",
    "API.\n",
    "Creating an optimal pipeline of augmentations is an art, but in this section of\n",
    "the guide we'll offer some tips on best practices for classification.\n",
    "\n",
    "One caveat to be aware of with image data augmentation is that you must be careful\n",
    "to not shift your augmented data distribution too far from the original data\n",
    "distribution.\n",
    "The goal is to prevent overfitting and increase generalization,\n",
    "but samples that lie completely out of the data distribution simply add noise to\n",
    "the training process.\n",
    "\n",
    "The first augmentation we'll use is `RandomFlip`.\n",
    "This augmentation behaves more or less how you'd expect: it either flips the\n",
    "image or not.\n",
    "While this augmentation is useful in CalTech101 and ImageNet, it should be noted\n",
    "that it should not be used on tasks where the data distribution is not vertical\n",
    "mirror invariant.\n",
    "An example of a dataset where this occurs is MNIST hand written digits.\n",
    "Flipping a `6` over the\n",
    "vertical axis will make the digit appear more like a `7` than a `6`, but the\n",
    "label will still show a `6`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "random_flip = keras.layers.RandomFlip()\n",
    "augmenters += [random_flip]\n",
    "\n",
    "image_batch = random_flip(image_batch)\n",
    "plot_image_gallery(image_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Half of the images have been flipped!\n",
    "\n",
    "The next augmentation we'll use is `RandomCrop`.\n",
    "This operation selects a random subset of the image.\n",
    "By using this augmentation, we force our classifier to become spatially invariant.\n",
    "\n",
    "Let's add a `RandomCrop` to our set of augmentations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "crop = keras.layers.RandomCrop(\n",
    "    int(IMAGE_SIZE[0] * 0.9),\n",
    "    int(IMAGE_SIZE[1] * 0.9),\n",
    ")\n",
    "\n",
    "augmenters += [crop]\n",
    "\n",
    "image_batch = crop(image_batch)\n",
    "plot_image_gallery(\n",
    "    image_batch,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "We can also rotate images by a random angle using Keras' `RandomRotation` layer. Let's\n",
    "apply a rotation by a randomly selected angle in the interval -45\u00b0...45\u00b0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "rotate = keras.layers.RandomRotation((-45 / 360, 45 / 360))\n",
    "\n",
    "augmenters += [rotate]\n",
    "\n",
    "image_batch = rotate(image_batch)\n",
    "plot_image_gallery(image_batch)\n",
    "\n",
    "resize = keras.layers.Resizing(*IMAGE_SIZE, crop_to_aspect_ratio=True)\n",
    "augmenters += [resize]\n",
    "\n",
    "image_batch = resize(image_batch)\n",
    "plot_image_gallery(image_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Now let's apply our final augmenter to the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_augmenter_fn(augmenters):\n",
    "    def augmenter_fn(inputs):\n",
    "        for augmenter in augmenters:\n",
    "            inputs[\"images\"] = augmenter(inputs[\"images\"])\n",
    "        return inputs\n",
    "\n",
    "    return augmenter_fn\n",
    "\n",
    "\n",
    "augmenter_fn = create_augmenter_fn(augmenters)\n",
    "train_ds = train_ds.map(augmenter_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "image_batch = next(iter(train_ds.take(1)))[\"images\"]\n",
    "plot_image_gallery(\n",
    "    image_batch,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "We also need to resize our evaluation set to get dense batches of the image size\n",
    "expected by our model. We directly use the deterministic `keras.layers.Resizing` in\n",
    "this case to avoid adding noise to our evaluation metric due to applying random\n",
    "augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inference_resizing = keras.layers.Resizing(*IMAGE_SIZE, crop_to_aspect_ratio=True)\n",
    "\n",
    "\n",
    "def do_resize(inputs):\n",
    "    inputs[\"images\"] = inference_resizing(inputs[\"images\"])\n",
    "    return inputs\n",
    "\n",
    "\n",
    "eval_ds = eval_ds.map(do_resize, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "image_batch = next(iter(eval_ds.take(1)))[\"images\"]\n",
    "plot_image_gallery(\n",
    "    image_batch,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Finally, lets unpackage our datasets and prepare to pass them to `model.fit()`,\n",
    "which accepts a tuple of `(images, labels)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def unpackage_dict(inputs):\n",
    "    return inputs[\"images\"], inputs[\"labels\"]\n",
    "\n",
    "\n",
    "train_ds = train_ds.map(unpackage_dict, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "eval_ds = eval_ds.map(unpackage_dict, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Data augmentation is by far the hardest piece of training a modern\n",
    "classifier.\n",
    "Congratulations on making it this far!\n",
    "\n",
    "### Optimizer Tuning\n",
    "\n",
    "To achieve optimal performance, we need to use a learning rate schedule instead\n",
    "of a single learning rate. While we won't go into detail on the Cosine decay\n",
    "with warmup schedule used here,\n",
    "[you can read more about it here](https://scorrea92.medium.com/cosine-learning-rate-decay-e8b50aa455b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def lr_warmup_cosine_decay(\n",
    "    global_step,\n",
    "    warmup_steps,\n",
    "    hold=0,\n",
    "    total_steps=0,\n",
    "    start_lr=0.0,\n",
    "    target_lr=1e-2,\n",
    "):\n",
    "    # Cosine decay\n",
    "    learning_rate = (\n",
    "        0.5\n",
    "        * target_lr\n",
    "        * (\n",
    "            1\n",
    "            + ops.cos(\n",
    "                math.pi\n",
    "                * ops.convert_to_tensor(\n",
    "                    global_step - warmup_steps - hold, dtype=\"float32\"\n",
    "                )\n",
    "                / ops.convert_to_tensor(\n",
    "                    total_steps - warmup_steps - hold, dtype=\"float32\"\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    warmup_lr = target_lr * (global_step / warmup_steps)\n",
    "\n",
    "    if hold > 0:\n",
    "        learning_rate = ops.where(\n",
    "            global_step > warmup_steps + hold, learning_rate, target_lr\n",
    "        )\n",
    "\n",
    "    learning_rate = ops.where(global_step < warmup_steps, warmup_lr, learning_rate)\n",
    "    return learning_rate\n",
    "\n",
    "\n",
    "class WarmUpCosineDecay(schedules.LearningRateSchedule):\n",
    "    def __init__(self, warmup_steps, total_steps, hold, start_lr=0.0, target_lr=1e-2):\n",
    "        super().__init__()\n",
    "        self.start_lr = start_lr\n",
    "        self.target_lr = target_lr\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.total_steps = total_steps\n",
    "        self.hold = hold\n",
    "\n",
    "    def __call__(self, step):\n",
    "        lr = lr_warmup_cosine_decay(\n",
    "            global_step=step,\n",
    "            total_steps=self.total_steps,\n",
    "            warmup_steps=self.warmup_steps,\n",
    "            start_lr=self.start_lr,\n",
    "            target_lr=self.target_lr,\n",
    "            hold=self.hold,\n",
    "        )\n",
    "        return ops.where(step > self.total_steps, 0.0, lr)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "![WarmUpCosineDecay schedule](https://i.imgur.com/YCr5pII.png)\n",
    "\n",
    "The schedule looks a as we expect.\n",
    "\n",
    "Next let's construct this optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "total_images = 9000\n",
    "total_steps = (total_images // BATCH_SIZE) * EPOCHS\n",
    "warmup_steps = int(0.1 * total_steps)\n",
    "hold_steps = int(0.45 * total_steps)\n",
    "schedule = WarmUpCosineDecay(\n",
    "    start_lr=0.05,\n",
    "    target_lr=1e-2,\n",
    "    warmup_steps=warmup_steps,\n",
    "    total_steps=total_steps,\n",
    "    hold=hold_steps,\n",
    ")\n",
    "optimizer = optimizers.SGD(\n",
    "    weight_decay=5e-4,\n",
    "    learning_rate=schedule,\n",
    "    momentum=0.9,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "At long last, we can now build our model and call `fit()`!\n",
    "Here, we directly instantiate our `ResNetBackbone`, specifying all architectural\n",
    "parameters, which gives us full control to tweak the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "backbone = keras_hub.models.ResNetBackbone(\n",
    "    input_conv_filters=[64],\n",
    "    input_conv_kernel_sizes=[7],\n",
    "    stackwise_num_filters=[64, 64, 64],\n",
    "    stackwise_num_blocks=[2, 2, 2],\n",
    "    stackwise_num_strides=[1, 2, 2],\n",
    "    block_type=\"basic_block\",\n",
    ")\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        backbone,\n",
    "        keras.layers.GlobalMaxPooling2D(),\n",
    "        keras.layers.Dropout(rate=0.5),\n",
    "        keras.layers.Dense(101, activation=\"softmax\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "We employ label smoothing to prevent the model from overfitting to artifacts of\n",
    "our augmentation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "loss = losses.CategoricalCrossentropy(label_smoothing=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Let's compile our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\n",
    "        metrics.CategoricalAccuracy(),\n",
    "        metrics.TopKCategoricalAccuracy(k=5),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "and finally call fit()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=eval_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Congratulations!  You now know how to train a powerful image classifier from\n",
    "scratch using KerasHub.\n",
    "Depending on the availability of labeled data for your application, training\n",
    "from scratch may or may not be more powerful than using transfer learning in\n",
    "addition to the data augmentations discussed above. For smaller datasets,\n",
    "pretrained models generally produce high accuracy and faster convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Conclusions\n",
    "\n",
    "While image classification is perhaps the simplest problem in computer vision,\n",
    "the modern landscape has numerous complex components.\n",
    "Luckily, KerasHub offers robust, production-grade APIs to make assembling most\n",
    "of these components possible in one line of code.\n",
    "Through the use of KerasHub's `ImageClassifier` API, pretrained weights, and\n",
    "Keras' data augmentations you can assemble everything you need to train a\n",
    "powerful classifier in a few hundred lines of code!\n",
    "\n",
    "As a follow up exercise, try fine tuning a KerasHub classifier on your own dataset!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "classification_with_keras_hub",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
