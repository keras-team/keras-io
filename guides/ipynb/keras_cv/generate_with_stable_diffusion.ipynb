{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Generate images using KerasCV's StableDiffusion's at unprecedented speeds\n",
    "\n",
    "**Author:** [fchollet](https://github.com/fchollet), [lukewood](https://lukewood.xyz), [divamgupta](https://github.com/divamgupta)<br>\n",
    "**Date created:** 2022/09/24<br>\n",
    "**Last modified:** 2022/09/24<br>\n",
    "**Description:** Generate new images using KerasCV's StableDiffusion model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Overview\n",
    "\n",
    "In this guide, we will show how to generate novel images based on a text prompt using\n",
    "the KerasCV implementation of [stability.ai's](https://stability.ai/) image to text\n",
    "model,\n",
    "[StableDiffusion](https://github.com/CompVis/stable-diffusion).\n",
    "\n",
    "StableDiffusion is a powerful, open-source text to image generation model.  While there\n",
    "exist numerous open source implementations that allow you to easily create images from\n",
    "textual prompts, KerasCV's offers a few distinct advantages.\n",
    "These include [XLA compilation](https://www.tensorflow.org/xla) and\n",
    "[mixed precision computation](https://www.tensorflow.org/guide/mixed_precision).\n",
    "\n",
    "In this guide, we will explore KerasCV's StableDiffusion implementation, show how to use\n",
    "these powerful performance boosts, and explore the performance benefits\n",
    "that they offer.\n",
    "\n",
    "To get started, let's install a few dependencies and sort out some imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import keras_cv\n",
    "from luketils import visualization\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import mixed_precision\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Unlike most tutorials, where we first explain a topic then show how to implement it,\n",
    "with text to image generation it is easiest to show instead of tell.\n",
    "\n",
    "Check out the power of `keras_cv.models.StableDiffusion()`.\n",
    "First, we construct a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "stable_diffusion = keras_cv.models.StableDiffusion(img_width=512, img_height=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Next, we give it a prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "images = stable_diffusion.text_to_image(\n",
    "    \"a cartoon caterpillar wearing glasses\", batch_size=3\n",
    ")\n",
    "\n",
    "visualization.plot_gallery(\n",
    "    images,\n",
    "    rows=1,\n",
    "    cols=3,\n",
    "    scale=4,\n",
    "    value_range=(0, 255),\n",
    "    show=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Pretty incredible!\n",
    "\n",
    "But that's not all this model can do.  Let's try a more complex prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def visualize_prompt(prompt, sd_model=None):\n",
    "    sd_model = sd_model or stable_diffusion\n",
    "    visualization.plot_gallery(\n",
    "        sd_model.text_to_image(prompt, batch_size=3),\n",
    "        rows=1,\n",
    "        cols=3,\n",
    "        scale=4,\n",
    "        value_range=(0, 255),\n",
    "        show=True,\n",
    "    )\n",
    "\n",
    "\n",
    "visualize_prompt(\n",
    "    \"a cute magical flying dog, fantasy art drawn by disney concept artists, \"\n",
    "    \"golden colour, high quality, highly detailed, elegant, sharp focus, \"\n",
    "    \"concept art, character concepts, digital painting, mystery, adventure\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "The possibilities are literally endless (or at least extend to the boundaries of\n",
    "StableDiffusion's latent manifold).\n",
    "\n",
    "Pretty incredible!  The idea should be self evident at this point.\n",
    "Now let's take a step back and look at how this algorithm actually works.\n",
    "\n",
    "## The StableDiffusion Algorithm\n",
    "\n",
    "TODO(fchollet): write this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Need to write up the actual algorithm and provide an overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Perks of KerasCV\n",
    "\n",
    "With numerous implementations of StableDiffusion publicly available why shoud you use\n",
    "`keras_cv.models.StableDiffusion()`?\n",
    "\n",
    "Aside from the easy-to-use API, KerasCV's StableDiffusion model comes with some nice\n",
    "bells and trinkets.  These extra features include but are not limited to:\n",
    "\n",
    "- XLA compilation through `jit_compile=True`\n",
    "- support for mixed precision computation\n",
    "- graph mode execution\n",
    "\n",
    "When these are combined, the KerasCV StableDiffusion model runs orders of magnitude\n",
    "faster than naive implementations.  This section shows how to enable all of these\n",
    "features, and the resulting performance gain yielded from using them.\n",
    "\n",
    "For the purposes of comparison, I ran benchmarks comparing the runtime of the\n",
    "[HuggingFace diffusers](https://github.com/huggingface/diffusers) implementation of\n",
    "StableDiffusion against the KerasCV implementation.\n",
    "Both implementations were tasked to generate 3 images with a step count of 50 for each\n",
    "image.  In this benchmark, I used a Tesla T4 GPU.\n",
    "\n",
    "\n",
    "[All of my benchmarks are open source on GitHub, and may be re-run on Colab to\n",
    "reproduce the results.](https://github.com/LukeWood/stable-diffusion-performance-benchmarks)\n",
    "The results from the benchmark are displayed in the table below:\n",
    "\n",
    "\n",
    "| GPU        | Model                  | Runtime |\n",
    "|------------|------------------------|---------|\n",
    "| Tesla T4   | KerasCV (Warm Start)   | _28.97s_  |\n",
    "| Tesla T4   | diffusers (Warm Start) | 41.33s  |\n",
    "| Tesla V100 | KerasCV (Warm Start)   | _12.45_   |\n",
    "| Tesla V100 | diffusers (Warm Start) | 12.72   |\n",
    "\n",
    "\n",
    "30% improvement in execution time on the Tesla T4!.  While the improvement is much lower\n",
    "on the V100, we expect the results of the benchmark to consistently favor the KerasCV.\n",
    "For the sake of completeness, both cold-start and warm-start generation times are\n",
    "reported. Cold-start execution time is a one time cost on model creation, and is\n",
    "therefore neglible in a production environment.  Regardless, here are the cold-start\n",
    "numbers:\n",
    "\n",
    "\n",
    "| GPU        | Model                  | Runtime |\n",
    "|------------|------------------------|---------|\n",
    "| Tesla T4   | KerasCV (Cold Start)   | 83.47s  |\n",
    "| Tesla T4   | diffusers (Cold Start) | 46.27s  |\n",
    "| Tesla V100 | KerasCV (Cold Start)   | 76.43   |\n",
    "| Tesla V100 | diffusers (Cold Start) | 13.90   |\n",
    "\n",
    "\n",
    "The runtime results from running this guide may vary, in my testing the KerasCV\n",
    "implementation of StableDiffusion is significantly faster than the PyTorch counterpart.\n",
    "This may be largely attributed to XLA compilation.\n",
    "\n",
    "**Note: The difference between the performance benefits from each optimization vary\n",
    "drastically between hardware**\n",
    "\n",
    "To get started, let's first benchmark our unoptimized model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "benchmark_result = []\n",
    "start = time.time()\n",
    "visualize_prompt(\n",
    "    \"A cute water-colored otter in a rainbow whirlpool holding shells\",\n",
    "    sd_model=stable_diffusion,\n",
    ")\n",
    "end = time.time()\n",
    "benchmark_result.append([\"Standard\", end - start])\n",
    "print(f\"Standard model took {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Mixed Precision\n",
    "\n",
    "Mixed precision computation is the process of performing computation using `float16`\n",
    "precision, while storing weights in the `float32` format.\n",
    "This is done to take advantage of the fact that `float16` operations are\n",
    "significantly faster than their `float32` counterparts on modern accelarators.\n",
    "\n",
    "While a low-level setting, enabling mixed precision computation in Keras\n",
    "(and therefore for `keras_cv.models.StableDiffusion`) is as simple as calling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "That's all.  Out of the box - it just works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# clear session to preserve memory\n",
    "tf.keras.backend.clear_session()\n",
    "stable_diffusion = keras_cv.models.StableDiffusion()\n",
    "print(\"Compute dtype:\", stable_diffusion.diffusion_model.compute_dtype)\n",
    "print(\n",
    "    \"Variable dtype:\",\n",
    "    stable_diffusion.diffusion_model.variable_dtype,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "As you can see, the model constructed above now uses mixed precision computation;\n",
    "leveraging the speed of `float16` for computation, and `float32` to store variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# warm up model to run graph tracing before benchmarking\n",
    "stable_diffusion.text_to_image(\"warming up the model\", batch_size=3)\n",
    "\n",
    "start = time.time()\n",
    "visualize_prompt(\n",
    "    \"a cute magical flying dog, fantasy art drawn by disney concept artists, \"\n",
    "    \"golden colour, high quality, highly detailed, elegant, sharp focus, \"\n",
    "    \"concept art, character concepts, digital painting, mystery, adventure\",\n",
    "    sd_model=stable_diffusion,\n",
    ")\n",
    "end = time.time()\n",
    "benchmark_result.append([\"Mixed Precision\", end - start])\n",
    "print(f\"Mixed precision model took {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### XLA Compilation\n",
    "\n",
    "TensorFlow comes with the\n",
    "[XLA: Accelerated Linear Algebra](https://www.tensorflow.org/xla) compiler built in.\n",
    "`keras_cv.models.StableDiffusion` supports a `jit_compile` argument out of the box.\n",
    "Setting this argument to `True` enables XLA compilation, resulting in a significant\n",
    "speed-up.\n",
    "\n",
    "Let's use this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "# set back to the default for benchmarking purposes\n",
    "mixed_precision.set_global_policy(\"float32\")\n",
    "stable_diffusion = keras_cv.models.StableDiffusion(jit_compile=True)\n",
    "# before we benchmark the model, we run inference once to make sure the TensorFlow\n",
    "# graph has already been traced.\n",
    "visualize_prompt(\n",
    "    \"An oldschool macintosh computer showing an avocado on its screen\",\n",
    "    sd_model=stable_diffusion,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Let's benchmark our XLA model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "visualize_prompt(\n",
    "    \"A cute water-colored otter in a rainbow whirlpool holding shells\",\n",
    "    sd_model=stable_diffusion,\n",
    ")\n",
    "end = time.time()\n",
    "benchmark_result.append([\"XLA\", end - start])\n",
    "print(f\"With XLA took {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "On my hardware I see about a 2x speedup.  Fantastic!\n",
    "## Putting It All Together\n",
    "\n",
    "So?  How do you assemble the world's most performant stable diffusion inference\n",
    "pipeline (as of September 2022).\n",
    "\n",
    "Two lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "stable_diffusion = keras_cv.models.StableDiffusion(jit_compile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "and to use it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Let's make sure to warm up the model\n",
    "\n",
    "visualize_prompt(\n",
    "    \"Teddy bears conducting machine learning research\", sd_model=stable_diffusion\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Exactly how fast is it?\n",
    "Let's find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "start = time.time()\n",
    "visualize_prompt(\n",
    "    \"A mysterious dark stranger visits the great pyramids of egypt, \"\n",
    "    \"high quality, highly detailed, elegant, sharp focus, \"\n",
    "    \"concept art, character concepts, digital painting\",\n",
    "    sd_model=stable_diffusion,\n",
    ")\n",
    "end = time.time()\n",
    "benchmark_result.append([\"XLA + Mixed Precision\", end - start])\n",
    "print(f\"XLA + mixed precision took {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Let's check out the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "print(\"{:<20} {:<20}\".format(\"Model\", \"Runtime\"))\n",
    "for result in benchmark_result:\n",
    "    name, runtime = result\n",
    "    print(\"{:<20} {:<20}\".format(name, runtime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "It only took our fully optimized model four seconds to generate three novel images from\n",
    "a text prompt.\n",
    "\n",
    "What a time to be alive!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Conclusions\n",
    "\n",
    "KerasCV offers a high quality API to leverage StableDiffusion today.\n",
    "Through the use of XLA and mixed precision Tensorflow allows us to construct the fastest StableDiffusion pipeline available as of September 2022.\n",
    "\n",
    "Normally, at the end of a keras.io tutorial we leave you with some future directions to continue in to learn.\n",
    "This time, we leave you with one idea:\n",
    "\n",
    "**Go run your own prompts through the model!  It is an absolute blast!**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "generate_with_stable_diffusion",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}