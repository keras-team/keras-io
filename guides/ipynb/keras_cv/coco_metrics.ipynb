{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Using KerasCV COCO Metrics\n",
    "\n",
    "**Author:** [lukewood](https://lukewood.xyz)<br>\n",
    "**Date created:** 2022/04/13<br>\n",
    "**Last modified:** 2022/04/13<br>\n",
    "**Description:** Use KerasCV COCO metrics to evaluate object detection models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Overview\n",
    "\n",
    "With KerasCV's COCO metrics implementation, you can easily evaluate your object\n",
    "detection model's performance all from within the TensorFlow graph. This guide\n",
    "shows you how to use KerasCV's COCO metrics and integrate it into your own model\n",
    "evaluation pipeline.  Historically, users have evaluated COCO metrics as a post training\n",
    "step.  KerasCV offers an in graph implementation of COCO metrics, enabling users to\n",
    "evaluate COCO metrics *during* training!\n",
    "\n",
    "Let's get started using KerasCV's COCO metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Input format\n",
    "\n",
    "All KerasCV components that process bounding boxes, including COCO metrics, require a\n",
    "`bounding_box_format` parameter.  This parameter is used to tell the components what\n",
    "format your bounding boxes are in.  While this guide uses the `xyxy` format, a full\n",
    "list of supported formats is available in\n",
    "[the bounding_box API documentation](https://keras.io/api/keras_cv/bounding_box/formats/).\n",
    "\n",
    "The metrics expect `y_true` and be a `float` Tensor with the shape `[batch,\n",
    "num_images, num_boxes, 5]`, with the ordering of last set of axes determined by the\n",
    "provided format.  The same is true of `y_pred`, except that an additional `confidence`\n",
    "axis must be provided.\n",
    "\n",
    "Due to the fact that each image may have a different number of bounding boxes,\n",
    "the `num_boxes` dimension may actually have a mismatching shape between images.\n",
    "KerasCV works around this by allowing you to either pass a `RaggedTensor` as an\n",
    "input to the KerasCV COCO metrics, or padding unused bounding boxes with `-1`.\n",
    "\n",
    "Utility functions to manipulate bounding boxes, transform between formats, and\n",
    "pad bounding box Tensors with `-1s` are available from the\n",
    "[`keras_cv.bounding_box`](https://github.com/keras-team/keras-cv/blob/master/keras_cv/bounding_box)\n",
    "package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Independent metric use\n",
    "\n",
    "The usage first pattern for KerasCV COCO metrics is to manually call\n",
    "`update_state()` and `result()` methods. This pattern is recommended for users\n",
    "who want finer grained control of their metric evaluation, or want to use a\n",
    "different format for `y_pred` in their model.\n",
    "\n",
    "Let's run through a quick code example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "1.) First, we must construct our metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import keras_cv\n",
    "\n",
    "# import all modules we will need in this example\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# only consider boxes with areas less than a 32x32 square.\n",
    "metric = keras_cv.metrics.COCORecall(\n",
    "    bounding_box_format=\"xyxy\", class_ids=[1, 2, 3], area_range=(0, 32**2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "2.) Create Some Bounding Boxes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "y_true = tf.ragged.stack(\n",
    "    [\n",
    "        # image 1\n",
    "        tf.constant([[0, 0, 10, 10, 1], [11, 12, 30, 30, 2]], tf.float32),\n",
    "        # image 2\n",
    "        tf.constant([[0, 0, 10, 10, 1]], tf.float32),\n",
    "    ]\n",
    ")\n",
    "y_pred = tf.ragged.stack(\n",
    "    [\n",
    "        # predictions for image 1\n",
    "        tf.constant([[5, 5, 10, 10, 1, 0.9]], tf.float32),\n",
    "        # predictions for image 2\n",
    "        tf.constant([[0, 0, 10, 10, 1, 1.0], [5, 5, 10, 10, 1, 0.9]], tf.float32),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "3.) Update metric state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "metric.update_state(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "4.) Evaluate the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "metric.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Evaluating COCORecall for your object detection model is as simple as that!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Metric use in a model\n",
    "\n",
    "You can also leverage COCORecall in your model's training loop.  Let's walk through this\n",
    "process.\n",
    "\n",
    "1.) Construct your the metric and a dummy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "i = keras.layers.Input((None, 6))\n",
    "model = keras.Model(i, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "2.) Create some fake bounding boxes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "y_true = tf.constant([[[0, 0, 10, 10, 1], [5, 5, 10, 10, 1]]], tf.float32)\n",
    "y_pred = tf.constant([[[0, 0, 10, 10, 1, 1.0], [5, 5, 10, 10, 1, 0.9]]], tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "3.) Create the metric and compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "recall = keras_cv.metrics.COCORecall(\n",
    "    bounding_box_format=\"xyxy\",\n",
    "    max_detections=100,\n",
    "    class_ids=[1],\n",
    "    area_range=(0, 64**2),\n",
    "    name=\"coco_recall\",\n",
    ")\n",
    "model.compile(metrics=[recall])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "4.) Use `model.evaluate()` to evaluate the metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.evaluate(y_pred, y_true, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Looks great!  That's all it takes to use KerasCV's COCO metrics to evaluate object\n",
    "detection models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Supported constructor parameters\n",
    "\n",
    "KerasCV COCO Metrics are sufficiently parameterized to support all of the\n",
    "permutations evaluated in the original COCO challenge, all metrics evaluated in\n",
    "the accompanying `pycocotools` library, and more!\n",
    "\n",
    "Check out the full documentation for [`COCORecall`](/api/keras_cv/metrics/coco_recall/) and\n",
    "[`COCOMeanAveragePrecision`](/api/keras_cv/metrics/coco_mean_average_precision/).\n",
    "\n",
    "\n",
    "## Conclusion & next steps\n",
    "KerasCV makes it easier than ever before to evaluate a Keras object detection model.\n",
    "Historically, users had to perform post training evaluation.  With KerasCV, you can\n",
    "perform train time evaluation to see how these metrics evolve over time!\n",
    "\n",
    "As an additional exercise for readers, you can:\n",
    "\n",
    "- Configure `iou_thresholds`, `max_detections`, and `area_range` to reproduce the suite\n",
    "of metrics evaluted in `pycocotools`\n",
    "- Integrate COCO metrics into a RetinaNet using the\n",
    "[keras.io RetinaNet example](https://keras.io/examples/vision/retinanet/)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "coco_metrics",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
