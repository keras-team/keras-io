{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Face image generation with StyleGAN\n",
    "\n",
    "**Author:** [Soon-Yau Cheong](https://www.linkedin.com/in/soonyau/)<br>\n",
    "**Date created:** 2021/07/01<br>\n",
    "**Last modified:** 2021/07/01<br>\n",
    "**Description:** Implementation of StyleGAN for image generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "The key idea of StyleGAN is to progressively increase the resolution of the generated\n",
    "images and to incorporate style features in the generative process.This\n",
    "[StyleGAN](https://arxiv.org/abs/1812.04948) implementation is based on the book\n",
    "[Hands-on Image Generation with TensorFlow](https://www.amazon.com/dp/1838826785).\n",
    "The code from the book's\n",
    "[Github repository](https://github.com/PacktPublishing/Hands-On-Image-Generation-with-TensorFlow-2.0/tree/master/Chapter07)\n",
    "was refactored to leverage a custom `train_step()` to enable\n",
    "faster training time via compilation and distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from enum import Enum\n",
    "from glob import glob\n",
    "from functools import partial\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow_addons.layers import InstanceNormalization\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Prepare the dataset\n",
    "\n",
    "In this example, we will train using the CelebA from TensorFlow Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def log2(x):\n",
    "    return int(np.log2(x))\n",
    "\n",
    "\n",
    "# we use different batch size for different resolution, so larger image size\n",
    "# could fit into GPU memory. The keys is image resolution in log2\n",
    "batch_sizes = {2: 16, 3: 16, 4: 16, 5: 16, 6: 16, 7: 8, 8: 4, 9: 2, 10: 1}\n",
    "# We adjust the train step accordingly\n",
    "train_step_ratio = {k: batch_sizes[2] / v for k, v in batch_sizes.items()}\n",
    "\n",
    "\n",
    "ds_train = tfds.load(\"celeb_a\", split=\"train\")\n",
    "\n",
    "\n",
    "def resize_image(res, sample):\n",
    "    image = sample[\"image\"]\n",
    "    # only donwsampling, so use nearest neighbor that is faster to run\n",
    "    image = tf.image.resize(\n",
    "        image, (res, res), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR\n",
    "    )\n",
    "    image = tf.cast(image, tf.float32) / 127.5 - 1.0\n",
    "    return image\n",
    "\n",
    "\n",
    "def create_dataloader(res):\n",
    "    batch_size = batch_sizes[log2(res)]\n",
    "    dl = ds_train.map(partial(resize_image, res), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dl = dl.shuffle(200).batch(batch_size, drop_remainder=True).prefetch(1).repeat()\n",
    "    return dl\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Utility function to display images after each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_images(images, log2_res, fname=\"\"):\n",
    "    scales = {2: 0.5, 3: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7, 10: 8}\n",
    "    scale = scales[log2_res]\n",
    "\n",
    "    grid_col = min(images.shape[0], int(32 // scale))\n",
    "    grid_row = 1\n",
    "\n",
    "    f, axarr = plt.subplots(\n",
    "        grid_row, grid_col, figsize=(grid_col * scale, grid_row * scale)\n",
    "    )\n",
    "\n",
    "    for row in range(grid_row):\n",
    "        ax = axarr if grid_row == 1 else axarr[row]\n",
    "        for col in range(grid_col):\n",
    "            ax[col].imshow(images[row * grid_col + col])\n",
    "            ax[col].axis(\"off\")\n",
    "    plt.show()\n",
    "    if fname:\n",
    "        f.savefig(fname)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Custom Layers\n",
    "\n",
    "The following are building blocks that will be used to construct the generators and\n",
    "discriminators of the StyleGAN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def fade_in(alpha, a, b):\n",
    "    return alpha * a + (1.0 - alpha) * b\n",
    "\n",
    "\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return -tf.reduce_mean(y_true * y_pred)\n",
    "\n",
    "\n",
    "def pixel_norm(x, epsilon=1e-8):\n",
    "    return x / tf.math.sqrt(tf.reduce_mean(x ** 2, axis=-1, keepdims=True) + epsilon)\n",
    "\n",
    "\n",
    "def minibatch_std(input_tensor, epsilon=1e-8):\n",
    "    n, h, w, c = tf.shape(input_tensor)\n",
    "    group_size = tf.minimum(4, n)\n",
    "    x = tf.reshape(input_tensor, [group_size, -1, h, w, c])\n",
    "    group_mean, group_var = tf.nn.moments(x, axes=(0), keepdims=False)\n",
    "    group_std = tf.sqrt(group_var + epsilon)\n",
    "    avg_std = tf.reduce_mean(group_std, axis=[1, 2, 3], keepdims=True)\n",
    "    x = tf.tile(avg_std, [group_size, h, w, 1])\n",
    "    return tf.concat([input_tensor, x], axis=-1)\n",
    "\n",
    "\n",
    "class EqualizedConv(layers.Layer):\n",
    "    def __init__(self, out_channels, kernel=3, gain=2, **kwargs):\n",
    "        super(EqualizedConv, self).__init__(**kwargs)\n",
    "        self.kernel = kernel\n",
    "        self.out_channels = out_channels\n",
    "        self.gain = gain\n",
    "        self.pad = kernel != 1\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.in_channels = input_shape[-1]\n",
    "        initializer = keras.initializers.RandomNormal(mean=0.0, stddev=1.0)\n",
    "        self.w = self.add_weight(\n",
    "            shape=[self.kernel, self.kernel, self.in_channels, self.out_channels],\n",
    "            initializer=initializer,\n",
    "            trainable=True,\n",
    "            name=\"kernel\",\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.out_channels,), initializer=\"zeros\", trainable=True, name=\"bias\"\n",
    "        )\n",
    "        fan_in = self.kernel * self.kernel * self.in_channels\n",
    "        self.scale = tf.sqrt(self.gain / fan_in)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self.pad:\n",
    "            x = tf.pad(inputs, [[0, 0], [1, 1], [1, 1], [0, 0]], mode=\"REFLECT\")\n",
    "        else:\n",
    "            x = inputs\n",
    "        output = (\n",
    "            tf.nn.conv2d(x, self.scale * self.w, strides=1, padding=\"VALID\") + self.b\n",
    "        )\n",
    "        return output\n",
    "\n",
    "\n",
    "class EqualizedDense(layers.Layer):\n",
    "    def __init__(self, units, gain=2, learning_rate_multiplier=1, **kwargs):\n",
    "        super(EqualizedDense, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.gain = gain\n",
    "        self.learning_rate_multiplier = learning_rate_multiplier\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.in_channels = input_shape[-1]\n",
    "        initializer = keras.initializers.RandomNormal(\n",
    "            mean=0.0, stddev=1.0 / self.learning_rate_multiplier\n",
    "        )\n",
    "        self.w = self.add_weight(\n",
    "            shape=[self.in_channels, self.units],\n",
    "            initializer=initializer,\n",
    "            trainable=True,\n",
    "            name=\"kernel\",\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.units,), initializer=\"zeros\", trainable=True, name=\"bias\"\n",
    "        )\n",
    "        fan_in = self.in_channels\n",
    "        self.scale = tf.sqrt(self.gain / fan_in)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        output = tf.add(tf.matmul(inputs, self.scale * self.w), self.b)\n",
    "        return output * self.learning_rate_multiplier\n",
    "\n",
    "\n",
    "class AddNoise(layers.Layer):\n",
    "    def build(self, input_shape):\n",
    "        n, h, w, c = input_shape[0]\n",
    "        initializer = keras.initializers.RandomNormal(mean=0.0, stddev=1.0)\n",
    "        self.b = self.add_weight(\n",
    "            shape=[1, 1, 1, c], initializer=initializer, trainable=True, name=\"kernel\"\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, noise = inputs\n",
    "        output = x + self.b * noise\n",
    "        return output\n",
    "\n",
    "\n",
    "class AdaIN(layers.Layer):\n",
    "    def __init__(self, gain=1, **kwargs):\n",
    "        super(AdaIN, self).__init__(**kwargs)\n",
    "        self.gain = gain\n",
    "\n",
    "    def build(self, input_shapes):\n",
    "        x_shape = input_shapes[0]\n",
    "        w_shape = input_shapes[1]\n",
    "\n",
    "        self.w_channels = w_shape[-1]\n",
    "        self.x_channels = x_shape[-1]\n",
    "\n",
    "        self.dense_1 = EqualizedDense(self.x_channels, gain=1)\n",
    "        self.dense_2 = EqualizedDense(self.x_channels, gain=1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, w = inputs\n",
    "        ys = tf.reshape(self.dense_1(w), (-1, 1, 1, self.x_channels))\n",
    "        yb = tf.reshape(self.dense_2(w), (-1, 1, 1, self.x_channels))\n",
    "        return ys * x + yb\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Next we build the following:\n",
    "\n",
    "- A model mapping to map the random noise into style code\n",
    "- The generator\n",
    "- The discriminator\n",
    "\n",
    "For the generator, we build generator blocks at multiple resolutions,\n",
    "e.g. 4x4, 8x8, ...up to 1024x1024. We only use 4x4 in the beginning\n",
    "and we use progressively larger-resolution blocks as the training proceeds.\n",
    "Same for the discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def Mapping(num_stages, input_shape=512):\n",
    "    z = layers.Input(shape=(input_shape))\n",
    "    w = pixel_norm(z)\n",
    "    for i in range(8):\n",
    "        w = EqualizedDense(512, learning_rate_multiplier=0.01)(w)\n",
    "        w = layers.LeakyReLU(0.2)(w)\n",
    "    w = tf.tile(tf.expand_dims(w, 1), (1, num_stages, 1))\n",
    "    return keras.Model(z, w, name=\"mapping\")\n",
    "\n",
    "\n",
    "class Generator:\n",
    "    def __init__(self, start_res_log2, target_res_log2):\n",
    "        self.start_res_log2 = start_res_log2\n",
    "        self.target_res_log2 = target_res_log2\n",
    "        self.num_stages = target_res_log2 - start_res_log2 + 1\n",
    "        # list of generator blocks at increasing resolution\n",
    "        self.g_blocks = []\n",
    "        # list of layers to convert g_block activation to RGB\n",
    "        self.to_rgb = []\n",
    "        # list of noise input of different resolutions into g_blocks\n",
    "        self.noise_inputs = []\n",
    "        # filter size to use at each stage, keys are log2(resolution)\n",
    "        self.filter_nums = {\n",
    "            0: 512,\n",
    "            1: 512,\n",
    "            2: 512,  # 4x4\n",
    "            3: 512,  # 8x8\n",
    "            4: 512,  # 16x16\n",
    "            5: 512,  # 32x32\n",
    "            6: 256,  # 64x64\n",
    "            7: 128,  # 128x128\n",
    "            8: 64,  # 256x256\n",
    "            9: 32,  # 512x512\n",
    "            10: 16,\n",
    "        }  # 1024x1024\n",
    "\n",
    "        start_res = 2 ** start_res_log2\n",
    "        self.input_shape = (start_res, start_res, self.filter_nums[start_res_log2])\n",
    "        self.g_input = layers.Input(self.input_shape, name=\"generator_input\")\n",
    "\n",
    "        for i in range(start_res_log2, target_res_log2 + 1):\n",
    "            filter_num = self.filter_nums[i]\n",
    "            res = 2 ** i\n",
    "            self.noise_inputs.append(\n",
    "                layers.Input(shape=(res, res, 1), name=f\"noise_{res}x{res}\")\n",
    "            )\n",
    "            to_rgb = Sequential(\n",
    "                [\n",
    "                    layers.InputLayer(input_shape=(res, res, filter_num)),\n",
    "                    EqualizedConv(3, 1, gain=1),\n",
    "                ],\n",
    "                name=f\"to_rgb_{res}x{res}\",\n",
    "            )\n",
    "            self.to_rgb.append(to_rgb)\n",
    "            is_base = i == self.start_res_log2\n",
    "            if is_base:\n",
    "                input_shape = (res, res, self.filter_nums[i - 1])\n",
    "            else:\n",
    "                input_shape = (2 ** (i - 1), 2 ** (i - 1), self.filter_nums[i - 1])\n",
    "            g_block = self.build_block(\n",
    "                filter_num, res=res, input_shape=input_shape, is_base=is_base\n",
    "            )\n",
    "            self.g_blocks.append(g_block)\n",
    "\n",
    "    def build_block(self, filter_num, res, input_shape, is_base):\n",
    "        input_tensor = layers.Input(shape=input_shape, name=f\"g_{res}\")\n",
    "        noise = layers.Input(shape=(res, res, 1), name=f\"noise_{res}\")\n",
    "        w = layers.Input(shape=512)\n",
    "        x = input_tensor\n",
    "\n",
    "        if not is_base:\n",
    "            x = layers.UpSampling2D((2, 2))(x)\n",
    "            x = EqualizedConv(filter_num, 3)(x)\n",
    "\n",
    "        x = AddNoise()([x, noise])\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "        x = InstanceNormalization()(x)\n",
    "        x = AdaIN()([x, w])\n",
    "\n",
    "        x = EqualizedConv(filter_num, 3)(x)\n",
    "        x = AddNoise()([x, noise])\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "        x = InstanceNormalization()(x)\n",
    "        x = AdaIN()([x, w])\n",
    "        return keras.Model([input_tensor, w, noise], x, name=f\"genblock_{res}x{res}\")\n",
    "\n",
    "    def grow(self, res_log2):\n",
    "        res = 2 ** res_log2\n",
    "\n",
    "        num_stages = res_log2 - self.start_res_log2 + 1\n",
    "        w = layers.Input(shape=(self.num_stages, 512), name=\"w\")\n",
    "\n",
    "        alpha = layers.Input(shape=(1), name=\"g_alpha\")\n",
    "        x = self.g_blocks[0]([self.g_input, w[:, 0], self.noise_inputs[0]])\n",
    "\n",
    "        if num_stages == 1:\n",
    "            rgb = self.to_rgb[0](x)\n",
    "        else:\n",
    "            for i in range(1, num_stages - 1):\n",
    "\n",
    "                x = self.g_blocks[i]([x, w[:, i], self.noise_inputs[i]])\n",
    "\n",
    "            old_rgb = self.to_rgb[num_stages - 2](x)\n",
    "            old_rgb = layers.UpSampling2D((2, 2))(old_rgb)\n",
    "\n",
    "            i = num_stages - 1\n",
    "            x = self.g_blocks[i]([x, w[:, i], self.noise_inputs[i]])\n",
    "\n",
    "            new_rgb = self.to_rgb[i](x)\n",
    "\n",
    "            rgb = fade_in(alpha[0], new_rgb, old_rgb)\n",
    "\n",
    "        return keras.Model(\n",
    "            [self.g_input, w, self.noise_inputs, alpha],\n",
    "            rgb,\n",
    "            name=f\"generator_{res}_x_{res}\",\n",
    "        )\n",
    "\n",
    "\n",
    "class Discriminator:\n",
    "    def __init__(self, start_res_log2, target_res_log2):\n",
    "        self.start_res_log2 = start_res_log2\n",
    "        self.target_res_log2 = target_res_log2\n",
    "        self.num_stages = target_res_log2 - start_res_log2 + 1\n",
    "        # filter size to use at each stage, keys are log2(resolution)\n",
    "        self.filter_nums = {\n",
    "            0: 512,\n",
    "            1: 512,\n",
    "            2: 512,  # 4x4\n",
    "            3: 512,  # 8x8\n",
    "            4: 512,  # 16x16\n",
    "            5: 512,  # 32x32\n",
    "            6: 256,  # 64x64\n",
    "            7: 128,  # 128x128\n",
    "            8: 64,  # 256x256\n",
    "            9: 32,  # 512x512\n",
    "            10: 16,\n",
    "        }  # 1024x1024\n",
    "        # list of discriminator blocks at increasing resolution\n",
    "        self.d_blocks = []\n",
    "        # list of layers to convert RGB into activation for d_blocks inputs\n",
    "        self.from_rgb = []\n",
    "\n",
    "        for res_log2 in range(self.start_res_log2, self.target_res_log2 + 1):\n",
    "            res = 2 ** res_log2\n",
    "            filter_num = self.filter_nums[res_log2]\n",
    "            from_rgb = Sequential(\n",
    "                [\n",
    "                    layers.InputLayer(\n",
    "                        input_shape=(res, res, 3), name=f\"from_rgb_input_{res}\"\n",
    "                    ),\n",
    "                    EqualizedConv(filter_num, 1),\n",
    "                    layers.LeakyReLU(0.2),\n",
    "                ],\n",
    "                name=f\"from_rgb_{res}\",\n",
    "            )\n",
    "\n",
    "            self.from_rgb.append(from_rgb)\n",
    "\n",
    "            input_shape = (res, res, filter_num)\n",
    "            if len(self.d_blocks) == 0:\n",
    "                d_block = self.build_base(filter_num, res)\n",
    "            else:\n",
    "                d_block = self.build_block(\n",
    "                    filter_num, self.filter_nums[res_log2 - 1], res\n",
    "                )\n",
    "\n",
    "            self.d_blocks.append(d_block)\n",
    "\n",
    "    def build_base(self, filter_num, res):\n",
    "        input_tensor = layers.Input(shape=(res, res, filter_num), name=f\"d_{res}\")\n",
    "        x = minibatch_std(input_tensor)\n",
    "        x = EqualizedConv(filter_num, 3)(x)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "        x = layers.Flatten()(x)\n",
    "        x = EqualizedDense(filter_num)(x)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "        x = EqualizedDense(1)(x)\n",
    "        return keras.Model(input_tensor, x, name=f\"d_{res}\")\n",
    "\n",
    "    def build_block(self, filter_num_1, filter_num_2, res):\n",
    "        input_tensor = layers.Input(shape=(res, res, filter_num_1), name=f\"d_{res}\")\n",
    "        x = EqualizedConv(filter_num_1, 3)(input_tensor)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "        x = EqualizedConv(filter_num_2)(x)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "        x = layers.AveragePooling2D((2, 2))(x)\n",
    "        return keras.Model(input_tensor, x, name=f\"d_{res}\")\n",
    "\n",
    "    def grow(self, res_log2):\n",
    "        res = 2 ** res_log2\n",
    "        idx = res_log2 - self.start_res_log2\n",
    "        alpha = layers.Input(shape=(1), name=\"d_alpha\")\n",
    "        input_image = layers.Input(shape=(res, res, 3), name=\"input_image\")\n",
    "        x = self.from_rgb[idx](input_image)\n",
    "        x = self.d_blocks[idx](x)\n",
    "        if idx > 0:\n",
    "            idx -= 1\n",
    "            downsized_image = layers.AveragePooling2D((2, 2))(input_image)\n",
    "            y = self.from_rgb[idx](downsized_image)\n",
    "            x = fade_in(alpha[0], x, y)\n",
    "\n",
    "            for i in range(idx, -1, -1):\n",
    "                x = self.d_blocks[i](x)\n",
    "        return keras.Model([input_image, alpha], x, name=f\"discriminator_{res}_x_{res}\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Build StyleGAN with custom train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "class StyleGAN(tf.keras.Model):\n",
    "    def __init__(self, z_dim=512, target_res=64, start_res=4):\n",
    "        super(StyleGAN, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.target_res_log2 = log2(target_res)\n",
    "        self.start_res_log2 = log2(start_res)\n",
    "        self.current_res_log2 = self.target_res_log2\n",
    "        self.num_stages = self.target_res_log2 - self.start_res_log2 + 1\n",
    "\n",
    "        self.alpha = tf.Variable(1.0, dtype=tf.float32, trainable=False, name=\"alpha\")\n",
    "\n",
    "        self.mapping = Mapping(num_stages=self.num_stages)\n",
    "        self.d_builder = Discriminator(self.start_res_log2, self.target_res_log2)\n",
    "        self.g_builder = Generator(self.start_res_log2, self.target_res_log2)\n",
    "        self.g_input_shape = self.g_builder.input_shape\n",
    "\n",
    "        self.phase = None\n",
    "        self.train_step_counter = tf.Variable(0, dtype=tf.int32, trainable=False)\n",
    "\n",
    "        self.loss_weights = {\"gradient_penalty\": 10, \"drift\": 0.001}\n",
    "\n",
    "    def grow_model(self, res):\n",
    "        tf.keras.backend.clear_session()\n",
    "        res_log2 = log2(res)\n",
    "        self.generator = self.g_builder.grow(res_log2)\n",
    "        self.discriminator = self.d_builder.grow(res_log2)\n",
    "        self.current_res_log2 = res_log2\n",
    "        print(f\"\\nModel resolution:{res}x{res}\")\n",
    "\n",
    "    def compile(\n",
    "        self, steps_per_epoch, phase, res, d_optimizer, g_optimizer, *args, **kwargs\n",
    "    ):\n",
    "        self.loss_weights = kwargs.pop(\"loss_weights\", self.loss_weights)\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        if res != 2 ** self.current_res_log2:\n",
    "            self.grow_model(res)\n",
    "            self.d_optimizer = d_optimizer\n",
    "            self.g_optimizer = g_optimizer\n",
    "\n",
    "        self.train_step_counter.assign(0)\n",
    "        self.phase = phase\n",
    "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "        super(StyleGAN, self).compile(*args, **kwargs)\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "\n",
    "    def generate_noise(self, batch_size):\n",
    "        noise = [\n",
    "            tf.random.normal((batch_size, 2 ** res, 2 ** res, 1))\n",
    "            for res in range(self.start_res_log2, self.target_res_log2 + 1)\n",
    "        ]\n",
    "        return noise\n",
    "\n",
    "    def gradient_loss(self, grad):\n",
    "        loss = tf.square(grad)\n",
    "        loss = tf.reduce_sum(loss, axis=tf.range(1, tf.size(tf.shape(loss))))\n",
    "        loss = tf.sqrt(loss)\n",
    "        loss = tf.reduce_mean(tf.square(loss - 1))\n",
    "        return loss\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "\n",
    "        self.train_step_counter.assign_add(1)\n",
    "\n",
    "        if self.phase == \"TRANSITION\":\n",
    "            self.alpha.assign(\n",
    "                tf.cast(self.train_step_counter / self.steps_per_epoch, tf.float32)\n",
    "            )\n",
    "        elif self.phase == \"STABLE\":\n",
    "            self.alpha.assign(1.0)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        alpha = tf.expand_dims(self.alpha, 0)\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        real_labels = tf.ones(batch_size)\n",
    "        fake_labels = -tf.ones(batch_size)\n",
    "\n",
    "        z = tf.random.normal((batch_size, self.z_dim))\n",
    "        const_input = tf.ones(tuple([batch_size] + list(self.g_input_shape)))\n",
    "        noise = self.generate_noise(batch_size)\n",
    "\n",
    "        # generator\n",
    "        with tf.GradientTape() as g_tape:\n",
    "            w = self.mapping(z)\n",
    "            fake_images = self.generator([const_input, w, noise, alpha])\n",
    "            pred_fake = self.discriminator([fake_images, alpha])\n",
    "            g_loss = wasserstein_loss(real_labels, pred_fake)\n",
    "\n",
    "            trainable_weights = (\n",
    "                self.mapping.trainable_weights + self.generator.trainable_weights\n",
    "            )\n",
    "            gradients = g_tape.gradient(g_loss, trainable_weights)\n",
    "            self.g_optimizer.apply_gradients(zip(gradients, trainable_weights))\n",
    "\n",
    "        # discriminator\n",
    "        with tf.GradientTape() as gradient_tape, tf.GradientTape() as total_tape:\n",
    "            # forward pass\n",
    "            pred_fake = self.discriminator([fake_images, alpha])\n",
    "            pred_real = self.discriminator([real_images, alpha])\n",
    "\n",
    "            epsilon = tf.random.uniform((batch_size, 1, 1, 1))\n",
    "            interpolates = epsilon * real_images + (1 - epsilon) * fake_images\n",
    "            gradient_tape.watch(interpolates)\n",
    "            pred_fake_grad = self.discriminator([interpolates, alpha])\n",
    "\n",
    "            # calculate losses\n",
    "            loss_fake = wasserstein_loss(fake_labels, pred_fake)\n",
    "            loss_real = wasserstein_loss(real_labels, pred_real)\n",
    "            loss_fake_grad = wasserstein_loss(fake_labels, pred_fake_grad)\n",
    "\n",
    "            # gradient penalty\n",
    "            gradients_fake = gradient_tape.gradient(loss_fake_grad, [interpolates])\n",
    "            gradient_penalty = self.loss_weights[\n",
    "                \"gradient_penalty\"\n",
    "            ] * self.gradient_loss(gradients_fake)\n",
    "\n",
    "            # drift loss\n",
    "            all_pred = tf.concat([pred_fake, pred_real], axis=0)\n",
    "            drift_loss = self.loss_weights[\"drift\"] * tf.reduce_mean(all_pred ** 2)\n",
    "\n",
    "            d_loss = loss_fake + loss_real + gradient_penalty + drift_loss\n",
    "\n",
    "            gradients = total_tape.gradient(\n",
    "                d_loss, self.discriminator.trainable_weights\n",
    "            )\n",
    "            self.d_optimizer.apply_gradients(\n",
    "                zip(gradients, self.discriminator.trainable_weights)\n",
    "            )\n",
    "\n",
    "        # Update metrics\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        return {\n",
    "            \"d_loss\": self.d_loss_metric.result(),\n",
    "            \"g_loss\": self.g_loss_metric.result(),\n",
    "        }\n",
    "\n",
    "    def call(self, inputs: dict()):\n",
    "        style_code = inputs.get(\"style_code\", None)\n",
    "        z = inputs.get(\"z\", None)\n",
    "        noise = inputs.get(\"noise\", None)\n",
    "        batch_size = inputs.get(\"batch_size\", 1)\n",
    "        alpha = inputs.get(\"alpha\", 1.0)\n",
    "        alpha = tf.expand_dims(alpha, 0)\n",
    "        if style_code is None:\n",
    "            if z is None:\n",
    "                z = tf.random.normal((batch_size, self.z_dim))\n",
    "            style_code = self.mapping(z)\n",
    "\n",
    "        if noise is None:\n",
    "            noise = self.generate_noise(batch_size)\n",
    "\n",
    "        # self.alpha.assign(alpha)\n",
    "\n",
    "        const_input = tf.ones(tuple([batch_size] + list(self.g_input_shape)))\n",
    "        images = self.generator([const_input, style_code, noise, alpha])\n",
    "        images = np.clip((images * 0.5 + 0.5) * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "        return images\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Training\n",
    "\n",
    "We first build the StyleGAN at smallest resolution, such as 4x4 or 8x8. Then we\n",
    "progressively grow the model to higher resolution by appending new generator and\n",
    "discriminator blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "START_RES = 4\n",
    "TARGET_RES = 128\n",
    "\n",
    "style_gan = StyleGAN(start_res=START_RES, target_res=TARGET_RES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "The training for each new resolution happen in two phases - \"transition\" and \"stable\".\n",
    "In the transition phase, the features from the previous resolution are mixed with the\n",
    "current resolution. This allows for a smoother transition when scalling up. We use each\n",
    "epoch in `model.fit()` as a phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(\n",
    "    start_res=START_RES,\n",
    "    target_res=TARGET_RES,\n",
    "    steps_per_epoch=5000,\n",
    "    display_images=True,\n",
    "):\n",
    "    opt_cfg = {\"learning_rate\": 1e-3, \"beta_1\": 0.0, \"beta_2\": 0.99, \"epsilon\": 1e-8}\n",
    "\n",
    "    val_batch_size = 16\n",
    "    val_z = tf.random.normal((val_batch_size, style_gan.z_dim))\n",
    "    val_noise = style_gan.generate_noise(val_batch_size)\n",
    "\n",
    "    start_res_log2 = int(np.log2(start_res))\n",
    "    target_res_log2 = int(np.log2(target_res))\n",
    "\n",
    "    for res_log2 in range(start_res_log2, target_res_log2 + 1):\n",
    "        res = 2 ** res_log2\n",
    "        for phase in [\"TRANSITION\", \"STABLE\"]:\n",
    "            if res == start_res and phase == \"TRANSITION\":\n",
    "                continue\n",
    "\n",
    "            train_dl = create_dataloader(res)\n",
    "\n",
    "            steps = int(train_step_ratio[res_log2] * steps_per_epoch)\n",
    "\n",
    "            style_gan.compile(\n",
    "                d_optimizer=tf.keras.optimizers.Adam(**opt_cfg),\n",
    "                g_optimizer=tf.keras.optimizers.Adam(**opt_cfg),\n",
    "                loss_weights={\"gradient_penalty\": 10, \"drift\": 0.001},\n",
    "                steps_per_epoch=steps,\n",
    "                res=res,\n",
    "                phase=phase,\n",
    "                run_eagerly=False,\n",
    "            )\n",
    "\n",
    "            prefix = f\"res_{res}x{res}_{style_gan.phase}\"\n",
    "\n",
    "            ckpt_cb = keras.callbacks.ModelCheckpoint(\n",
    "                f\"checkpoints/stylegan_{res}x{res}.ckpt\",\n",
    "                save_weights_only=True,\n",
    "                verbose=0,\n",
    "            )\n",
    "            print(phase)\n",
    "            style_gan.fit(\n",
    "                train_dl, epochs=1, steps_per_epoch=steps, callbacks=[ckpt_cb]\n",
    "            )\n",
    "\n",
    "            if display_images:\n",
    "                images = style_gan({\"z\": val_z, \"noise\": val_noise, \"alpha\": 1.0})\n",
    "                plot_images(images, res_log2)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "StyleGAN can take a long time to train, in the code below, a small `steps_per_epoch`\n",
    "value of 1 is used to sanity-check the code is working alright. In practice, a larger\n",
    "`steps_per_epoch` value (over 10000)\n",
    "is required to get decent results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "train(start_res=4, target_res=16, steps_per_epoch=1, display_images=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Results\n",
    "\n",
    "We can now run some inference using pre-trained 64x64 checkpoints. In general, the image\n",
    "fidelity increases with the resolution. You can try to train this StyleGAN to resolutions\n",
    "above 128x128 with the CelebA HQ dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "url = \"https://github.com/soon-yau/stylegan_keras/releases/download/keras_example_v1.0/stylegan_128x128.ckpt.zip\"\n",
    "\n",
    "weights_path = keras.utils.get_file(\n",
    "    \"stylegan_128x128.ckpt.zip\",\n",
    "    url,\n",
    "    extract=True,\n",
    "    cache_dir=os.path.abspath(\".\"),\n",
    "    cache_subdir=\"pretrained\",\n",
    ")\n",
    "\n",
    "style_gan.grow_model(128)\n",
    "style_gan.load_weights(os.path.join(\"pretrained/stylegan_128x128.ckpt\"))\n",
    "\n",
    "tf.random.set_seed(196)\n",
    "batch_size = 2\n",
    "z = tf.random.normal((batch_size, style_gan.z_dim))\n",
    "w = style_gan.mapping(z)\n",
    "noise = style_gan.generate_noise(batch_size=batch_size)\n",
    "images = style_gan({\"style_code\": w, \"noise\": noise, \"alpha\": 1.0})\n",
    "plot_images(images, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Style Mixing\n",
    "\n",
    "We can also mix styles from two images to create a new image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "alpha = 0.4\n",
    "w_mix = np.expand_dims(alpha * w[0] + (1 - alpha) * w[1], 0)\n",
    "noise_a = [np.expand_dims(n[0], 0) for n in noise]\n",
    "mix_images = style_gan({\"style_code\": w_mix, \"noise\": noise_a})\n",
    "image_row = np.hstack([images[0], images[1], mix_images[0]])\n",
    "plt.figure(figsize=(9, 3))\n",
    "plt.imshow(image_row)\n",
    "plt.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "stylegan",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}