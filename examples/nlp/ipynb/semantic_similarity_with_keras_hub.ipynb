{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Semantic Similarity with KerasHub\n",
    "\n",
    "**Author:** [Anshuman Mishra](https://github.com/shivance/)<br>\n",
    "**Date created:** 2023/02/25<br>\n",
    "**Last modified:** 2023/02/25<br>\n",
    "**Description:** Use pretrained models from KerasHub for the Semantic Similarity Task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Semantic similarity refers to the task of determining the degree of similarity between two\n",
    "sentences in terms of their meaning. We already saw in [this](https://keras.io/examples/nlp/semantic_similarity_with_bert/)\n",
    "example how to use SNLI (Stanford Natural Language Inference) corpus to predict sentence\n",
    "semantic similarity with the HuggingFace Transformers library. In this tutorial we will\n",
    "learn how to use [KerasHub](https://keras.io/keras_hub/), an extension of the core Keras API,\n",
    "for the same task. Furthermore, we will discover how KerasHub effectively reduces boilerplate\n",
    "code and simplifies the process of building and utilizing models. For more information on KerasHub,\n",
    "please refer to [KerasHub's official documentation](https://keras.io/keras_hub/).\n",
    "\n",
    "This guide is broken down into the following parts:\n",
    "\n",
    "1. *Setup*, task definition, and establishing a baseline.\n",
    "2. *Establishing baseline* with BERT.\n",
    "3. *Saving and Reloading* the model.\n",
    "4. *Performing inference* with the model.\n",
    "5  *Improving accuracy* with RoBERTa\n",
    "\n",
    "## Setup\n",
    "\n",
    "The following guide uses [Keras Core](https://keras.io/keras_core/) to work in\n",
    "any of `tensorflow`, `jax` or `torch`. Support for Keras Core is baked into\n",
    "KerasHub, simply change the `KERAS_BACKEND` environment variable below to change\n",
    "the backend you would like to use. We select the `jax` backend below, which will\n",
    "give us a particularly fast train step below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "!pip install -q --upgrade keras-hub\n",
    "!pip install -q --upgrade keras  # Upgrade to Keras 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras_hub\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "To load the SNLI dataset, we use the tensorflow-datasets library, which\n",
    "contains over 550,000 samples in total. However, to ensure that this example runs\n",
    "quickly, we use only 20% of the training samples.\n",
    "\n",
    "## Overview of SNLI Dataset\n",
    "\n",
    "Every sample in the dataset contains three components: `hypothesis`, `premise`,\n",
    "and `label`. epresents the original caption provided to the author of the pair,\n",
    "while the hypothesis refers to the hypothesis caption created by the author of\n",
    "the pair. The label is assigned by annotators to indicate the similarity between\n",
    "the two sentences.\n",
    "\n",
    "The dataset contains three possible similarity label values: Contradiction, Entailment,\n",
    "and Neutral. Contradiction represents completely dissimilar sentences, while Entailment\n",
    "denotes similar meaning sentences. Lastly, Neutral refers to sentences where no clear\n",
    "similarity or dissimilarity can be established between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "snli_train = tfds.load(\"snli\", split=\"train[:20%]\")\n",
    "snli_val = tfds.load(\"snli\", split=\"validation\")\n",
    "snli_test = tfds.load(\"snli\", split=\"test\")\n",
    "\n",
    "# Here's an example of how our training samples look like, where we randomly select\n",
    "# four samples:\n",
    "sample = snli_test.batch(4).take(1).get_single_element()\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Preprocessing\n",
    "\n",
    "In our dataset, we have identified that some samples have missing or incorrectly labeled\n",
    "data, which is denoted by a value of -1. To ensure the accuracy and reliability of our model,\n",
    "we simply filter out these samples from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def filter_labels(sample):\n",
    "    return sample[\"label\"] >= 0\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Here's a utility function that splits the example into an `(x, y)` tuple that is suitable\n",
    "for `model.fit()`. By default, `keras_hub.models.BertClassifier` will tokenize and pack\n",
    "together raw strings using a `\"[SEP]\"` token during training. Therefore, this label\n",
    "splitting is all the data preparation that we need to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def split_labels(sample):\n",
    "    x = (sample[\"hypothesis\"], sample[\"premise\"])\n",
    "    y = sample[\"label\"]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "train_ds = (\n",
    "    snli_train.filter(filter_labels)\n",
    "    .map(split_labels, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(16)\n",
    ")\n",
    "val_ds = (\n",
    "    snli_val.filter(filter_labels)\n",
    "    .map(split_labels, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(16)\n",
    ")\n",
    "test_ds = (\n",
    "    snli_test.filter(filter_labels)\n",
    "    .map(split_labels, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(16)\n",
    ")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Establishing baseline with BERT.\n",
    "\n",
    "We use the BERT model from KerasHub to establish a baseline for our semantic similarity\n",
    "task. The `keras_hub.models.BertClassifier` class attaches a classification head to the BERT\n",
    "Backbone, mapping the backbone outputs to a logit output suitable for a classification task.\n",
    "This significantly reduces the need for custom code.\n",
    "\n",
    "KerasHub models have built-in tokenization capabilities that handle tokenization by default\n",
    "based on the selected model. However, users can also use custom preprocessing techniques\n",
    "as per their specific needs. If we pass a tuple as input, the model will tokenize all the\n",
    "strings and concatenate them with a `\"[SEP]\"` separator.\n",
    "\n",
    "We use this model with pretrained weights, and we can use the `from_preset()` method\n",
    "to use our own preprocessor. For the SNLI dataset, we set `num_classes` to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "bert_classifier = keras_hub.models.BertClassifier.from_preset(\n",
    "    \"bert_tiny_en_uncased\", num_classes=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Please note that the BERT Tiny model has only 4,386,307 trainable parameters.\n",
    "\n",
    "KerasHub task models come with compilation defaults. We can now train the model we just\n",
    "instantiated by calling the `fit()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "bert_classifier.fit(train_ds, validation_data=val_ds, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Our BERT classifier achieved an accuracy of around 76% on the validation split. Now,\n",
    "let's evaluate its performance on the test split.\n",
    "\n",
    "### Evaluate the performance of the trained model on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "bert_classifier.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Our baseline BERT model achieved a similar accuracy of around 76% on the test split.\n",
    "Now, let's try to improve its performance by recompiling the model with a slightly\n",
    "higher learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "bert_classifier = keras_hub.models.BertClassifier.from_preset(\n",
    "    \"bert_tiny_en_uncased\", num_classes=3\n",
    ")\n",
    "bert_classifier.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(5e-5),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "bert_classifier.fit(train_ds, validation_data=val_ds, epochs=1)\n",
    "bert_classifier.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Just tweaking the learning rate alone was not enough to boost performance, which\n",
    "stayed right around 76%. Let's try again, but this time with\n",
    "`keras.optimizers.AdamW`, and a learning rate schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "class TriangularSchedule(keras.optimizers.schedules.LearningRateSchedule):\n",
    "    \"\"\"Linear ramp up for `warmup` steps, then linear decay to zero at `total` steps.\"\"\"\n",
    "\n",
    "    def __init__(self, rate, warmup, total):\n",
    "        self.rate = rate\n",
    "        self.warmup = warmup\n",
    "        self.total = total\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\"rate\": self.rate, \"warmup\": self.warmup, \"total\": self.total}\n",
    "        return config\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = keras.ops.cast(step, dtype=\"float32\")\n",
    "        rate = keras.ops.cast(self.rate, dtype=\"float32\")\n",
    "        warmup = keras.ops.cast(self.warmup, dtype=\"float32\")\n",
    "        total = keras.ops.cast(self.total, dtype=\"float32\")\n",
    "\n",
    "        warmup_rate = rate * step / self.warmup\n",
    "        cooldown_rate = rate * (total - step) / (total - warmup)\n",
    "        triangular_rate = keras.ops.minimum(warmup_rate, cooldown_rate)\n",
    "        return keras.ops.maximum(triangular_rate, 0.0)\n",
    "\n",
    "\n",
    "bert_classifier = keras_hub.models.BertClassifier.from_preset(\n",
    "    \"bert_tiny_en_uncased\", num_classes=3\n",
    ")\n",
    "\n",
    "# Get the total count of training batches.\n",
    "# This requires walking the dataset to filter all -1 labels.\n",
    "epochs = 3\n",
    "total_steps = sum(1 for _ in train_ds.as_numpy_iterator()) * epochs\n",
    "warmup_steps = int(total_steps * 0.2)\n",
    "\n",
    "bert_classifier.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.AdamW(\n",
    "        TriangularSchedule(1e-4, warmup_steps, total_steps)\n",
    "    ),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "bert_classifier.fit(train_ds, validation_data=val_ds, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Success! With the learning rate scheduler and the `AdamW` optimizer, our validation\n",
    "accuracy improved to around 79%.\n",
    "\n",
    "Now, let's evaluate our final model on the test set and see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "bert_classifier.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Our Tiny BERT model achieved an accuracy of approximately 79% on the test set\n",
    "with the use of a learning rate scheduler. This is a significant improvement over\n",
    "our previous results. Fine-tuning a pretrained BERT\n",
    "model can be a powerful tool in natural language processing tasks, and even a\n",
    "small model like Tiny BERT can achieve impressive results.\n",
    "\n",
    "Let's save our model for now\n",
    "and move on to learning how to perform inference with it.\n",
    "\n",
    "## Save and Reload the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "bert_classifier.save(\"bert_classifier.keras\")\n",
    "restored_model = keras.models.load_model(\"bert_classifier.keras\")\n",
    "restored_model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Performing inference with the model.\n",
    "\n",
    "Let's see how to perform inference with KerasHub models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Convert to Hypothesis-Premise pair, for forward pass through model\n",
    "sample = (sample[\"hypothesis\"], sample[\"premise\"])\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "The default preprocessor in KerasHub models handles input tokenization automatically,\n",
    "so we don't need to perform tokenization explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "predictions = bert_classifier.predict(sample)\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.exp(x).sum(axis=0)\n",
    "\n",
    "\n",
    "# Get the class predictions with maximum probabilities\n",
    "predictions = softmax(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Improving accuracy with RoBERTa\n",
    "\n",
    "Now that we have established a baseline, we can attempt to improve our results\n",
    "by experimenting with different models. Thanks to KerasHub, fine-tuning a RoBERTa\n",
    "checkpoint on the same dataset is easy with just a few lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Inittializing a RoBERTa from preset\n",
    "roberta_classifier = keras_hub.models.RobertaClassifier.from_preset(\n",
    "    \"roberta_base_en\", num_classes=3\n",
    ")\n",
    "\n",
    "roberta_classifier.fit(train_ds, validation_data=val_ds, epochs=1)\n",
    "\n",
    "roberta_classifier.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "The RoBERTa base model has significantly more trainable parameters than the BERT\n",
    "Tiny model, with almost 30 times as many at 124,645,635 parameters. As a result, it took\n",
    "approximately 1.5 hours to train on a P100 GPU. However, the performance\n",
    "improvement was substantial, with accuracy increasing to 88% on both the validation\n",
    "and test splits. With RoBERTa, we were able to fit a maximum batch size of 16 on\n",
    "our P100 GPU.\n",
    "\n",
    "Despite using a different model, the steps to perform inference with RoBERTa are\n",
    "the same as with BERT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "predictions = roberta_classifier.predict(sample)\n",
    "print(tf.math.argmax(predictions, axis=1).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "We hope this tutorial has been helpful in demonstrating the ease and effectiveness\n",
    "of using KerasHub and BERT for semantic similarity tasks.\n",
    "\n",
    "Throughout this tutorial, we demonstrated how to use a pretrained BERT model to\n",
    "establish a baseline and improve performance by training a larger RoBERTa model\n",
    "using just a few lines of code.\n",
    "\n",
    "The KerasHub toolbox provides a range of modular building blocks for preprocessing\n",
    "text, including pretrained state-of-the-art models and low-level Transformer Encoder\n",
    "layers. We believe that this makes experimenting with natural language solutions\n",
    "more accessible and efficient."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "semantic_similarity_with_keras_hub",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}