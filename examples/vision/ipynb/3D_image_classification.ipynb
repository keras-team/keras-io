{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# 3D Image Classification from CT Scans\n",
    "\n",
    "**Author:** [Hasib Zunair](https://twitter.com/hasibzunair)<br>\n",
    "**Date created:** 2020/09/23<br>\n",
    "**Last modified:** 2020/09/23<br>\n",
    "**Description:** Train a 3D convolutional neural network to predict presence of pneumonia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This example will show the steps needed to build a 3D convolutional neural network (CNN)\n",
    "to predict the presence of viral pneumonia in computer tomography (CT) scans. 2D CNNs are\n",
    "commonly used to process RGB images (3 channels). A 3D CNN is simply the 3D\n",
    "equivalent: it takes as input a 3D volume or a sequence of 2D frames (e.g. slices in a CT scan),\n",
    "3D CNNs are a powerful model for learning representations for volumetric data.\n",
    "\n",
    "## References\n",
    "\n",
    "- [A survey on Deep Learning Advances on Different 3D DataRepresentations](https://arxiv.org/pdf/1808.01462.pdf)\n",
    "- [VoxNet: A 3D Convolutional Neural Network for Real-Time Object Recognition](https://www.ri.cmu.edu/pub_files/2015/9/voxnet_maturana_scherer_iros15.pdf)\n",
    "- [FusionNet: 3D Object Classification Using MultipleData Representations](http://3ddl.cs.princeton.edu/2016/papers/Hegde_Zadeh.pdf)\n",
    "- [Uniformizing Techniques to Process CT scans with 3D CNNs for Tuberculosis Prediction](https://arxiv.org/abs/2007.13224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Downloading the MosMedData:Chest CT Scans with COVID-19 Related Findings\n",
    "\n",
    "In this example, we use a subset of the\n",
    "[MosMedData: Chest CT Scans with COVID-19 Related\n",
    "Findings](https://www.medrxiv.org/content/10.1101/2020.05.20.20100362v1). This dataset\n",
    "consists of lung CT scans with COVID-19 related findings, as well as without such\n",
    "findings.\n",
    "\n",
    "We will be using the associated radiological findings of the CT scans as labels to build\n",
    "a classifier to predict presence of viral pneumonia.\n",
    "Hence, the task is a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Download url of normal CT scans.\n",
    "url = \"https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-0.zip\"\n",
    "filename = os.path.join(os.getcwd(), \"CT-0.zip\")\n",
    "keras.utils.get_file(filename, url)\n",
    "\n",
    "# Download url of abnormal CT scans.\n",
    "url = \"https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-1.zip\"\n",
    "filename = os.path.join(os.getcwd(), \"CT-1.zip\")\n",
    "keras.utils.get_file(filename, url)\n",
    "\n",
    "# Make a directory to store the data.\n",
    "os.makedirs(\"MosMedData\")\n",
    "\n",
    "# Unzip data in the newly created directory.\n",
    "with zipfile.ZipFile(\"CT-0.zip\", \"r\") as z_fp:\n",
    "    z_fp.extractall(\"./MosMedData/\")\n",
    "\n",
    "with zipfile.ZipFile(\"CT-1.zip\", \"r\") as z_fp:\n",
    "    z_fp.extractall(\"./MosMedData/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Load data\n",
    "\n",
    "The files are provided in Nifti format with the extension .nii. To read the\n",
    "scans, we use the `nibabel` package.\n",
    "You can install the package via `pip install nibabel`.\n",
    "\n",
    "To process the data, we do the following:\n",
    "\n",
    "* We first rotate the volumes by 90 degrees, so the orientation is fixed\n",
    "* We resize width, height and depth.\n",
    "\n",
    "Here we define several helper functions to process the data. These functions\n",
    "will be used when building training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import cv2\n",
    "\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "\n",
    "def read_nifti_file(filepath):\n",
    "    \"\"\"Read and load volume\"\"\"\n",
    "    # read file\n",
    "    scan = nib.load(filepath)\n",
    "    # get raw data\n",
    "    scan = scan.get_fdata()\n",
    "    # rotate\n",
    "    scan = np.rot90(np.array(scan))\n",
    "    return scan\n",
    "\n",
    "\n",
    "def resize_slices(img):\n",
    "    \"\"\"Resize width and height\"\"\"\n",
    "    # resize all slices\n",
    "    flatten = [\n",
    "        cv2.resize(img[:, :, i], (128, 128), interpolation=cv2.INTER_CUBIC)\n",
    "        for i in range(img.shape[-1])\n",
    "    ]\n",
    "    # stack along the z-axis\n",
    "    img = np.array(np.dstack(flatten))\n",
    "    return img\n",
    "\n",
    "\n",
    "def resize_depth(img):\n",
    "    \"\"\"Resize across z-axis\"\"\"\n",
    "    # set the desired depth\n",
    "    desired_depth = 64\n",
    "    # get current depth\n",
    "    current_depth = img.shape[-1]\n",
    "    # compute depth factor\n",
    "    depth = current_depth / desired_depth\n",
    "    depth_factor = 1 / depth\n",
    "    # resize across z-axis\n",
    "    img_new = zoom(img, (1, 1, depth_factor), mode=\"nearest\")\n",
    "    return img_new\n",
    "\n",
    "\n",
    "def process_scan(path):\n",
    "    \"\"\"Read and resize volume\"\"\"\n",
    "    # read scan\n",
    "    volume = read_nifti_file(path)\n",
    "    # resize width and height\n",
    "    volume = resize_slices(volume)\n",
    "    # resize across z-axis\n",
    "    volume = resize_depth(volume)\n",
    "    return volume\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Let's read the paths of the CT scans from the class directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Folder \"CT-0\" consist of CT scans having normal lung tissue,\n",
    "# no CT-signs of viral pneumonia.\n",
    "normal_scan_paths = [\n",
    "    os.path.join(os.getcwd(), \"MosMedData/CT-0\", x)\n",
    "    for x in os.listdir(\"MosMedData/CT-0\")\n",
    "]\n",
    "# Folder \"CT-1\" consist of CT scans having several ground-glass opacifications,\n",
    "# involvement of lung parenchyma.\n",
    "abnormal_scan_paths = [\n",
    "    os.path.join(os.getcwd(), \"MosMedData/CT-1\", x)\n",
    "    for x in os.listdir(\"MosMedData/CT-1\")\n",
    "]\n",
    "\n",
    "print(\"CT scans with normal lung tissue: \" + str(len(normal_scan_paths)))\n",
    "print(\"CT scans with abnormal lung tissue: \" + str(len(abnormal_scan_paths)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Let's visualize a CT scan and it's shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read a scan.\n",
    "img = read_nifti_file(normal_scan_paths[15])\n",
    "print(\"Dimension of the CT scan is:\", img.shape)\n",
    "plt.imshow(img[:, :, 15], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Since a CT scan has many slices, let's visualize a montage of the slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_slices(num_rows, num_columns, width, height, data):\n",
    "    \"\"\"Plot a montage of 20 CT slices\"\"\"\n",
    "    data = np.rot90(np.array(data))\n",
    "    data = np.transpose(data)\n",
    "    data = np.reshape(data, (num_rows, num_columns, width, height))\n",
    "    rows_data, columns_data = data.shape[0], data.shape[1]\n",
    "    heights = [slc[0].shape[0] for slc in data]\n",
    "    widths = [slc.shape[1] for slc in data[0]]\n",
    "    fig_width = 12.0\n",
    "    fig_height = fig_width * sum(heights) / sum(widths)\n",
    "    f, axarr = plt.subplots(\n",
    "        rows_data,\n",
    "        columns_data,\n",
    "        figsize=(fig_width, fig_height),\n",
    "        gridspec_kw={\"height_ratios\": heights},\n",
    "    )\n",
    "    for i in range(rows_data):\n",
    "        for j in range(columns_data):\n",
    "            axarr[i, j].imshow(data[i][j], cmap=\"gray\")\n",
    "            axarr[i, j].axis(\"off\")\n",
    "    plt.subplots_adjust(wspace=0, hspace=0, left=0, right=1, bottom=0, top=1)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Display 20 slices from the CT scan.\n",
    "# Here we visualize 20 slices, 2 rows and 10 columns\n",
    "# adapt it according to your need.\n",
    "plot_slices(2, 10, 512, 512, img[:, :, :20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Build train and validation datasets\n",
    "Read the scans from the class directories and assign labels. Downsample the scans to have\n",
    "shape of 128x128x64.\n",
    "Lastly, split the dataset into train and validation subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Read and process the scans.\n",
    "# Each scan is resized across width, height, and depth.\n",
    "abnormal_scans = np.array([process_scan(path) for path in abnormal_scan_paths])\n",
    "normal_scans = np.array([process_scan(path) for path in normal_scan_paths])\n",
    "\n",
    "# For the CT scans having presence of viral pneumonia\n",
    "# assign 1, for the normal ones assign 0.\n",
    "abnormal_labels = np.array([1 for _ in range(len(abnormal_scans))])\n",
    "normal_labels = np.array([0 for _ in range(len(normal_scans))])\n",
    "\n",
    "# Split data in the ratio 70-30 for training and validation.\n",
    "x_train = np.concatenate((abnormal_scans[:70], normal_scans[:70]), axis=0)\n",
    "y_train = np.concatenate((abnormal_labels[:70], normal_labels[:70]), axis=0)\n",
    "x_val = np.concatenate((abnormal_scans[70:], normal_scans[70:]), axis=0)\n",
    "y_val = np.concatenate((abnormal_labels[70:], normal_labels[70:]), axis=0)\n",
    "print(\n",
    "    \"Number of samples in train and validation are %d and %d.\"\n",
    "    % (x_train.shape[0], x_val.shape[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Preprocessing and data augmentation\n",
    "\n",
    "CT scans store raw voxel intensity in Hounsfield units (HU). They range from\n",
    "-1024 to above 2000 in this dataset. Above 400 are bones with different\n",
    "radiointensity, so this is used as a higher bound. A threshold between\n",
    "-1000 and 400 is commonly used to normalize CT scans. The CT scans are\n",
    "also augmented by rotating and blurring. There are different kinds of\n",
    "preprocessing and augmentation techniques out there, this example shows a few\n",
    "simple ones to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def normalize(volume):\n",
    "    \"\"\"Normalize the volume\"\"\"\n",
    "    min = -1000\n",
    "    max = 400\n",
    "    volume = volume - min / max - min\n",
    "    volume_min = tf.reduce_min(volume)\n",
    "    volume_max = tf.reduce_max(volume)\n",
    "    normalized_volume = (volume - volume_min) / (volume_max - volume_min)\n",
    "    normalized_volume = tf.expand_dims(normalized_volume, axis=3)\n",
    "    return normalized_volume\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def rotate(volume):\n",
    "    \"\"\"Rotate the volume by a few degrees\"\"\"\n",
    "\n",
    "    def scipy_rotate(volume):\n",
    "        # define some rotation angles\n",
    "        angles = [-20, -10, -5, 5, 10, 20]\n",
    "        # pick angles at random\n",
    "        angle = random.choice(angles)\n",
    "        # rotate volume\n",
    "        volume = ndimage.rotate(volume, angle, reshape=False)\n",
    "        return volume\n",
    "\n",
    "    augmented_volume = tf.numpy_function(scipy_rotate, [volume], tf.float64)\n",
    "    return augmented_volume\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def blur(volume):\n",
    "    \"\"\"Blur the volume\"\"\"\n",
    "\n",
    "    def scipy_blur(volume):\n",
    "        # gaussian blur\n",
    "        volume = gaussian_filter(volume, sigma=1)\n",
    "        return volume\n",
    "\n",
    "    augmented_volume = tf.numpy_function(scipy_blur, [volume], tf.float64)\n",
    "    return augmented_volume\n",
    "\n",
    "\n",
    "def train_preprocessing(volume, label):\n",
    "    \"\"\"Process training data by rotating, blur and normalizing.\"\"\"\n",
    "    # rotate data\n",
    "    volume = rotate(volume)\n",
    "    # blur data\n",
    "    volume = blur(volume)\n",
    "    # normalize\n",
    "    volume = normalize(volume)\n",
    "    return volume, label\n",
    "\n",
    "\n",
    "def validation_preprocessing(volume, label):\n",
    "    \"\"\"Process validation data by only normalizing.\"\"\"\n",
    "    volume = normalize(volume)\n",
    "    return volume, label\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "While defining the train and validation data loader, the training data is passed through\n",
    "and augmentation function which randomly rotates or blurs the volume and finally normalizes\n",
    "it to have values between 0 and 1. For the validation data, the volumes are only normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Define data loaders.\n",
    "train_loader = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "validation_loader = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "\n",
    "batch_size = 2\n",
    "# Augment the on the fly during training.\n",
    "train_dataset = (\n",
    "    train_loader.shuffle(len(x_train))\n",
    "    .map(train_preprocessing)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(2)\n",
    ")\n",
    "# Only rescale.\n",
    "validation_dataset = (\n",
    "    validation_loader.shuffle(len(x_val))\n",
    "    .map(validation_preprocessing)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Visualize an augmented CT scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = train_dataset.take(1)\n",
    "images, labels = list(data)[0]\n",
    "images = images.numpy()\n",
    "image = images[0]\n",
    "print(\"Dimension of the CT scan is:\", image.shape)\n",
    "plt.imshow(np.squeeze(image[:, :, 30]), cmap=\"gray\")\n",
    "\n",
    "# Visualize montage of slices.\n",
    "# 10 rows and 10 columns for 100 slices of the CT scan.\n",
    "plot_slices(4, 10, 128, 128, image[:, :, :40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Define a 3D convolutional neural network\n",
    "\n",
    "To make the model easier to understand, we structure it into blocks.\n",
    "The architecture of the 3D CNN used in this example\n",
    "is based on [this paper](https://arxiv.org/abs/2007.13224)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_model(width=128, height=128, depth=64):\n",
    "    \"\"\"build a 3D convolutional neural network model\"\"\"\n",
    "\n",
    "    inputs = keras.Input((width, height, depth, 1))\n",
    "\n",
    "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling3D()(x)\n",
    "    x = layers.Dense(units=512, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    # Define the model.\n",
    "    model = keras.Model(inputs, outputs, name=\"3dcnn\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# Build model.\n",
    "model = get_model(width=128, height=128, depth=64)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Compile model.\n",
    "initial_learning_rate = 0.0001\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    ")\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    metrics=[\"acc\"],\n",
    ")\n",
    "\n",
    "# Define callbacks.\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    \"3d_image_classification.h5\", save_best_only=True\n",
    ")\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_acc\", patience=10)\n",
    "\n",
    "# Train the model, doing validation at the end of each epoch.\n",
    "epochs = 100\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "It is important to note that the number of samples is very small (only 200) and we don't\n",
    "specify a random seed. As such, you can expect significant variance in the results. The full dataset\n",
    "which consists of over 1000 CT scans can be found [here](https://www.medrxiv.org/content/10.1101/2020.05.20.20100362v1). Using the full\n",
    "dataset, an accuracy of 83% was achieved. A variability of 6-7% in the classification\n",
    "performance is observed in both cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Visualizing model performance\n",
    "\n",
    "Here the model accuracy and loss for the training and the validation sets are plotted.\n",
    "Since the validation set is class-balanced, accuracy provides an unbiased representation\n",
    "of the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 3))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, metric in enumerate([\"acc\", \"loss\"]):\n",
    "    ax[i].plot(model.history.history[metric])\n",
    "    ax[i].plot(model.history.history[\"val_\" + metric])\n",
    "    ax[i].set_title(\"Model {}\".format(metric))\n",
    "    ax[i].set_xlabel(\"epochs\")\n",
    "    ax[i].set_ylabel(metric)\n",
    "    ax[i].legend([\"train\", \"val\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Make predictions on a single CT scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Load best weights.\n",
    "model.load_weights(\"3d_image_classification.h5\")\n",
    "prediction = model.predict(np.expand_dims(x_val[0], axis=0))[0]\n",
    "scores = [1 - prediction[0], prediction[0]]\n",
    "\n",
    "class_names = [\"normal\", \"abnormal\"]\n",
    "for score, name in zip(scores, class_names):\n",
    "    print(\n",
    "        \"This model is %.2f percent confident that CT scan is %s\"\n",
    "        % ((100 * score), name)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "3D_image_classification",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}