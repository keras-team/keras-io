{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# CutMix data augmentation for image classification\n",
    "\n",
    "**Author:** [Sayan Nath](https://twitter.com/sayannath2350)<br>\n",
    "**Date created:** 2021/06/08<br>\n",
    "**Last modified:** 2021/06/08<br>\n",
    "**Description:** Data augmentation with CutMix for image classification on CIFAR-10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "_CutMix_ is a data augmentation technique that addresses the issue of information loss\n",
    "and inefficiency present in regional dropout strategies.\n",
    "Instead of removing pixels and filling them with black or grey pixels or Gaussian noise,\n",
    "you replace the removed regions with a patch from another image,\n",
    "while the ground truth labels are mixed proportionally to the number of pixels of combined images.\n",
    "CutMix was proposed in\n",
    "[CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features](https://arxiv.org/abs/1905.04899)\n",
    "(Yun et al., 2019)\n",
    "\n",
    "It's implemented via the following formulas:\n",
    "\n",
    "<img src=\"https://i.imgur.com/cGvd13V.png\" width=\"200\"/>\n",
    "\n",
    "where `M` is the binary mask which indicates the cutout and the fill-in\n",
    "regions from the two randomly drawn images and `Î»` (in `[0, 1]`) is drawn from a\n",
    "[`Beta(Î±, Î±)` distribution](https://en.wikipedia.org/wiki/Beta_distribution)\n",
    "\n",
    "The coordinates of bounding boxes are:\n",
    "\n",
    "<img src=\"https://i.imgur.com/eNisep4.png\" width=\"150\"/>\n",
    "\n",
    "which indicates the cutout and fill-in regions in case of the images.\n",
    "The bounding box sampling is represented by:\n",
    "\n",
    "<img src=\"https://i.imgur.com/Snph9aj.png\" width=\"200\"/>\n",
    "\n",
    "where `rx, ry` are randomly drawn from a uniform distribution with upper bound."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Load the CIFAR-10 dataset\n",
    "\n",
    "In this example, we will use the\n",
    "[CIFAR-10 image classification dataset](https://www.cs.toronto.edu/~kriz/cifar.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "class_names = [\n",
    "    \"Airplane\",\n",
    "    \"Automobile\",\n",
    "    \"Bird\",\n",
    "    \"Cat\",\n",
    "    \"Deer\",\n",
    "    \"Dog\",\n",
    "    \"Frog\",\n",
    "    \"Horse\",\n",
    "    \"Ship\",\n",
    "    \"Truck\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "AUTO = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Define the image preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_image(image, label):\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32) / 255.0\n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Convert the data into TensorFlow `Dataset` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "train_ds_one = (\n",
    "    tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    .shuffle(1024)\n",
    "    .map(preprocess_image, num_parallel_calls=AUTO)\n",
    ")\n",
    "train_ds_two = (\n",
    "    tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    .shuffle(1024)\n",
    "    .map(preprocess_image, num_parallel_calls=AUTO)\n",
    ")\n",
    "\n",
    "train_ds_simple = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "train_ds_simple = (\n",
    "    train_ds_simple.map(preprocess_image, num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "# Combine two shuffled datasets from the same training data.\n",
    "train_ds = tf.data.Dataset.zip((train_ds_one, train_ds_two))\n",
    "\n",
    "test_ds = (\n",
    "    test_ds.map(preprocess_image, num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Define the CutMix data augmentation function\n",
    "\n",
    "The CutMix function takes two `image` and `label` pairs to perform the augmentation. It samples `Î»(l)` from the [Beta distribution](https://en.wikipedia.org/wiki/Beta_distribution) and returns a bounding box from `get_box` function. We then crop the second image (`image2`) and pad this image in the final padded image at the same location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def sample_beta_distribution(size, concentration_0=0.2, concentration_1=0.2):\n",
    "    gamma_1_sample = tf.random.gamma(shape=[size], alpha=concentration_1)\n",
    "    gamma_2_sample = tf.random.gamma(shape=[size], alpha=concentration_0)\n",
    "    return gamma_1_sample / (gamma_1_sample + gamma_2_sample)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_box(lambda_value):\n",
    "    cut_rat = tf.math.sqrt(1.0 - lambda_value)\n",
    "\n",
    "    cut_w = IMG_SIZE * cut_rat  # rw\n",
    "    cut_w = tf.cast(cut_w, tf.int32)\n",
    "\n",
    "    cut_h = IMG_SIZE * cut_rat  # rh\n",
    "    cut_h = tf.cast(cut_h, tf.int32)\n",
    "\n",
    "    cut_x = tf.random.uniform((1,), minval=0, maxval=IMG_SIZE, dtype=tf.int32)  # rx\n",
    "    cut_y = tf.random.uniform((1,), minval=0, maxval=IMG_SIZE, dtype=tf.int32)  # ry\n",
    "\n",
    "    boundaryx1 = tf.clip_by_value(cut_x[0] - cut_w // 2, 0, IMG_SIZE)\n",
    "    boundaryy1 = tf.clip_by_value(cut_y[0] - cut_h // 2, 0, IMG_SIZE)\n",
    "    bbx2 = tf.clip_by_value(cut_x[0] + cut_w // 2, 0, IMG_SIZE)\n",
    "    bby2 = tf.clip_by_value(cut_y[0] + cut_h // 2, 0, IMG_SIZE)\n",
    "\n",
    "    target_h = bby2 - boundaryy1\n",
    "    if target_h == 0:\n",
    "        target_h += 1\n",
    "\n",
    "    target_w = bbx2 - boundaryx1\n",
    "    if target_w == 0:\n",
    "        target_w += 1\n",
    "\n",
    "    return boundaryx1, boundaryy1, target_h, target_w\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def cutmix(train_ds_one, train_ds_two):\n",
    "    (image1, label1), (image2, label2) = train_ds_one, train_ds_two\n",
    "\n",
    "    alpha = [0.25]\n",
    "    beta = [0.25]\n",
    "\n",
    "    # Get a sample from the Beta distribution\n",
    "    lambda_value = sample_beta_distribution(1, alpha, beta)\n",
    "\n",
    "    # Define Lambda\n",
    "    lambda_value = lambda_value[0][0]\n",
    "\n",
    "    # Get the bounding box offsets, heights and widths\n",
    "    boundaryx1, boundaryy1, target_h, target_w = get_box(lambda_value)\n",
    "\n",
    "    # Get a patch from the second image (`image2`)\n",
    "    crop2 = tf.image.crop_to_bounding_box(\n",
    "        image2, boundaryy1, boundaryx1, target_h, target_w\n",
    "    )\n",
    "    # Pad the `image2` patch (`crop2`) with the same offset\n",
    "    image2 = tf.image.pad_to_bounding_box(\n",
    "        crop2, boundaryy1, boundaryx1, IMG_SIZE, IMG_SIZE\n",
    "    )\n",
    "    # Get a patch from the first image (`image1`)\n",
    "    crop1 = tf.image.crop_to_bounding_box(\n",
    "        image1, boundaryy1, boundaryx1, target_h, target_w\n",
    "    )\n",
    "    # Pad the `image1` patch (`crop1`) with the same offset\n",
    "    img1 = tf.image.pad_to_bounding_box(\n",
    "        crop1, boundaryy1, boundaryx1, IMG_SIZE, IMG_SIZE\n",
    "    )\n",
    "\n",
    "    # Modify the first image by subtracting the patch from `image1`\n",
    "    # (before applying the `image2` patch)\n",
    "    image1 = image1 - img1\n",
    "    # Add the modified `image1` and `image2`  together to get the CutMix image\n",
    "    image = image1 + image2\n",
    "\n",
    "    # Adjust Lambda in accordance to the pixel ration\n",
    "    lambda_value = 1 - (target_w * target_h) / (IMG_SIZE * IMG_SIZE)\n",
    "    lambda_value = tf.cast(lambda_value, tf.float32)\n",
    "\n",
    "    # Combine the labels of both images\n",
    "    label = lambda_value * label1 + (1 - lambda_value) * label2\n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Note**: we are combining two images to create a single one.\n",
    "\n",
    "## Visualize the new dataset after applying the CutMix augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Create the new dataset using our `cutmix` utility\n",
    "train_ds_cmu = (\n",
    "    train_ds.shuffle(1024)\n",
    "    .map(cutmix, num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "# Let's preview 9 samples from the dataset\n",
    "image_batch, label_batch = next(iter(train_ds_cmu))\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.title(class_names[np.argmax(label_batch[i])])\n",
    "    plt.imshow(image_batch[i])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Define a ResNet-20 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def resnet_layer(\n",
    "    inputs,\n",
    "    num_filters=16,\n",
    "    kernel_size=3,\n",
    "    strides=1,\n",
    "    activation=\"relu\",\n",
    "    batch_normalization=True,\n",
    "    conv_first=True,\n",
    "):\n",
    "    conv = keras.layers.Conv2D(\n",
    "        num_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        strides=strides,\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "        kernel_regularizer=keras.regularizers.l2(1e-4),\n",
    "    )\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = keras.layers.Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = keras.layers.Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet_v20(input_shape, depth, num_classes=10):\n",
    "    if (depth - 2) % 6 != 0:\n",
    "        raise ValueError(\"depth should be 6n+2 (eg 20, 32, 44 in [a])\")\n",
    "    # Start model definition.\n",
    "    num_filters = 16\n",
    "    num_res_blocks = int((depth - 2) / 6)\n",
    "\n",
    "    inputs = keras.layers.Input(shape=input_shape)\n",
    "    x = resnet_layer(inputs=inputs)\n",
    "    # Instantiate the stack of residual units\n",
    "    for stack in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            strides = 1\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                strides = 2  # downsample\n",
    "            y = resnet_layer(inputs=x, num_filters=num_filters, strides=strides)\n",
    "            y = resnet_layer(inputs=y, num_filters=num_filters, activation=None)\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(\n",
    "                    inputs=x,\n",
    "                    num_filters=num_filters,\n",
    "                    kernel_size=1,\n",
    "                    strides=strides,\n",
    "                    activation=None,\n",
    "                    batch_normalization=False,\n",
    "                )\n",
    "            x = keras.layers.add([x, y])\n",
    "            x = keras.layers.Activation(\"relu\")(x)\n",
    "        num_filters *= 2\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v1 does not use BN after last shortcut connection-ReLU\n",
    "    x = keras.layers.AveragePooling2D(pool_size=8)(x)\n",
    "    y = keras.layers.Flatten()(x)\n",
    "    outputs = keras.layers.Dense(\n",
    "        num_classes, activation=\"softmax\", kernel_initializer=\"he_normal\"\n",
    "    )(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def training_model():\n",
    "    return resnet_v20((32, 32, 3), 20)\n",
    "\n",
    "\n",
    "initial_model = training_model()\n",
    "initial_model.save_weights(\"initial_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Train the model with the dataset augmented by CutMix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = training_model()\n",
    "model.load_weights(\"initial_weights.h5\")\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(train_ds_cmu, validation_data=test_ds, epochs=15)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "print(\"Test accuracy: {:.2f}%\".format(test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Train the model using the original non-augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = training_model()\n",
    "model.load_weights(\"initial_weights.h5\")\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(train_ds_simple, validation_data=test_ds, epochs=15)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "print(\"Test accuracy: {:.2f}%\".format(test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Notes\n",
    "\n",
    "In this example, we trained our model for 15 epochs.\n",
    "In our experiment, the model with CutMix achieves a better accuracy on the CIFAR-10 dataset\n",
    "(80.36% in our experiment) compared to the model that doesn't use the augmentation (72.70%).\n",
    "You may notice it takes less time to train the model with the CutMix augmentation.\n",
    "\n",
    "You can experiment further with the CutMix technique by following the\n",
    "[original paper](https://arxiv.org/abs/1905.04899).\n",
    "Example available on HuggingFace.\n",
    "| Trained Model | Demo |\n",
    "| :--: | :--: |\n",
    "| [![Generic badge](https://img.shields.io/badge/ðŸ¤—%20Model-CutMix%20Data%20augmentation-black.svg)](https://huggingface.co/keras-io/CutMix_data_augmentation_for_image_classification) | [![Generic badge](https://img.shields.io/badge/ðŸ¤—%20Spaces-CutMix%20Data%20augmentation-black.svg)](https://huggingface.co/spaces/keras-io/CutMix_Data_Augmentation_for_Image_Classification) |"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "cutmix",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
