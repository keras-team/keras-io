{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33c74727"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This tutorial demonstrates how to use the Deep Learning Recommendation Model (DLRM) to effectively learn the relationships between items and user preferences using a dot-product interaction mechanism. For more details, please refer to the [DLRM](https://arxiv.org/pdf/1906.00091) paper.\n",
        "\n",
        "DLRM is designed to excel at capturing explicit, bounded-degree feature interactions and is particularly effective at processing both categorical and continuous (sparse/dense) input features. The architecture consists of three main components: dedicated input layers to handle diverse features (typically embedding layers for categorical features), a dot-product interaction layer to explicitly model feature interactions, and a Multi-Layer Perceptron (MLP) to capture implicit feature relationships.\n",
        "\n",
        "The dot-product interaction layer lies at the heart of DLRM, efficiently computing pairwise interactions between different feature embeddings. This contrasts with models like Deep & Cross Network (DCN), which can treat elements within a feature vector as independent units, potentially leading to a higher-dimensional space and increased computational cost. The MLP is a standard feedforward network. The DLRM is formed by combining the interaction layer and MLP.\n",
        "\n",
        "The following image illustrates the DLRM architecture:\n",
        "\n",
        "![DLRM Architecture](https://raw.githubusercontent.com/kharshith-k/keras-io/refs/heads/keras-rs-examples/examples/keras_rs/img/dlrm/dlrm_architecture.gif)\n",
        "\n",
        "\n",
        "Now that we have a foundational understanding of DLRM's architecture and key characteristics, let's dive into the code. We will train a DLRM on a real-world dataset to demonstrate its capability to learn meaningful feature interactions. Let's begin by setting the backend to JAX and organizing our imports."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blj4_0Wg62kR"
      },
      "outputs": [],
      "source": [
        "!pip install keras-rs -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeFXrN1962kT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # `\"tensorflow\"`/`\"torch\"`\n",
        "\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "import keras_rs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHdT0D1762kT"
      },
      "source": [
        "Let's also define variables which will be reused throughout the example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRJOAiMv62kT"
      },
      "outputs": [],
      "source": [
        "MOVIELENS_CONFIG = {\n",
        "    # features\n",
        "    \"continuous_features\": [\n",
        "        \"raw_user_age\",\n",
        "        \"timestamp\",\n",
        "    ],\n",
        "    \"categorical_int_features\": [\n",
        "        \"user_gender\",\n",
        "    ],\n",
        "    \"categorical_str_features\": [\n",
        "        \"user_zip_code\",\n",
        "        \"user_occupation_text\",\n",
        "        \"movie_id\",\n",
        "        \"user_id\",\n",
        "    ],\n",
        "    # model\n",
        "    \"embedding_dim\": 8,\n",
        "    \"mlp_dim\": 8,\n",
        "    \"deep_net_num_units\": [192, 192, 192],\n",
        "    # training\n",
        "    \"learning_rate\": 1e-4,\n",
        "    \"num_epochs\": 30,\n",
        "    \"batch_size\": 8192,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6J6XFNC62kT"
      },
      "source": [
        "Here, we define a helper function for visualising weights of the cross layer in\n",
        "order to better understand its functioning. Also, we define a function for\n",
        "compiling, training and evaluating a given model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyojSTKw62kT"
      },
      "outputs": [],
      "source": [
        "def plot_training_metrics(history):\n",
        "    \"\"\"Graphs all metrics tracked in the history object.\"\"\"\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    for metric_name, metric_values in history.history.items():\n",
        "        plt.plot(metric_values, label=metric_name.replace('_', ' ').title())\n",
        "\n",
        "    plt.title('Metrics over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Metric Value')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "def visualize_layer(matrix, features, cmap=plt.cm.Blues):\n",
        "\n",
        "    im = plt.matshow(matrix, cmap=cmap, extent=[-0.5, len(features)-0.5, len(features)-0.5, -0.5])\n",
        "\n",
        "    ax = plt.gca()\n",
        "    divider = make_axes_locatable(plt.gca())\n",
        "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "    plt.colorbar(im, cax=cax)\n",
        "    cax.tick_params(labelsize=10)\n",
        "\n",
        "    # Set tick locations explicitly before setting labels\n",
        "    ax.set_xticks(np.arange(len(features)))\n",
        "    ax.set_yticks(np.arange(len(features)))\n",
        "\n",
        "    ax.set_xticklabels(features, rotation=45, fontsize=5)\n",
        "    ax.set_yticklabels(features, fontsize=5)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def train_and_evaluate(\n",
        "    learning_rate,\n",
        "    epochs,\n",
        "    train_data,\n",
        "    test_data,\n",
        "    model,\n",
        "    plot_metrics=False,\n",
        "):\n",
        "    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate, clipnorm=1.0)\n",
        "    loss = keras.losses.MeanSquaredError()\n",
        "    rmse = keras.metrics.RootMeanSquaredError()\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=loss,\n",
        "        metrics=[rmse],\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        train_data,\n",
        "        epochs=epochs,\n",
        "        verbose=1,\n",
        "    )\n",
        "    if plot_metrics:\n",
        "      plot_training_metrics(history)\n",
        "\n",
        "    results = model.evaluate(test_data, return_dict=True, verbose=1)\n",
        "    rmse_value = results[\"root_mean_squared_error\"]\n",
        "\n",
        "    return rmse_value, model.count_params()\n",
        "\n",
        "\n",
        "def print_stats(rmse_list, num_params, model_name):\n",
        "    # Report metrics.\n",
        "    num_trials = len(rmse_list)\n",
        "    avg_rmse = np.mean(rmse_list)\n",
        "    std_rmse = np.std(rmse_list)\n",
        "\n",
        "    if num_trials == 1:\n",
        "        print(f\"{model_name}: RMSE = {avg_rmse}; #params = {num_params}\")\n",
        "    else:\n",
        "        print(f\"{model_name}: RMSE = {avg_rmse} Â± {std_rmse}; #params = {num_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVHJBIJ_62kV"
      },
      "source": [
        "## Real-world example\n",
        "\n",
        "Let's use the MovieLens 100K dataset. This dataset is used to train models to\n",
        "predict users' movie ratings, based on user-related features and movie-related\n",
        "features.\n",
        "\n",
        "### Preparing the dataset\n",
        "\n",
        "The dataset processing steps here are similar to what's given in the\n",
        "[basic ranking](/keras_rs/examples/basic_ranking/)\n",
        "tutorial. Let's load the dataset, and keep only the useful columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kipGDLuZ62kW"
      },
      "outputs": [],
      "source": [
        "ratings_ds = tfds.load(\"movielens/100k-ratings\", split=\"train\", download_and_prepare_kwargs={\n",
        "    \"download_config\": tfds.download.DownloadConfig(\n",
        "        verify_ssl=False,\n",
        "    )\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwF0m8Mv-DIl"
      },
      "outputs": [],
      "source": [
        "ratings_ds = ratings_ds.map(\n",
        "    lambda x: (\n",
        "        {\n",
        "            \"movie_id\": x[\"movie_id\"],\n",
        "            \"user_id\": x[\"user_id\"],\n",
        "            \"user_gender\": tf.cast(x[\"user_gender\"], dtype=tf.int32),\n",
        "            \"user_zip_code\": x[\"user_zip_code\"],\n",
        "            \"user_occupation_text\": x[\"user_occupation_text\"],\n",
        "            \"raw_user_age\": tf.cast(x[\"raw_user_age\"], dtype=tf.float32),\n",
        "            \"timestamp\": tf.cast(x[\"timestamp\"], dtype=tf.float32),\n",
        "        },\n",
        "        tf.cast(x[\"user_rating\"], dtype=tf.float32),\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DrNFuZi62kW"
      },
      "source": [
        "For every categorical feature, let's get the list of unique values, i.e., vocabulary, so\n",
        "that we can use that for the embedding layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8JF-C9SsfLg"
      },
      "outputs": [],
      "source": [
        "vocabularies = {}\n",
        "for feature_name in MOVIELENS_CONFIG[\"categorical_int_features\"] + MOVIELENS_CONFIG[\"categorical_str_features\"]:\n",
        "    vocabulary = ratings_ds.batch(10_000).map(lambda x, y: x[feature_name])\n",
        "    vocabularies[feature_name] = np.unique(np.concatenate(list(vocabulary)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PLhYqF062kW"
      },
      "source": [
        "One thing we need to do is to use `keras.layers.StringLookup` and\n",
        "`keras.layers.IntegerLookup` to convert all the categorical features into indices, which can then be fed into embedding layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfZ19mDitzS3"
      },
      "outputs": [],
      "source": [
        "lookup_layers = {}\n",
        "lookup_layers.update(\n",
        "    {\n",
        "        feature: keras.layers.IntegerLookup(vocabulary=vocabularies[feature])\n",
        "        for feature in MOVIELENS_CONFIG[\"categorical_int_features\"]\n",
        "    }\n",
        ")\n",
        "lookup_layers.update(\n",
        "    {\n",
        "        feature: keras.layers.StringLookup(vocabulary=vocabularies[feature])\n",
        "        for feature in MOVIELENS_CONFIG[\"categorical_str_features\"]\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's normalize all the continuous features, so that we can use that for the MLP layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rjnQQU9Qh8s"
      },
      "outputs": [],
      "source": [
        "normalization_layers = {}\n",
        "for feature_name in MOVIELENS_CONFIG[\"continuous_features\"]:\n",
        "    normalization_layers[feature_name] = keras.layers.Normalization(axis=-1)\n",
        "\n",
        "training_data_for_adaptation = ratings_ds.take(80_000).map(lambda x, y: x)\n",
        "\n",
        "for feature_name in MOVIELENS_CONFIG[\"continuous_features\"]:\n",
        "    feature_ds = training_data_for_adaptation.map(lambda x: tf.expand_dims(x[feature_name], axis=-1))\n",
        "    normalization_layers[feature_name].adapt(feature_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdpE2nWbdAZn"
      },
      "outputs": [],
      "source": [
        "ratings_ds = ratings_ds.map(\n",
        "    lambda x, y: (\n",
        "        {\n",
        "            **{\n",
        "                feature_name: lookup_layers[feature_name](x[feature_name])\n",
        "                for feature_name in vocabularies\n",
        "            },\n",
        "            # Apply the adapted normalization layers to the continuous features.\n",
        "            **{\n",
        "                feature_name: tf.squeeze(\n",
        "                    normalization_layers[feature_name](tf.expand_dims(x[feature_name], axis=-1)),\n",
        "                    axis=-1\n",
        "                )\n",
        "                for feature_name in MOVIELENS_CONFIG[\"continuous_features\"]\n",
        "            }\n",
        "        },\n",
        "        y,\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBKk-mX962kW"
      },
      "source": [
        "Let's split our data into train and test sets. We also use `cache()` and\n",
        "`prefetch()` for better performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ha3v4rHN62kW"
      },
      "outputs": [],
      "source": [
        "ratings_ds = ratings_ds.shuffle(100_000)\n",
        "\n",
        "train_ds = (\n",
        "    ratings_ds.take(80_000)\n",
        "    .batch(MOVIELENS_CONFIG[\"batch_size\"])\n",
        "    .cache()\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "test_ds = (\n",
        "    ratings_ds.skip(80_000)\n",
        "    .batch(MOVIELENS_CONFIG[\"batch_size\"])\n",
        "    .take(20_000)\n",
        "    .cache()\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXuXvsl062kW"
      },
      "source": [
        "### Building the model\n",
        "\n",
        "The model will have embedding layers for categorical features, dense layer for continuous features followed by DotInteraction and feedforward\n",
        "layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ww3ZJ6R062kW"
      },
      "outputs": [],
      "source": [
        "class DLRM(keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dense_num_units_lst,\n",
        "        embedding_dim=MOVIELENS_CONFIG[\"embedding_dim\"],\n",
        "        mlp_dim=MOVIELENS_CONFIG[\"mlp_dim\"],\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        # Layers for categorical features.\n",
        "        self.embedding_layers = {}\n",
        "        for feature_name in MOVIELENS_CONFIG[\"categorical_int_features\"] + MOVIELENS_CONFIG['categorical_str_features']:\n",
        "            vocab_size = len(vocabularies[feature_name]) + 1 # +1 for OOV token\n",
        "            self.embedding_layers[feature_name] = keras.layers.Embedding(\n",
        "                    input_dim=vocab_size,\n",
        "                    output_dim=embedding_dim,\n",
        "                )\n",
        "\n",
        "        # Layers for continuous features.\n",
        "        self.continuous_dense_layers = {}\n",
        "        for feature_name in MOVIELENS_CONFIG[\"continuous_features\"]:\n",
        "             # Use a small MLP to process continuous features\n",
        "            self.continuous_dense_layers[feature_name] = keras.Sequential([\n",
        "                keras.layers.Dense(mlp_dim, activation=\"relu\"),\n",
        "                keras.layers.Dense(mlp_dim),\n",
        "            ])\n",
        "\n",
        "\n",
        "        self.dot_layer = keras_rs.layers.DotInteraction()\n",
        "\n",
        "        self.dense_layers = []\n",
        "        for num_units in dense_num_units_lst:\n",
        "            self.dense_layers.append(keras.layers.Dense(num_units, activation=\"relu\"))\n",
        "\n",
        "        self.output_layer = keras.layers.Dense(1)\n",
        "\n",
        "        # Attributes.\n",
        "        self.dense_num_units_lst = dense_num_units_lst\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        embeddings = []\n",
        "        for feature_name in MOVIELENS_CONFIG[\"categorical_int_features\"] + MOVIELENS_CONFIG['categorical_str_features']:\n",
        "            embedding = self.embedding_layers[feature_name](inputs[feature_name])\n",
        "            embeddings.append(embedding)\n",
        "\n",
        "\n",
        "        # Process continuous features\n",
        "        continuous_vectors = []\n",
        "        for feature_name in MOVIELENS_CONFIG[\"continuous_features\"]:\n",
        "            continuous_input = keras.ops.reshape(\n",
        "                keras.ops.cast(inputs[feature_name], dtype=\"float32\"), (-1, 1)\n",
        "            )\n",
        "            processed_continuous = self.continuous_dense_layers[feature_name](continuous_input)\n",
        "            continuous_vectors.append(processed_continuous)\n",
        "\n",
        "        # Combine continuous vectors and categorical embeddings\n",
        "        combined_features = embeddings + continuous_vectors\n",
        "\n",
        "        # Pass the list of combined features to the DotInteraction layer\n",
        "        x = self.dot_layer(combined_features)\n",
        "\n",
        "        for dense_layer in self.dense_layers:\n",
        "            x = dense_layer(x)\n",
        "\n",
        "        x = self.output_layer(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAoTyyzi_Nau"
      },
      "outputs": [],
      "source": [
        "dot_network = DLRM(\n",
        "    dense_num_units_lst=MOVIELENS_CONFIG[\"deep_net_num_units\"],\n",
        "    embedding_dim=MOVIELENS_CONFIG[\"embedding_dim\"],\n",
        "    mlp_dim=MOVIELENS_CONFIG[\"mlp_dim\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UqPO_2oEHDVy",
        "outputId": "351920d4-677b-4b02-bdcb-0002af9eae3a"
      },
      "outputs": [],
      "source": [
        "rmse, dot_network_num_params = train_and_evaluate(\n",
        "    learning_rate=MOVIELENS_CONFIG[\"learning_rate\"],\n",
        "    epochs=MOVIELENS_CONFIG[\"num_epochs\"],\n",
        "    train_data=train_ds,\n",
        "    test_data=test_ds,\n",
        "    model= dot_network,\n",
        "    plot_metrics=True\n",
        ")\n",
        "print_stats(\n",
        "    rmse_list=[rmse],\n",
        "    num_params=dot_network_num_params,\n",
        "    model_name=\"Dot Network\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E68GrcDN62kW"
      },
      "source": [
        "### Visualizing feature interactions\n",
        "\n",
        "The DotInteraction layer itself doesn't have a conventional \"weight\" matrix like a Dense layer. Instead, its function is to compute the dot product between the embedding vectors of your features.\n",
        "\n",
        "To visualize the strength of these interactions, we can calculate a matrix representing the pairwise interaction strength between all feature embeddings. A common way to do this is to take the dot product of the embedding matrices for each pair of features and then aggregate the result into a single value (like the mean of the absolute values) that represents the overall interaction strength."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "qPLjyv7V8GGB",
        "outputId": "ca51f005-2d8b-4711-dd76-24d547402fac"
      },
      "outputs": [],
      "source": [
        "def get_dot_interaction_matrix(model, categorical_features, continuous_features):\n",
        "    all_feature_names = categorical_features + continuous_features\n",
        "    num_features = len(all_feature_names)\n",
        "\n",
        "    # Store all feature outputs in the correct order.\n",
        "    all_feature_outputs = []\n",
        "\n",
        "    # Get outputs for categorical features from embedding layers.\n",
        "    for feature_name in categorical_features:\n",
        "        # Pass a dummy input (index 0) to get the embedding vector for each categorical feature\n",
        "        embedding = model.embedding_layers[feature_name](keras.ops.array([0]))\n",
        "        all_feature_outputs.append(embedding)\n",
        "\n",
        "    # Get outputs for continuous features from dense layers by passing a dummy input.\n",
        "    for feature_name in continuous_features:\n",
        "        # Pass a dummy input (value 0.0) to the continuous dense layer\n",
        "        processed_continuous = model.continuous_dense_layers[feature_name](keras.ops.array([[0.0]]))\n",
        "        all_feature_outputs.append(processed_continuous)\n",
        "\n",
        "    interaction_matrix = np.zeros((num_features, num_features))\n",
        "\n",
        "    # Iterate through each pair of features to calculate their interaction strength.\n",
        "    for i in range(num_features):\n",
        "        for j in range(num_features):\n",
        "            # Calculate the dot product between the two feature output vectors\n",
        "            interaction = keras.ops.dot(all_feature_outputs[i], keras.ops.transpose(all_feature_outputs[j]))\n",
        "\n",
        "            # Take the absolute value as a measure of interaction strength.\n",
        "            # Since the output is a scalar (dot product of two vectors), we just take the absolute value.\n",
        "            interaction_strength = keras.ops.convert_to_numpy(np.abs(interaction))[0][0]\n",
        "            interaction_matrix[i, j] = interaction_strength\n",
        "\n",
        "    return interaction_matrix\n",
        "\n",
        "# Get the list of feature names in the correct order.\n",
        "feature_names = MOVIELENS_CONFIG[\"categorical_int_features\"] + MOVIELENS_CONFIG['categorical_str_features'] + MOVIELENS_CONFIG[\"continuous_features\"]\n",
        "\n",
        "# Calculate the interaction matrix with the corrected function.\n",
        "interaction_matrix = get_dot_interaction_matrix(\n",
        "    model=dot_network,\n",
        "    categorical_features=MOVIELENS_CONFIG[\"categorical_int_features\"] + MOVIELENS_CONFIG['categorical_str_features'],\n",
        "    continuous_features=MOVIELENS_CONFIG[\"continuous_features\"]\n",
        ")\n",
        "\n",
        "# Visualize the matrix as a heatmap.\n",
        "print(\"\\nVisualizing the feature interaction strengths (corrected):\")\n",
        "visualize_layer(interaction_matrix, feature_names)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
