{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Deep Recommenders\n",
    "\n",
    "**Author:** [Fabien Hertschuh](https://github.com/hertschuh/), [Abheesht Sharma](https://github.com/abheesht17/)<br>\n",
    "**Date created:** 2025/04/28<br>\n",
    "**Last modified:** 2025/04/28<br>\n",
    "**Description:** Building a deep retrieval model with multiple stacked layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "One of the great advantages of using Keras to build recommender models is the\n",
    "freedom to build rich, flexible feature representations.\n",
    "\n",
    "The first step in doing so is preparing the features, as raw features will\n",
    "usually not be immediately usable in a model.\n",
    "\n",
    "For example:\n",
    "\n",
    "- User and item IDs may be strings (titles, usernames) or large, non-contiguous\n",
    "  integers (database IDs).\n",
    "- Item descriptions could be raw text.\n",
    "- Interaction timestamps could be raw Unix timestamps.\n",
    "\n",
    "These need to be appropriately transformed in order to be useful in building\n",
    "models:\n",
    "\n",
    "- User and item IDs have to be translated into embedding vectors,\n",
    "  high-dimensional numerical representations that are adjusted during training\n",
    "  to help the model predict its objective better.\n",
    "- Raw text needs to be tokenized (split into smaller parts such as individual\n",
    "  words) and translated into embeddings.\n",
    "- Numerical features need to be normalized so that their values lie in a small\n",
    "  interval around 0.\n",
    "\n",
    "Fortunately, the Keras\n",
    "[`FeatureSpace`](/api/utils/feature_space/) utility makes this\n",
    "preprocessing easy.\n",
    "\n",
    "In this tutorial, we are going to incorporate multiple features in our models.\n",
    "These features will come from preprocessing the MovieLens dataset.\n",
    "\n",
    "In the\n",
    "[basic retrieval](/keras_rs/examples/basic_retrieval/)\n",
    "tutorial, the models consist of only an embedding layer. In this tutorial, we\n",
    "add more dense layers to our models to increase their expressive power.\n",
    "\n",
    "In general, deeper models are capable of learning more complex patterns than\n",
    "shallower models. For example, our user model incorporates user IDs and user\n",
    "features such as age, gender and occupation. A shallow model (say, a single\n",
    "embedding layer) may only be able to learn the simplest relationships between\n",
    "those features and movies: a given user generally prefers horror movies to\n",
    "comedies. To capture more complex relationships, such as user preferences\n",
    "evolving with their age, we may need a deeper model with multiple stacked dense\n",
    "layers.\n",
    "\n",
    "Of course, complex models also have their disadvantages. The first is\n",
    "computational cost, as larger models require both more memory and more\n",
    "computation to train and serve. The second is the requirement for more data. In\n",
    "general, more training data is needed to take advantage of deeper models. With\n",
    "more parameters, deep models might overfit or even simply memorize the training\n",
    "examples instead of learning a function that can generalize. Finally, training\n",
    "deeper models may be harder, and more care needs to be taken in choosing\n",
    "settings like regularization and learning rate.\n",
    "\n",
    "Finding a good architecture for a real-world recommender system is a complex\n",
    "art, requiring good intuition and careful hyperparameter tuning. For example,\n",
    "factors such as the depth and width of the model, activation function, learning\n",
    "rate, and optimizer can radically change the performance of the model. Modelling\n",
    "choices are further complicated by the fact that good offline evaluation metrics\n",
    "may not correspond to good online performance, and that the choice of what to\n",
    "optimize for is often more critical than the choice of model itself.\n",
    "\n",
    "Nevertheless, effort put into building and fine-tuning larger models often pays\n",
    "off. In this tutorial, we will illustrate how to build a deep retrieval model.\n",
    "We'll do this by building progressively more complex models to see how this\n",
    "affects model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "!pip install -q keras-rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # `\"tensorflow\"`/`\"torch\"`\n",
    "\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf  # Needed for the dataset\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import keras_rs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## The MovieLens dataset\n",
    "\n",
    "Let's first have a look at what features we can use from the MovieLens dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Ratings data with user and movie data.\n",
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "# Features of all the available movies.\n",
    "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "The ratings dataset returns a dictionary of movie id, user id, the assigned\n",
    "rating, timestamp, movie information, and user information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "for data in ratings.take(1).as_numpy_iterator():\n",
    "    print(str(data).replace(\", '\", \",\\n '\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "In the Movielens dataset, user IDs are integers (represented as strings)\n",
    "starting at 1 and with no gap. Normally, you would need to create a lookup table\n",
    "to map user IDs to integers from 0 to N-1. But as a simplication, we'll use the\n",
    "user id directly as an index in our model, in particular to lookup the user\n",
    "embedding from the user embedding table. So we need do know the number of users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "USERS_COUNT = (\n",
    "    ratings.map(lambda x: tf.strings.to_number(x[\"user_id\"], out_type=tf.int32))\n",
    "    .reduce(tf.constant(0, tf.int32), tf.maximum)\n",
    "    .numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "The movies dataset contains the movie id, movie title, and the genres it belongs\n",
    "to. Note that the genres are encoded with integer labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "for data in movies.take(1).as_numpy_iterator():\n",
    "    print(str(data).replace(\", '\", \",\\n '\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "In the Movielens dataset, movie IDs are integers (represented as strings)\n",
    "starting at 1 and with no gap. Normally, you would need to create a lookup table\n",
    "to map movie IDs to integers from 0 to N-1. But as a simplication, we'll use the\n",
    "movie id directly as an index in our model, in particular to lookup the movie\n",
    "embedding from the movie embedding table. So we need do know the number of\n",
    "movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "MOVIES_COUNT = movies.cardinality().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Preprocessing the dataset\n",
    "\n",
    "### Normalizing continuous features\n",
    "\n",
    "Continuous features may need normalization so that they fall within an\n",
    "acceptable range for the model. We will give two examples of such normalization.\n",
    "\n",
    "#### Discretization\n",
    "\n",
    "A common transformation is to turn a continuous feature into a number of\n",
    "categorical features. This makes good sense if we have reasons to suspect that a\n",
    "feature's effect is non-continuous.\n",
    "\n",
    "We need to decide on a number the buckets we will use for discretization. Then,\n",
    "we will use the Keras `FeatureSpace` utility to automatically find the minimum\n",
    "and maximum value, and divide that range by the number of buckets to perform the\n",
    "discretization.\n",
    "\n",
    "In this example, we will discretize the user age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "AGE_BINS_COUNT = 10\n",
    "user_age_feature = keras.utils.FeatureSpace.float_discretized(\n",
    "    num_bins=AGE_BINS_COUNT, output_mode=\"int\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Rescaling\n",
    "\n",
    "Often, we want continous features to be between 0 and 1, or between -1 and 1.\n",
    "To achieve this, we can rescale features that have a different range.\n",
    "\n",
    "In this example, we will standardize the rating, which is a integer between 1\n",
    "and 5, to be a float between 0 and 1. We need to rescale it and offset it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "user_rating_feature = keras.utils.FeatureSpace.float_rescaled(\n",
    "    scale=1.0 / 4.0, offset=-1.0 / 4.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Turning categorical features into embeddings\n",
    "\n",
    "A categorical feature is a feature that does not express a continuous quantity,\n",
    "but rather takes on one of a set of fixed values.\n",
    "\n",
    "Most deep learning models express these feature by turning them into\n",
    "high-dimensional vectors. During model training, the value of that vector is\n",
    "adjusted to help the model predict its objective better.\n",
    "\n",
    "For example, suppose that our goal is to predict which user is going to watch\n",
    "which movie. To do that, we represent each user and each movie by an embedding\n",
    "vector. Initially, these embeddings will take on random values. During training,\n",
    "we adjust them so that embeddings of users and the movies they watch end up\n",
    "closer together.\n",
    "\n",
    "Taking raw categorical features and turning them into embeddings is normally a\n",
    "two-step process:\n",
    "1. First, we need to translate the raw values into a range of contiguous\n",
    "   integers, normally by building a mapping (called a \"vocabulary\") that maps\n",
    "   raw values to integers.\n",
    "2. Second, we need to take these integers and turn them into embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Defining categorical features\n",
    "\n",
    "We will use the Keras `FeatureSpace` utility for the first step. Its `adapt`\n",
    "method automatically discovers the vocabulary for categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "user_gender_feature = keras.utils.FeatureSpace.integer_categorical(\n",
    "    num_oov_indices=0, output_mode=\"int\"\n",
    ")\n",
    "user_occupation_feature = keras.utils.FeatureSpace.integer_categorical(\n",
    "    num_oov_indices=0, output_mode=\"int\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Using feature crosses\n",
    "\n",
    "With crosses we can do feature interactions between multiple categorical\n",
    "features.  This can be powerful to express that the combination of features\n",
    "represents a specific taste for movies.\n",
    "\n",
    "Note that the combination of multiple features can result into on a super large\n",
    "feature space, that is why the crossing_dim parameter is important to limit the\n",
    "output dimension of the cross feature.\n",
    "\n",
    "In this example, we will cross age and gender with the Keras `FeatureSpace`\n",
    "utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "USER_GENDER_CROSS_COUNT = 20\n",
    "user_gender_age_cross = keras.utils.FeatureSpace.cross(\n",
    "    feature_names=(\"user_gender\", \"raw_user_age\"),\n",
    "    crossing_dim=USER_GENDER_CROSS_COUNT,\n",
    "    output_mode=\"int\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Processing text features\n",
    "\n",
    "We may also want to add text features to our model. Usually, things like product\n",
    "descriptions are free form text, and we can hope that our model can learn to use\n",
    "the information they contain to make better recommendations, especially in a\n",
    "cold-start or long tail scenario.\n",
    "\n",
    "While the MovieLens dataset does not give us rich textual features, we can still\n",
    "use movie titles. This may help us capture the fact that movies with very\n",
    "similar titles are likely to belong to the same series.\n",
    "\n",
    "The first transformation we need to apply to text is tokenization (splitting\n",
    "into constituent words or word-pieces), followed by vocabulary learning,\n",
    "followed by an embedding.\n",
    "\n",
    "\n",
    "The\n",
    "[`keras.layers.TextVectorization`](/api/layers/preprocessing_layers/text/text_vectorization/)\n",
    "layer can do the first two steps for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "title_vectorizer = keras.layers.TextVectorization(\n",
    "    max_tokens=10_000, output_sequence_length=16, dtype=\"int32\"\n",
    ")\n",
    "title_vectorizer.adapt(movies.map(lambda x: x[\"movie_title\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Let's try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "for data in movies.take(1).as_numpy_iterator():\n",
    "    print(title_vectorizer(data[\"movie_title\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Each title is translated into a sequence of tokens, one for each piece we've\n",
    "tokenized.\n",
    "\n",
    "We can check the learned vocabulary to verify that the layer is using the\n",
    "correct tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "print(title_vectorizer.get_vocabulary()[40:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This looks correct, the layer is tokenizing titles into individual words. Later,\n",
    "we will see how to embed this tokenized text. For now, we turn this vectorizer\n",
    "into a Keras `FeatureSpace` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "title_feature = keras.utils.FeatureSpace.feature(\n",
    "    preprocessor=title_vectorizer, dtype=\"string\", output_mode=\"float\"\n",
    ")\n",
    "TITLE_TOKEN_COUNT = title_vectorizer.vocabulary_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Putting the FeatureSpace features together\n",
    "\n",
    "We're now ready to assemble the features with preprocessors in a `FeatureSpace`\n",
    "object. We're then using `adapt` to go through the dataset and learn what needs\n",
    "to be learned, such as the vocabulary size for categorical features or the\n",
    "minimum and maximum values for bucketized features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "feature_space = keras.utils.FeatureSpace(\n",
    "    features={\n",
    "        # Numerical features to discretize.\n",
    "        \"raw_user_age\": user_age_feature,\n",
    "        # Categorical features encoded as integers.\n",
    "        \"user_gender\": user_gender_feature,\n",
    "        \"user_occupation_label\": user_occupation_feature,\n",
    "        # Labels are ratings between 0 and 1.\n",
    "        \"user_rating\": user_rating_feature,\n",
    "        \"movie_title\": title_feature,\n",
    "    },\n",
    "    crosses=[user_gender_age_cross],\n",
    "    output_mode=\"dict\",\n",
    ")\n",
    "\n",
    "feature_space.adapt(ratings)\n",
    "GENDERS_COUNT = feature_space.preprocessors[\"user_gender\"].vocabulary_size()\n",
    "OCCUPATIONS_COUNT = feature_space.preprocessors[\n",
    "    \"user_occupation_label\"\n",
    "].vocabulary_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Pre-building the candidate set\n",
    "\n",
    "Our model is going to based on a `Retrieval` layer, which can provides a set of\n",
    "best candidates among to full set of candidates. To do this, the retrieval layer\n",
    "needs to know all the candidates and their features. In this section, we\n",
    "assemble the full set of movies with the associated features.\n",
    "\n",
    "### Extract raw candidate features\n",
    "\n",
    "First, we gather all the raw features from the dataset in lists. That is the\n",
    "titles of the movies and the genres. Note that one or more genres are\n",
    "associated with each movie, and the number of genres varies per movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "movie_titles = [\"\"] * (MOVIES_COUNT + 1)\n",
    "movie_genres = [[]] * (MOVIES_COUNT + 1)\n",
    "for x in movies.as_numpy_iterator():\n",
    "    movie_id = int(x[\"movie_id\"])\n",
    "    movie_titles[movie_id] = x[\"movie_title\"]\n",
    "    movie_genres[movie_id] = x[\"movie_genres\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Preprocess candidate features\n",
    "\n",
    "Genres are already in the form of category numbers starting at zero. However, we\n",
    "do need to figure out two things:\n",
    "- The maximum number of genres a single movie can have; this will determine the\n",
    "  dimension for this feature.\n",
    "- The maximum value for the genre, which will give us the total number of genres\n",
    "  and determine the size of our embedding table for genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "MAX_GENRES_PER_MOVIE = 0\n",
    "max_genre_id = 0\n",
    "for one_movie_genres in movie_genres:\n",
    "    MAX_GENRES_PER_MOVIE = max(MAX_GENRES_PER_MOVIE, len(one_movie_genres))\n",
    "    if one_movie_genres:\n",
    "        max_genre_id = max(max_genre_id, max(one_movie_genres))\n",
    "\n",
    "GENRES_COUNT = max_genre_id + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Now we need to pad genres with an Out Of Vocabulary value to be able to\n",
    "represent genres as a fixed size vector. We'll pad with zeros for simplicity, so\n",
    "we're adding one to the genres to not conflict with genre zero, which is a valid\n",
    "genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "movie_genres = [\n",
    "    [g + 1 for g in genres] + [0] * (MAX_GENRES_PER_MOVIE - len(genres))\n",
    "    for genres in movie_genres\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Then, we vectorize all the movie titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "movie_titles_vectors = title_vectorizer(movie_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Convert candidate set to native tensors\n",
    "\n",
    "We're now ready to combine these in a dataset. The last step is to make sure\n",
    "everything is a native tensor that can be consumed by the retrieval layer.\n",
    "As a remminder, movie id zero does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "MOVIES_DATASET = {\n",
    "    \"movie_id\": keras.ops.arange(0, MOVIES_COUNT + 1, dtype=\"int32\"),\n",
    "    \"movie_title_vector\": movie_titles_vectors,\n",
    "    \"movie_genres\": keras.ops.convert_to_tensor(movie_genres, dtype=\"int32\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Preparing the data\n",
    "\n",
    "We can now define our preprocessing function. Most features will be handled\n",
    "by the `FeatureSpace`. User IDs and Movie IDs need to be extracted. Movie genres\n",
    "need to be padded. Then everything is packaged as a tuple with a dict of input\n",
    "features and a float for the rating, which is used as a label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def preprocess_rating(x):\n",
    "    features = feature_space(\n",
    "        {\n",
    "            \"raw_user_age\": x[\"raw_user_age\"],\n",
    "            \"user_gender\": x[\"user_gender\"],\n",
    "            \"user_occupation_label\": x[\"user_occupation_label\"],\n",
    "            \"user_rating\": x[\"user_rating\"],\n",
    "            \"movie_title\": x[\"movie_title\"],\n",
    "        }\n",
    "    )\n",
    "    features = {k: tf.squeeze(v, axis=0) for k, v in features.items()}\n",
    "    movie_genres = x[\"movie_genres\"]\n",
    "\n",
    "    return (\n",
    "        {\n",
    "            # User inputs are user ID and user features\n",
    "            \"user_id\": int(x[\"user_id\"]),\n",
    "            \"raw_user_age\": features[\"raw_user_age\"],\n",
    "            \"user_gender\": features[\"user_gender\"],\n",
    "            \"user_occupation_label\": features[\"user_occupation_label\"],\n",
    "            \"user_gender_X_raw_user_age\": tf.squeeze(\n",
    "                features[\"user_gender_X_raw_user_age\"], axis=-1\n",
    "            ),\n",
    "            # Movie inputs are movie ID, vectorized title and genres\n",
    "            \"movie_id\": int(x[\"movie_id\"]),\n",
    "            \"movie_title_vector\": features[\"movie_title\"],\n",
    "            \"movie_genres\": tf.pad(\n",
    "                movie_genres + 1,\n",
    "                [[0, MAX_GENRES_PER_MOVIE - tf.shape(movie_genres)[0]]],\n",
    "            ),\n",
    "        },\n",
    "        # Label is user rating between 0 and 1\n",
    "        features[\"user_rating\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "We shuffle and then split the data into a training set and a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "shuffled_ratings = ratings.map(preprocess_rating).shuffle(\n",
    "    100_000, seed=42, reshuffle_each_iteration=False\n",
    ")\n",
    "\n",
    "train_ratings = shuffled_ratings.take(80_000).batch(1000).cache()\n",
    "test_ratings = shuffled_ratings.skip(80_000).take(20_000).batch(1000).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Model definition\n",
    "\n",
    "### Query model\n",
    "\n",
    "The query model is first tasked with converting user features to embeddings. The\n",
    "embeddings are then concatenated into a single vector.\n",
    "\n",
    "Defining deeper models will require us to stack more layers on top of this first\n",
    "set of embeddings. A progressively narrower stack of layers, separated by an\n",
    "activation function, is a common pattern:\n",
    "\n",
    "```\n",
    "                            +----------------------+\n",
    "                            |       64 x 32        |\n",
    "                            +----------------------+\n",
    "                                       | relu\n",
    "                          +--------------------------+\n",
    "                          |         128 x 64         |\n",
    "                          +--------------------------+\n",
    "                                       | relu\n",
    "                        +------------------------------+\n",
    "                        |          ... x 128           |\n",
    "                        +------------------------------+\n",
    "```\n",
    "\n",
    "Since the expressive power of deep linear models is no greater than that of\n",
    "shallow linear models, we use ReLU activations for all but the last hidden\n",
    "layer. The final hidden layer does not use any activation function: using an\n",
    "activation function would limit the output space of the final embeddings and\n",
    "might negatively impact the performance of the model. For instance, if ReLUs are\n",
    "used in the projection layer, all components in the output embedding would be\n",
    "non-negative.\n",
    "\n",
    "We're going to try this here. To make experimentation with different depths\n",
    "easy, let's define a model whose depth (and width) is defined by a constructor\n",
    "parameters. The `layer_sizes` parameter gives us the depth and width of the\n",
    "model. We can vary it to experiment with shallower or deeper models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class QueryModel(keras.Model):\n",
    "    \"\"\"Model for encoding user queries.\"\"\"\n",
    "\n",
    "    def __init__(self, layer_sizes, embedding_dimension=32):\n",
    "        \"\"\"Construct a model for encoding user queries.\n",
    "\n",
    "        Args:\n",
    "          layer_sizes: A list of integers where the i-th entry represents the\n",
    "            number of units the i-th layer contains.\n",
    "          embedding_dimension: Output dimension for all embedding tables.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # We first generate embeddings.\n",
    "        self.user_embedding = keras.layers.Embedding(\n",
    "            # +1 for user ID zero, which does not exist\n",
    "            USERS_COUNT + 1,\n",
    "            embedding_dimension,\n",
    "        )\n",
    "        self.gender_embedding = keras.layers.Embedding(\n",
    "            GENDERS_COUNT, embedding_dimension\n",
    "        )\n",
    "        self.age_embedding = keras.layers.Embedding(AGE_BINS_COUNT, embedding_dimension)\n",
    "        self.gender_x_age_embedding = keras.layers.Embedding(\n",
    "            USER_GENDER_CROSS_COUNT, embedding_dimension\n",
    "        )\n",
    "        self.occupation_embedding = keras.layers.Embedding(\n",
    "            OCCUPATIONS_COUNT, embedding_dimension\n",
    "        )\n",
    "\n",
    "        # Then construct the layers.\n",
    "        self.dense_layers = keras.Sequential()\n",
    "\n",
    "        # Use the ReLU activation for all but the last layer.\n",
    "        for layer_size in layer_sizes[:-1]:\n",
    "            self.dense_layers.add(keras.layers.Dense(layer_size, activation=\"relu\"))\n",
    "\n",
    "        # No activation for the last layer.\n",
    "        self.dense_layers.add(keras.layers.Dense(layer_sizes[-1]))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Take the inputs, pass each through its embedding layer, concatenate.\n",
    "        feature_embedding = keras.ops.concatenate(\n",
    "            [\n",
    "                self.user_embedding(inputs[\"user_id\"]),\n",
    "                self.gender_embedding(inputs[\"user_gender\"]),\n",
    "                self.age_embedding(inputs[\"raw_user_age\"]),\n",
    "                self.gender_x_age_embedding(inputs[\"user_gender_X_raw_user_age\"]),\n",
    "                self.occupation_embedding(inputs[\"user_occupation_label\"]),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        return self.dense_layers(feature_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Candidate model\n",
    "\n",
    "We can adopt the same approach for the candidate model. Again, we start with\n",
    "converting movie features to embeddings, concatenate them and then expand it\n",
    "with hidden layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CandidateModel(keras.Model):\n",
    "    \"\"\"Model for encoding candidates (movies).\"\"\"\n",
    "\n",
    "    def __init__(self, layer_sizes, embedding_dimension=32):\n",
    "        \"\"\"Construct a model for encoding candidates (movies).\n",
    "\n",
    "        Args:\n",
    "          layer_sizes: A list of integers where the i-th entry represents the\n",
    "            number of units the i-th layer contains.\n",
    "          embedding_dimension: Output dimension for all embedding tables.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # We first generate embeddings.\n",
    "        self.movie_embedding = keras.layers.Embedding(\n",
    "            # +1 for movie ID zero, which does not exist\n",
    "            MOVIES_COUNT + 1,\n",
    "            embedding_dimension,\n",
    "        )\n",
    "        # Take all the title tokens for the title of the movie, embed each\n",
    "        # token, and then take the mean of all token embeddings.\n",
    "        self.movie_title_embedding = keras.Sequential(\n",
    "            [\n",
    "                keras.layers.Embedding(\n",
    "                    # +1 for OOV token, which is used for padding\n",
    "                    TITLE_TOKEN_COUNT + 1,\n",
    "                    embedding_dimension,\n",
    "                    mask_zero=True,\n",
    "                ),\n",
    "                keras.layers.GlobalAveragePooling1D(),\n",
    "            ]\n",
    "        )\n",
    "        # Take all the genres for the movie, embed each genre, and then take the\n",
    "        # mean of all genre embeddings.\n",
    "        self.movie_genres_embedding = keras.Sequential(\n",
    "            [\n",
    "                keras.layers.Embedding(\n",
    "                    # +1 for OOV genre, which is used for padding\n",
    "                    GENRES_COUNT + 1,\n",
    "                    embedding_dimension,\n",
    "                    mask_zero=True,\n",
    "                ),\n",
    "                keras.layers.GlobalAveragePooling1D(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Then construct the layers.\n",
    "        self.dense_layers = keras.Sequential()\n",
    "\n",
    "        # Use the ReLU activation for all but the last layer.\n",
    "        for layer_size in layer_sizes[:-1]:\n",
    "            self.dense_layers.add(keras.layers.Dense(layer_size, activation=\"relu\"))\n",
    "\n",
    "        # No activation for the last layer.\n",
    "        self.dense_layers.add(keras.layers.Dense(layer_sizes[-1]))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        movie_id = inputs[\"movie_id\"]\n",
    "        movie_title_vector = inputs[\"movie_title_vector\"]\n",
    "        movie_genres = inputs[\"movie_genres\"]\n",
    "        feature_embedding = keras.ops.concatenate(\n",
    "            [\n",
    "                self.movie_embedding(movie_id),\n",
    "                self.movie_title_embedding(movie_title_vector),\n",
    "                self.movie_genres_embedding(movie_genres),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        return self.dense_layers(feature_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Combined model\n",
    "\n",
    "With both QueryModel and CandidateModel defined, we can put together a combined\n",
    "model and implement our loss and metrics logic. To make things simple, we'll\n",
    "enforce that the model structure is the same across the query and candidate\n",
    "models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class RetrievalModel(keras.Model):\n",
    "    \"\"\"Combined model.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        layer_sizes=(32,),\n",
    "        embedding_dimension=32,\n",
    "        retrieval_k=100,\n",
    "    ):\n",
    "        \"\"\"Construct a combined model.\n",
    "\n",
    "        Args:\n",
    "          layer_sizes: A list of integers where the i-th entry represents the\n",
    "            number of units the i-th layer contains.\n",
    "          embedding_dimension: Output dimension for all embedding tables.\n",
    "          retrieval_k: How many candidate movies to retrieve.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.query_model = QueryModel(layer_sizes, embedding_dimension)\n",
    "        self.candidate_model = CandidateModel(layer_sizes, embedding_dimension)\n",
    "        self.retrieval = keras_rs.layers.BruteForceRetrieval(\n",
    "            k=retrieval_k, return_scores=False\n",
    "        )\n",
    "        self.update_candidates()  # Provide an initial set of candidates\n",
    "        self.loss_fn = keras.losses.MeanSquaredError()\n",
    "        self.top_k_metric = keras.metrics.SparseTopKCategoricalAccuracy(\n",
    "            k=retrieval_k, from_sorted_ids=True\n",
    "        )\n",
    "\n",
    "    def update_candidates(self):\n",
    "        self.retrieval.update_candidates(\n",
    "            self.candidate_model.predict(MOVIES_DATASET, verbose=0)\n",
    "        )\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        query_embeddings = self.query_model(\n",
    "            {\n",
    "                \"user_id\": inputs[\"user_id\"],\n",
    "                \"raw_user_age\": inputs[\"raw_user_age\"],\n",
    "                \"user_gender\": inputs[\"user_gender\"],\n",
    "                \"user_occupation_label\": inputs[\"user_occupation_label\"],\n",
    "                \"user_gender_X_raw_user_age\": inputs[\"user_gender_X_raw_user_age\"],\n",
    "            }\n",
    "        )\n",
    "        candidate_embeddings = self.candidate_model(\n",
    "            {\n",
    "                \"movie_id\": inputs[\"movie_id\"],\n",
    "                \"movie_title_vector\": inputs[\"movie_title_vector\"],\n",
    "                \"movie_genres\": inputs[\"movie_genres\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        result = {\n",
    "            \"query_embeddings\": query_embeddings,\n",
    "            \"candidate_embeddings\": candidate_embeddings,\n",
    "        }\n",
    "        if not training:\n",
    "            # No need to spend time extracting top predicted movies during\n",
    "            # training, they are not used.\n",
    "            result[\"predictions\"] = self.retrieval(query_embeddings)\n",
    "        return result\n",
    "\n",
    "    def evaluate(\n",
    "        self,\n",
    "        x=None,\n",
    "        y=None,\n",
    "        batch_size=None,\n",
    "        verbose=\"auto\",\n",
    "        sample_weight=None,\n",
    "        steps=None,\n",
    "        callbacks=None,\n",
    "        return_dict=False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Overridden to update the candidate set.\n",
    "\n",
    "        Before evaluating the model, we need to update our retrieval layer by\n",
    "        re-computing the values predicted by the candidate model for all the\n",
    "        candidates.\n",
    "        \"\"\"\n",
    "        self.update_candidates()\n",
    "        return super().evaluate(\n",
    "            x,\n",
    "            y,\n",
    "            batch_size=batch_size,\n",
    "            verbose=verbose,\n",
    "            sample_weight=sample_weight,\n",
    "            steps=steps,\n",
    "            callbacks=callbacks,\n",
    "            return_dict=return_dict,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, x, y, y_pred, sample_weight, training=True):\n",
    "        query_embeddings = y_pred[\"query_embeddings\"]\n",
    "        candidate_embeddings = y_pred[\"candidate_embeddings\"]\n",
    "\n",
    "        labels = keras.ops.expand_dims(y, -1)\n",
    "        # Compute the affinity score by multiplying the two embeddings.\n",
    "        scores = keras.ops.sum(\n",
    "            keras.ops.multiply(query_embeddings, candidate_embeddings),\n",
    "            axis=1,\n",
    "            keepdims=True,\n",
    "        )\n",
    "        return self.loss_fn(labels, scores, sample_weight)\n",
    "\n",
    "    def compute_metrics(self, x, y, y_pred, sample_weight=None):\n",
    "        if \"predictions\" in y_pred:\n",
    "            # We are evaluating or predicting. Update `top_k_metric`.\n",
    "            movie_ids = x[\"movie_id\"]\n",
    "            predictions = y_pred[\"predictions\"]\n",
    "            # For `top_k_metric`, which is a `SparseTopKCategoricalAccuracy`, we\n",
    "            # only take top rated movies, and we put a weight of 0 for the rest.\n",
    "            rating_weight = keras.ops.cast(keras.ops.greater(y, 0.9), \"float32\")\n",
    "            sample_weight = (\n",
    "                rating_weight\n",
    "                if sample_weight is None\n",
    "                else keras.ops.multiply(rating_weight, sample_weight)\n",
    "            )\n",
    "            self.top_k_metric.update_state(\n",
    "                movie_ids, predictions, sample_weight=sample_weight\n",
    "            )\n",
    "            return self.get_metrics_result()\n",
    "        else:\n",
    "            # We are training. `top_k_metric` is not updated and is zero, so\n",
    "            # don't report it.\n",
    "            result = self.get_metrics_result()\n",
    "            result.pop(self.top_k_metric.name)\n",
    "            return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Training the model\n",
    "\n",
    "### Shallow model\n",
    "\n",
    "We're ready to try out our first, shallow, model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 30\n",
    "\n",
    "one_layer_model = RetrievalModel((32,))\n",
    "one_layer_model.compile(optimizer=keras.optimizers.Adagrad(0.05))\n",
    "\n",
    "one_layer_history = one_layer_model.fit(\n",
    "    train_ratings,\n",
    "    validation_data=test_ratings,\n",
    "    validation_freq=5,\n",
    "    epochs=NUM_EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This gives us a top-100 accuracy of around 0.30. We can use this as a reference\n",
    "point for evaluating deeper models.\n",
    "\n",
    "### Deeper model\n",
    "\n",
    "What about a deeper model with two layers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "two_layer_model = RetrievalModel((64, 32))\n",
    "two_layer_model.compile(optimizer=keras.optimizers.Adagrad(0.05))\n",
    "two_layer_history = two_layer_model.fit(\n",
    "    train_ratings,\n",
    "    validation_data=test_ratings,\n",
    "    validation_freq=5,\n",
    "    epochs=NUM_EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "While the deeper model seems to learn a bit better than the shallow model at\n",
    "first, the difference becomes minimal towards the end of the trainign. We can\n",
    "plot the validation accuracy curves to illustrate this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "METRIC = \"val_sparse_top_k_categorical_accuracy\"\n",
    "num_validation_runs = len(one_layer_history.history[METRIC])\n",
    "epochs = [(x + 1) * 5 for x in range(num_validation_runs)]\n",
    "\n",
    "plt.plot(epochs, one_layer_history.history[METRIC], label=\"1 layer\")\n",
    "plt.plot(epochs, two_layer_history.history[METRIC], label=\"2 layers\")\n",
    "plt.title(\"Accuracy vs epoch\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Top-100 accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Deeper models are not necessarily better. The following model extends the depth\n",
    "to three layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "three_layer_model = RetrievalModel((128, 64, 32))\n",
    "three_layer_model.compile(optimizer=keras.optimizers.Adagrad(0.05))\n",
    "three_layer_history = three_layer_model.fit(\n",
    "    train_ratings,\n",
    "    validation_data=test_ratings,\n",
    "    validation_freq=5,\n",
    "    epochs=NUM_EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "We don't really see an improvement over the shallow model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "plt.plot(epochs, one_layer_history.history[METRIC], label=\"1 layer\")\n",
    "plt.plot(epochs, two_layer_history.history[METRIC], label=\"2 layers\")\n",
    "plt.plot(epochs, three_layer_history.history[METRIC], label=\"3 layers\")\n",
    "plt.title(\"Accuracy vs epoch\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Top-100 accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This is a good illustration of the fact that deeper and larger models, while\n",
    "capable of superior performance, often require very careful tuning. For example,\n",
    "throughout this tutorial we used a single, fixed learning rate. Alternative\n",
    "choices may give very different results and are worth exploring.\n",
    "\n",
    "With appropriate tuning and sufficient data, the effort put into building larger\n",
    "and deeper models is in many cases well worth it: larger models can lead to\n",
    "substantial improvements in prediction accuracy.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "In this tutorial we expanded our retrieval model with dense layers and\n",
    "activation functions. To see how to create a model that can perform not only\n",
    "retrieval tasks but also rating tasks, take a look at the multitask tutorial."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "deep_recommender",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
